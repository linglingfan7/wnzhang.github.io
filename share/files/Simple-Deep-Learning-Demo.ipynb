{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_spin(size=400, n=2, n_class=2, noise=2):\n",
    "    xs = np.zeros((size * n, 2), dtype=np.float32)\n",
    "    ys = np.zeros(size * n, dtype=np.int32)\n",
    "    for i in range(n):\n",
    "        ix = range(size * i, size * (i + 1))\n",
    "        r = np.linspace(0.0, 5, size + 1)[1:]\n",
    "        t = np.linspace(2 * i * np.pi / n, (2 * (i + 4) + 1) * np.pi / n, size)\n",
    "        xs[ix] = np.c_[r * np.sin(t) + random.uniform(-1, 1) * noise, r * np.cos(t) + random.uniform(-1, 1) * noise]\n",
    "        ys[ix] = i % n_class\n",
    "    z = []\n",
    "    for yy in ys:\n",
    "        tmp = [0 if i != yy else 1 for i in range(n_class)]\n",
    "        z.append(tmp)\n",
    "    return xs, np.array(z)\n",
    "\n",
    "def gen_feature(x):\n",
    "    x1 = x[:, 0]\n",
    "    x2 = x[:, 1]\n",
    "    x_square = np.square(x)\n",
    "    x1x2 = x1 * x2\n",
    "    sin_x = np.sin(x)\n",
    "    return np.c_[x, x_square, x1x2, sin_x]\n",
    "\n",
    "def make_meshgrid(x, y, h=.02):\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "def plot_contours(ax, pred, xx, yy, **params):\n",
    "    Z = pred.reshape(xx.shape)\n",
    "    out = ax.contourf(xx, yy, Z, **params)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7efc5df3bf90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYRjF+P+8gNLYbagBvwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efc5ffc0510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_size = 150\n",
    "x, label = gen_spin(size=data_size, noise=0.1)\n",
    "feature = gen_feature(x)\n",
    "\n",
    "class_0 = x[label[:, 0] == 1]\n",
    "class_1 = x[label[:, 1] == 1]\n",
    "plt.scatter(class_0[:, 0], class_0[:, 1], c='b', s=20)\n",
    "plt.scatter(class_1[:, 0], class_1[:, 1], c='g', s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03690465,  0.04664385,  1.        ,  0.        ],\n",
       "       [-0.03058878,  0.07967734,  1.        ,  0.        ],\n",
       "       [-0.01804226,  0.11151546,  1.        ,  0.        ],\n",
       "       ..., \n",
       "       [-4.90768576, -0.90643573,  0.        ,  1.        ],\n",
       "       [-5.00723648, -0.44642371,  0.        ,  1.        ],\n",
       "       [-5.06290865,  0.02410848,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([x, label], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Tensorflow Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(data_size * 2, data_size * 2, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = feature[idx]\n",
    "train_label = label[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct network\n",
    "alpha = 0.003\n",
    "batch_size = 10\n",
    "max_iter = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, 7))\n",
    "y = tf.placeholder(tf.float32, shape=(None, 2))\n",
    "\n",
    "with tf.variable_scope(\"Net\"):\n",
    "    dense1 = tf.layers.dense(X, units=10, activation=tf.nn.tanh)\n",
    "    dense2 = tf.layers.dense(dense1, units=9, activation=tf.nn.tanh)\n",
    "    dense3 = tf.layers.dense(dense2, units=5, activation=tf.nn.tanh)\n",
    "    out = tf.layers.dense(dense3, units=2, activation=tf.nn.tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=out))\n",
    "train_op = tf.train.AdamOptimizer(alpha).minimize(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0/8000, Loss: 0.705349206924.\n",
      "Iteration: 1/8000, Loss: 0.701860845089.\n",
      "Iteration: 2/8000, Loss: 0.698654949665.\n",
      "Iteration: 3/8000, Loss: 0.695667386055.\n",
      "Iteration: 4/8000, Loss: 0.692884802818.\n",
      "Iteration: 5/8000, Loss: 0.690314114094.\n",
      "Iteration: 6/8000, Loss: 0.687959492207.\n",
      "Iteration: 7/8000, Loss: 0.685818076134.\n",
      "Iteration: 8/8000, Loss: 0.683876037598.\n",
      "Iteration: 9/8000, Loss: 0.682106494904.\n",
      "Iteration: 10/8000, Loss: 0.680473566055.\n",
      "Iteration: 11/8000, Loss: 0.678939282894.\n",
      "Iteration: 12/8000, Loss: 0.677469193935.\n",
      "Iteration: 13/8000, Loss: 0.676034510136.\n",
      "Iteration: 14/8000, Loss: 0.67461335659.\n",
      "Iteration: 15/8000, Loss: 0.673190951347.\n",
      "Iteration: 16/8000, Loss: 0.671758592129.\n",
      "Iteration: 17/8000, Loss: 0.670312941074.\n",
      "Iteration: 18/8000, Loss: 0.668854057789.\n",
      "Iteration: 19/8000, Loss: 0.667383909225.\n",
      "Iteration: 20/8000, Loss: 0.66590410471.\n",
      "Iteration: 21/8000, Loss: 0.664415001869.\n",
      "Iteration: 22/8000, Loss: 0.662914574146.\n",
      "Iteration: 23/8000, Loss: 0.66139960289.\n",
      "Iteration: 24/8000, Loss: 0.65986508131.\n",
      "Iteration: 25/8000, Loss: 0.658305943012.\n",
      "Iteration: 26/8000, Loss: 0.656717419624.\n",
      "Iteration: 27/8000, Loss: 0.655096173286.\n",
      "Iteration: 28/8000, Loss: 0.653440415859.\n",
      "Iteration: 29/8000, Loss: 0.651750206947.\n",
      "Iteration: 30/8000, Loss: 0.650027275085.\n",
      "Iteration: 31/8000, Loss: 0.648274481297.\n",
      "Iteration: 32/8000, Loss: 0.646495103836.\n",
      "Iteration: 33/8000, Loss: 0.644692063332.\n",
      "Iteration: 34/8000, Loss: 0.642867803574.\n",
      "Iteration: 35/8000, Loss: 0.641024947166.\n",
      "Iteration: 36/8000, Loss: 0.639166176319.\n",
      "Iteration: 37/8000, Loss: 0.637294888496.\n",
      "Iteration: 38/8000, Loss: 0.635415017605.\n",
      "Iteration: 39/8000, Loss: 0.63353061676.\n",
      "Iteration: 40/8000, Loss: 0.631645143032.\n",
      "Iteration: 41/8000, Loss: 0.629761576653.\n",
      "Iteration: 42/8000, Loss: 0.627881765366.\n",
      "Iteration: 43/8000, Loss: 0.626007318497.\n",
      "Iteration: 44/8000, Loss: 0.624140202999.\n",
      "Iteration: 45/8000, Loss: 0.622282624245.\n",
      "Iteration: 46/8000, Loss: 0.620437860489.\n",
      "Iteration: 47/8000, Loss: 0.618609786034.\n",
      "Iteration: 48/8000, Loss: 0.616802215576.\n",
      "Iteration: 49/8000, Loss: 0.615018308163.\n",
      "Iteration: 50/8000, Loss: 0.613260149956.\n",
      "Iteration: 51/8000, Loss: 0.611528754234.\n",
      "Iteration: 52/8000, Loss: 0.609823226929.\n",
      "Iteration: 53/8000, Loss: 0.608141958714.\n",
      "Iteration: 54/8000, Loss: 0.606482744217.\n",
      "Iteration: 55/8000, Loss: 0.604843020439.\n",
      "Iteration: 56/8000, Loss: 0.603220283985.\n",
      "Iteration: 57/8000, Loss: 0.60161203146.\n",
      "Iteration: 58/8000, Loss: 0.600015699863.\n",
      "Iteration: 59/8000, Loss: 0.598428606987.\n",
      "Iteration: 60/8000, Loss: 0.596848130226.\n",
      "Iteration: 61/8000, Loss: 0.595272243023.\n",
      "Iteration: 62/8000, Loss: 0.593699514866.\n",
      "Iteration: 63/8000, Loss: 0.59212911129.\n",
      "Iteration: 64/8000, Loss: 0.590561330318.\n",
      "Iteration: 65/8000, Loss: 0.58899641037.\n",
      "Iteration: 66/8000, Loss: 0.587434887886.\n",
      "Iteration: 67/8000, Loss: 0.585877001286.\n",
      "Iteration: 68/8000, Loss: 0.584322869778.\n",
      "Iteration: 69/8000, Loss: 0.582772731781.\n",
      "Iteration: 70/8000, Loss: 0.581226944923.\n",
      "Iteration: 71/8000, Loss: 0.579686164856.\n",
      "Iteration: 72/8000, Loss: 0.578150331974.\n",
      "Iteration: 73/8000, Loss: 0.57661730051.\n",
      "Iteration: 74/8000, Loss: 0.575082778931.\n",
      "Iteration: 75/8000, Loss: 0.573540568352.\n",
      "Iteration: 76/8000, Loss: 0.571985065937.\n",
      "Iteration: 77/8000, Loss: 0.57041323185.\n",
      "Iteration: 78/8000, Loss: 0.568825125694.\n",
      "Iteration: 79/8000, Loss: 0.567223548889.\n",
      "Iteration: 80/8000, Loss: 0.565611839294.\n",
      "Iteration: 81/8000, Loss: 0.563991725445.\n",
      "Iteration: 82/8000, Loss: 0.562363862991.\n",
      "Iteration: 83/8000, Loss: 0.560728311539.\n",
      "Iteration: 84/8000, Loss: 0.559085845947.\n",
      "Iteration: 85/8000, Loss: 0.557437717915.\n",
      "Iteration: 86/8000, Loss: 0.555785655975.\n",
      "Iteration: 87/8000, Loss: 0.55413043499.\n",
      "Iteration: 88/8000, Loss: 0.552470445633.\n",
      "Iteration: 89/8000, Loss: 0.550801575184.\n",
      "Iteration: 90/8000, Loss: 0.549119532108.\n",
      "Iteration: 91/8000, Loss: 0.547422170639.\n",
      "Iteration: 92/8000, Loss: 0.545711696148.\n",
      "Iteration: 93/8000, Loss: 0.543993353844.\n",
      "Iteration: 94/8000, Loss: 0.542271733284.\n",
      "Iteration: 95/8000, Loss: 0.540546417236.\n",
      "Iteration: 96/8000, Loss: 0.538812756538.\n",
      "Iteration: 97/8000, Loss: 0.537067174911.\n",
      "Iteration: 98/8000, Loss: 0.53531229496.\n",
      "Iteration: 99/8000, Loss: 0.533555746078.\n",
      "Iteration: 100/8000, Loss: 0.531801939011.\n",
      "Iteration: 101/8000, Loss: 0.530047357082.\n",
      "Iteration: 102/8000, Loss: 0.528286099434.\n",
      "Iteration: 103/8000, Loss: 0.526518285275.\n",
      "Iteration: 104/8000, Loss: 0.52475041151.\n",
      "Iteration: 105/8000, Loss: 0.522987246513.\n",
      "Iteration: 106/8000, Loss: 0.521226108074.\n",
      "Iteration: 107/8000, Loss: 0.519462645054.\n",
      "Iteration: 108/8000, Loss: 0.517697930336.\n",
      "Iteration: 109/8000, Loss: 0.515936493874.\n",
      "Iteration: 110/8000, Loss: 0.514181911945.\n",
      "Iteration: 111/8000, Loss: 0.512440085411.\n",
      "Iteration: 112/8000, Loss: 0.510723233223.\n",
      "Iteration: 113/8000, Loss: 0.50904661417.\n",
      "Iteration: 114/8000, Loss: 0.507419407368.\n",
      "Iteration: 115/8000, Loss: 0.505840361118.\n",
      "Iteration: 116/8000, Loss: 0.50429803133.\n",
      "Iteration: 117/8000, Loss: 0.502774834633.\n",
      "Iteration: 118/8000, Loss: 0.501253247261.\n",
      "Iteration: 119/8000, Loss: 0.499721854925.\n",
      "Iteration: 120/8000, Loss: 0.498176336288.\n",
      "Iteration: 121/8000, Loss: 0.496617376804.\n",
      "Iteration: 122/8000, Loss: 0.495046645403.\n",
      "Iteration: 123/8000, Loss: 0.493462085724.\n",
      "Iteration: 124/8000, Loss: 0.491854429245.\n",
      "Iteration: 125/8000, Loss: 0.490205705166.\n",
      "Iteration: 126/8000, Loss: 0.488492310047.\n",
      "Iteration: 127/8000, Loss: 0.486694723368.\n",
      "Iteration: 128/8000, Loss: 0.484803795815.\n",
      "Iteration: 129/8000, Loss: 0.482820153236.\n",
      "Iteration: 130/8000, Loss: 0.480746507645.\n",
      "Iteration: 131/8000, Loss: 0.478584647179.\n",
      "Iteration: 132/8000, Loss: 0.476343721151.\n",
      "Iteration: 133/8000, Loss: 0.474050492048.\n",
      "Iteration: 134/8000, Loss: 0.471746623516.\n",
      "Iteration: 135/8000, Loss: 0.469469606876.\n",
      "Iteration: 136/8000, Loss: 0.467227846384.\n",
      "Iteration: 137/8000, Loss: 0.464988827705.\n",
      "Iteration: 138/8000, Loss: 0.462698400021.\n",
      "Iteration: 139/8000, Loss: 0.460322767496.\n",
      "Iteration: 140/8000, Loss: 0.457871079445.\n",
      "Iteration: 141/8000, Loss: 0.455376207829.\n",
      "Iteration: 142/8000, Loss: 0.452860713005.\n",
      "Iteration: 143/8000, Loss: 0.450321018696.\n",
      "Iteration: 144/8000, Loss: 0.447734922171.\n",
      "Iteration: 145/8000, Loss: 0.445089101791.\n",
      "Iteration: 146/8000, Loss: 0.442390650511.\n",
      "Iteration: 147/8000, Loss: 0.439637035131.\n",
      "Iteration: 148/8000, Loss: 0.436809718609.\n",
      "Iteration: 149/8000, Loss: 0.43390801549.\n",
      "Iteration: 150/8000, Loss: 0.43095189333.\n",
      "Iteration: 151/8000, Loss: 0.427947282791.\n",
      "Iteration: 152/8000, Loss: 0.424874186516.\n",
      "Iteration: 153/8000, Loss: 0.421706795692.\n",
      "Iteration: 154/8000, Loss: 0.418428987265.\n",
      "Iteration: 155/8000, Loss: 0.415046334267.\n",
      "Iteration: 156/8000, Loss: 0.411602437496.\n",
      "Iteration: 157/8000, Loss: 0.40817117691.\n",
      "Iteration: 158/8000, Loss: 0.404817461967.\n",
      "Iteration: 159/8000, Loss: 0.40156981349.\n",
      "Iteration: 160/8000, Loss: 0.398438870907.\n",
      "Iteration: 161/8000, Loss: 0.39543107152.\n",
      "Iteration: 162/8000, Loss: 0.392540693283.\n",
      "Iteration: 163/8000, Loss: 0.389743477106.\n",
      "Iteration: 164/8000, Loss: 0.386991262436.\n",
      "Iteration: 165/8000, Loss: 0.38422665.\n",
      "Iteration: 166/8000, Loss: 0.381417244673.\n",
      "Iteration: 167/8000, Loss: 0.378577470779.\n",
      "Iteration: 168/8000, Loss: 0.37575173378.\n",
      "Iteration: 169/8000, Loss: 0.372973650694.\n",
      "Iteration: 170/8000, Loss: 0.37024217844.\n",
      "Iteration: 171/8000, Loss: 0.367538273335.\n",
      "Iteration: 172/8000, Loss: 0.364849507809.\n",
      "Iteration: 173/8000, Loss: 0.362184643745.\n",
      "Iteration: 174/8000, Loss: 0.359563976526.\n",
      "Iteration: 175/8000, Loss: 0.356990158558.\n",
      "Iteration: 176/8000, Loss: 0.354452192783.\n",
      "Iteration: 177/8000, Loss: 0.351950407028.\n",
      "Iteration: 178/8000, Loss: 0.34948977828.\n",
      "Iteration: 179/8000, Loss: 0.347063541412.\n",
      "Iteration: 180/8000, Loss: 0.344658970833.\n",
      "Iteration: 181/8000, Loss: 0.342272043228.\n",
      "Iteration: 182/8000, Loss: 0.339912235737.\n",
      "Iteration: 183/8000, Loss: 0.337595790625.\n",
      "Iteration: 184/8000, Loss: 0.335335344076.\n",
      "Iteration: 185/8000, Loss: 0.333130836487.\n",
      "Iteration: 186/8000, Loss: 0.330976307392.\n",
      "Iteration: 187/8000, Loss: 0.328861474991.\n",
      "Iteration: 188/8000, Loss: 0.326772332191.\n",
      "Iteration: 189/8000, Loss: 0.32470023632.\n",
      "Iteration: 190/8000, Loss: 0.322643369436.\n",
      "Iteration: 191/8000, Loss: 0.320601940155.\n",
      "Iteration: 192/8000, Loss: 0.318576425314.\n",
      "Iteration: 193/8000, Loss: 0.316567838192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 194/8000, Loss: 0.314587205648.\n",
      "Iteration: 195/8000, Loss: 0.312675118446.\n",
      "Iteration: 196/8000, Loss: 0.3109562397.\n",
      "Iteration: 197/8000, Loss: 0.3089633286.\n",
      "Iteration: 198/8000, Loss: 0.306857407093.\n",
      "Iteration: 199/8000, Loss: 0.305147349834.\n",
      "Iteration: 200/8000, Loss: 0.303198933601.\n",
      "Iteration: 201/8000, Loss: 0.30124181509.\n",
      "Iteration: 202/8000, Loss: 0.299536049366.\n",
      "Iteration: 203/8000, Loss: 0.297545999289.\n",
      "Iteration: 204/8000, Loss: 0.295747935772.\n",
      "Iteration: 205/8000, Loss: 0.293989479542.\n",
      "Iteration: 206/8000, Loss: 0.292064845562.\n",
      "Iteration: 207/8000, Loss: 0.29038053751.\n",
      "Iteration: 208/8000, Loss: 0.288544774055.\n",
      "Iteration: 209/8000, Loss: 0.286758959293.\n",
      "Iteration: 210/8000, Loss: 0.285058140755.\n",
      "Iteration: 211/8000, Loss: 0.283224076033.\n",
      "Iteration: 212/8000, Loss: 0.281525611877.\n",
      "Iteration: 213/8000, Loss: 0.279828071594.\n",
      "Iteration: 214/8000, Loss: 0.27805569768.\n",
      "Iteration: 215/8000, Loss: 0.276367038488.\n",
      "Iteration: 216/8000, Loss: 0.274722099304.\n",
      "Iteration: 217/8000, Loss: 0.273016184568.\n",
      "Iteration: 218/8000, Loss: 0.271336734295.\n",
      "Iteration: 219/8000, Loss: 0.269742965698.\n",
      "Iteration: 220/8000, Loss: 0.268145799637.\n",
      "Iteration: 221/8000, Loss: 0.266543656588.\n",
      "Iteration: 222/8000, Loss: 0.264941573143.\n",
      "Iteration: 223/8000, Loss: 0.263381928205.\n",
      "Iteration: 224/8000, Loss: 0.261857479811.\n",
      "Iteration: 225/8000, Loss: 0.260355770588.\n",
      "Iteration: 226/8000, Loss: 0.258908063173.\n",
      "Iteration: 227/8000, Loss: 0.257463395596.\n",
      "Iteration: 228/8000, Loss: 0.256111681461.\n",
      "Iteration: 229/8000, Loss: 0.254513382912.\n",
      "Iteration: 230/8000, Loss: 0.252851903439.\n",
      "Iteration: 231/8000, Loss: 0.251085937023.\n",
      "Iteration: 232/8000, Loss: 0.249515369534.\n",
      "Iteration: 233/8000, Loss: 0.248102575541.\n",
      "Iteration: 234/8000, Loss: 0.24661333859.\n",
      "Iteration: 235/8000, Loss: 0.245054751635.\n",
      "Iteration: 236/8000, Loss: 0.243028640747.\n",
      "Iteration: 237/8000, Loss: 0.241198971868.\n",
      "Iteration: 238/8000, Loss: 0.239695459604.\n",
      "Iteration: 239/8000, Loss: 0.238299801946.\n",
      "Iteration: 240/8000, Loss: 0.236952573061.\n",
      "Iteration: 241/8000, Loss: 0.234993711114.\n",
      "Iteration: 242/8000, Loss: 0.233231335878.\n",
      "Iteration: 243/8000, Loss: 0.231950879097.\n",
      "Iteration: 244/8000, Loss: 0.230809152126.\n",
      "Iteration: 245/8000, Loss: 0.229562461376.\n",
      "Iteration: 246/8000, Loss: 0.227855563164.\n",
      "Iteration: 247/8000, Loss: 0.226502031088.\n",
      "Iteration: 248/8000, Loss: 0.225582152605.\n",
      "Iteration: 249/8000, Loss: 0.224404767156.\n",
      "Iteration: 250/8000, Loss: 0.223028883338.\n",
      "Iteration: 251/8000, Loss: 0.22179491818.\n",
      "Iteration: 252/8000, Loss: 0.22084158659.\n",
      "Iteration: 253/8000, Loss: 0.21985039115.\n",
      "Iteration: 254/8000, Loss: 0.218562990427.\n",
      "Iteration: 255/8000, Loss: 0.217440962791.\n",
      "Iteration: 256/8000, Loss: 0.216525524855.\n",
      "Iteration: 257/8000, Loss: 0.215443074703.\n",
      "Iteration: 258/8000, Loss: 0.214308977127.\n",
      "Iteration: 259/8000, Loss: 0.213320881128.\n",
      "Iteration: 260/8000, Loss: 0.212384462357.\n",
      "Iteration: 261/8000, Loss: 0.211355626583.\n",
      "Iteration: 262/8000, Loss: 0.210318177938.\n",
      "Iteration: 263/8000, Loss: 0.209405034781.\n",
      "Iteration: 264/8000, Loss: 0.208482772112.\n",
      "Iteration: 265/8000, Loss: 0.207471817732.\n",
      "Iteration: 266/8000, Loss: 0.206511348486.\n",
      "Iteration: 267/8000, Loss: 0.205612882972.\n",
      "Iteration: 268/8000, Loss: 0.204674869776.\n",
      "Iteration: 269/8000, Loss: 0.20370054245.\n",
      "Iteration: 270/8000, Loss: 0.202761918306.\n",
      "Iteration: 271/8000, Loss: 0.201849222183.\n",
      "Iteration: 272/8000, Loss: 0.200894534588.\n",
      "Iteration: 273/8000, Loss: 0.199917942286.\n",
      "Iteration: 274/8000, Loss: 0.198969885707.\n",
      "Iteration: 275/8000, Loss: 0.198038324714.\n",
      "Iteration: 276/8000, Loss: 0.197095215321.\n",
      "Iteration: 277/8000, Loss: 0.196153014898.\n",
      "Iteration: 278/8000, Loss: 0.195240423083.\n",
      "Iteration: 279/8000, Loss: 0.194340363145.\n",
      "Iteration: 280/8000, Loss: 0.193426430225.\n",
      "Iteration: 281/8000, Loss: 0.192498013377.\n",
      "Iteration: 282/8000, Loss: 0.191573053598.\n",
      "Iteration: 283/8000, Loss: 0.19065669179.\n",
      "Iteration: 284/8000, Loss: 0.189730152488.\n",
      "Iteration: 285/8000, Loss: 0.188787445426.\n",
      "Iteration: 286/8000, Loss: 0.187835335732.\n",
      "Iteration: 287/8000, Loss: 0.186886042356.\n",
      "Iteration: 288/8000, Loss: 0.185942858458.\n",
      "Iteration: 289/8000, Loss: 0.184998318553.\n",
      "Iteration: 290/8000, Loss: 0.184052050114.\n",
      "Iteration: 291/8000, Loss: 0.183104708791.\n",
      "Iteration: 292/8000, Loss: 0.182160541415.\n",
      "Iteration: 293/8000, Loss: 0.181218877435.\n",
      "Iteration: 294/8000, Loss: 0.180276438594.\n",
      "Iteration: 295/8000, Loss: 0.179332599044.\n",
      "Iteration: 296/8000, Loss: 0.178385227919.\n",
      "Iteration: 297/8000, Loss: 0.177436202765.\n",
      "Iteration: 298/8000, Loss: 0.176485747099.\n",
      "Iteration: 299/8000, Loss: 0.175534710288.\n",
      "Iteration: 300/8000, Loss: 0.174582794309.\n",
      "Iteration: 301/8000, Loss: 0.17362858355.\n",
      "Iteration: 302/8000, Loss: 0.172671735287.\n",
      "Iteration: 303/8000, Loss: 0.171710252762.\n",
      "Iteration: 304/8000, Loss: 0.170744553208.\n",
      "Iteration: 305/8000, Loss: 0.169773608446.\n",
      "Iteration: 306/8000, Loss: 0.168798923492.\n",
      "Iteration: 307/8000, Loss: 0.167826354504.\n",
      "Iteration: 308/8000, Loss: 0.166863620281.\n",
      "Iteration: 309/8000, Loss: 0.165959939361.\n",
      "Iteration: 310/8000, Loss: 0.165067225695.\n",
      "Iteration: 311/8000, Loss: 0.164285093546.\n",
      "Iteration: 312/8000, Loss: 0.163133099675.\n",
      "Iteration: 313/8000, Loss: 0.161863490939.\n",
      "Iteration: 314/8000, Loss: 0.160686194897.\n",
      "Iteration: 315/8000, Loss: 0.159809350967.\n",
      "Iteration: 316/8000, Loss: 0.159016519785.\n",
      "Iteration: 317/8000, Loss: 0.157860383391.\n",
      "Iteration: 318/8000, Loss: 0.156638354063.\n",
      "Iteration: 319/8000, Loss: 0.155656099319.\n",
      "Iteration: 320/8000, Loss: 0.154813572764.\n",
      "Iteration: 321/8000, Loss: 0.153844565153.\n",
      "Iteration: 322/8000, Loss: 0.152717828751.\n",
      "Iteration: 323/8000, Loss: 0.151788309216.\n",
      "Iteration: 324/8000, Loss: 0.150997132063.\n",
      "Iteration: 325/8000, Loss: 0.150032550097.\n",
      "Iteration: 326/8000, Loss: 0.149066865444.\n",
      "Iteration: 327/8000, Loss: 0.14827555418.\n",
      "Iteration: 328/8000, Loss: 0.147481799126.\n",
      "Iteration: 329/8000, Loss: 0.146622464061.\n",
      "Iteration: 330/8000, Loss: 0.145863816142.\n",
      "Iteration: 331/8000, Loss: 0.145173162222.\n",
      "Iteration: 332/8000, Loss: 0.144430369139.\n",
      "Iteration: 333/8000, Loss: 0.143755540252.\n",
      "Iteration: 334/8000, Loss: 0.143148079515.\n",
      "Iteration: 335/8000, Loss: 0.14250805974.\n",
      "Iteration: 336/8000, Loss: 0.141940310597.\n",
      "Iteration: 337/8000, Loss: 0.141401857138.\n",
      "Iteration: 338/8000, Loss: 0.140864774585.\n",
      "Iteration: 339/8000, Loss: 0.140393719077.\n",
      "Iteration: 340/8000, Loss: 0.13991881907.\n",
      "Iteration: 341/8000, Loss: 0.139491796494.\n",
      "Iteration: 342/8000, Loss: 0.139079675078.\n",
      "Iteration: 343/8000, Loss: 0.138694807887.\n",
      "Iteration: 344/8000, Loss: 0.138335585594.\n",
      "Iteration: 345/8000, Loss: 0.137993365526.\n",
      "Iteration: 346/8000, Loss: 0.137676358223.\n",
      "Iteration: 347/8000, Loss: 0.137372151017.\n",
      "Iteration: 348/8000, Loss: 0.13709102571.\n",
      "Iteration: 349/8000, Loss: 0.13682064414.\n",
      "Iteration: 350/8000, Loss: 0.136567592621.\n",
      "Iteration: 351/8000, Loss: 0.136327043176.\n",
      "Iteration: 352/8000, Loss: 0.136098310351.\n",
      "Iteration: 353/8000, Loss: 0.135882750154.\n",
      "Iteration: 354/8000, Loss: 0.135675042868.\n",
      "Iteration: 355/8000, Loss: 0.13548079133.\n",
      "Iteration: 356/8000, Loss: 0.13529202342.\n",
      "Iteration: 357/8000, Loss: 0.135115534067.\n",
      "Iteration: 358/8000, Loss: 0.134944558144.\n",
      "Iteration: 359/8000, Loss: 0.134782269597.\n",
      "Iteration: 360/8000, Loss: 0.134627401829.\n",
      "Iteration: 361/8000, Loss: 0.134478181601.\n",
      "Iteration: 362/8000, Loss: 0.13433688879.\n",
      "Iteration: 363/8000, Loss: 0.134199976921.\n",
      "Iteration: 364/8000, Loss: 0.134069696069.\n",
      "Iteration: 365/8000, Loss: 0.133944556117.\n",
      "Iteration: 366/8000, Loss: 0.133823752403.\n",
      "Iteration: 367/8000, Loss: 0.133708626032.\n",
      "Iteration: 368/8000, Loss: 0.133597105742.\n",
      "Iteration: 369/8000, Loss: 0.133490040898.\n",
      "Iteration: 370/8000, Loss: 0.133387133479.\n",
      "Iteration: 371/8000, Loss: 0.13328742981.\n",
      "Iteration: 372/8000, Loss: 0.13319170475.\n",
      "Iteration: 373/8000, Loss: 0.133099064231.\n",
      "Iteration: 374/8000, Loss: 0.133009433746.\n",
      "Iteration: 375/8000, Loss: 0.132923096418.\n",
      "Iteration: 376/8000, Loss: 0.132839277387.\n",
      "Iteration: 377/8000, Loss: 0.132758170366.\n",
      "Iteration: 378/8000, Loss: 0.132679760456.\n",
      "Iteration: 379/8000, Loss: 0.132603496313.\n",
      "Iteration: 380/8000, Loss: 0.132529616356.\n",
      "Iteration: 381/8000, Loss: 0.132457941771.\n",
      "Iteration: 382/8000, Loss: 0.132388174534.\n",
      "Iteration: 383/8000, Loss: 0.132320478559.\n",
      "Iteration: 384/8000, Loss: 0.132254630327.\n",
      "Iteration: 385/8000, Loss: 0.132190465927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 386/8000, Loss: 0.132128089666.\n",
      "Iteration: 387/8000, Loss: 0.132067322731.\n",
      "Iteration: 388/8000, Loss: 0.132008045912.\n",
      "Iteration: 389/8000, Loss: 0.131950303912.\n",
      "Iteration: 390/8000, Loss: 0.131893962622.\n",
      "Iteration: 391/8000, Loss: 0.131838932633.\n",
      "Iteration: 392/8000, Loss: 0.131785273552.\n",
      "Iteration: 393/8000, Loss: 0.131732836366.\n",
      "Iteration: 394/8000, Loss: 0.131681576371.\n",
      "Iteration: 395/8000, Loss: 0.13163150847.\n",
      "Iteration: 396/8000, Loss: 0.131582543254.\n",
      "Iteration: 397/8000, Loss: 0.131534606218.\n",
      "Iteration: 398/8000, Loss: 0.131487712264.\n",
      "Iteration: 399/8000, Loss: 0.131441831589.\n",
      "Iteration: 400/8000, Loss: 0.131396874785.\n",
      "Iteration: 401/8000, Loss: 0.131352841854.\n",
      "Iteration: 402/8000, Loss: 0.131309702992.\n",
      "Iteration: 403/8000, Loss: 0.131267428398.\n",
      "Iteration: 404/8000, Loss: 0.131225958467.\n",
      "Iteration: 405/8000, Loss: 0.131185278296.\n",
      "Iteration: 406/8000, Loss: 0.131145387888.\n",
      "Iteration: 407/8000, Loss: 0.131106242537.\n",
      "Iteration: 408/8000, Loss: 0.131067812443.\n",
      "Iteration: 409/8000, Loss: 0.131030082703.\n",
      "Iteration: 410/8000, Loss: 0.130993023515.\n",
      "Iteration: 411/8000, Loss: 0.130956619978.\n",
      "Iteration: 412/8000, Loss: 0.130920872092.\n",
      "Iteration: 413/8000, Loss: 0.130885705352.\n",
      "Iteration: 414/8000, Loss: 0.13085116446.\n",
      "Iteration: 415/8000, Loss: 0.130817204714.\n",
      "Iteration: 416/8000, Loss: 0.130783811212.\n",
      "Iteration: 417/8000, Loss: 0.130750954151.\n",
      "Iteration: 418/8000, Loss: 0.130718633533.\n",
      "Iteration: 419/8000, Loss: 0.130686849356.\n",
      "Iteration: 420/8000, Loss: 0.130655556917.\n",
      "Iteration: 421/8000, Loss: 0.130624771118.\n",
      "Iteration: 422/8000, Loss: 0.130594447255.\n",
      "Iteration: 423/8000, Loss: 0.130564600229.\n",
      "Iteration: 424/8000, Loss: 0.130535200238.\n",
      "Iteration: 425/8000, Loss: 0.130506247282.\n",
      "Iteration: 426/8000, Loss: 0.130477711558.\n",
      "Iteration: 427/8000, Loss: 0.130449622869.\n",
      "Iteration: 428/8000, Loss: 0.130421921611.\n",
      "Iteration: 429/8000, Loss: 0.130394637585.\n",
      "Iteration: 430/8000, Loss: 0.130367740989.\n",
      "Iteration: 431/8000, Loss: 0.130341216922.\n",
      "Iteration: 432/8000, Loss: 0.130315095186.\n",
      "Iteration: 433/8000, Loss: 0.130289316177.\n",
      "Iteration: 434/8000, Loss: 0.130263894796.\n",
      "Iteration: 435/8000, Loss: 0.130238831043.\n",
      "Iteration: 436/8000, Loss: 0.130214124918.\n",
      "Iteration: 437/8000, Loss: 0.130189731717.\n",
      "Iteration: 438/8000, Loss: 0.130165666342.\n",
      "Iteration: 439/8000, Loss: 0.130141913891.\n",
      "Iteration: 440/8000, Loss: 0.130118489265.\n",
      "Iteration: 441/8000, Loss: 0.130095377564.\n",
      "Iteration: 442/8000, Loss: 0.130072548985.\n",
      "Iteration: 443/8000, Loss: 0.130050033331.\n",
      "Iteration: 444/8000, Loss: 0.130027800798.\n",
      "Iteration: 445/8000, Loss: 0.130005836487.\n",
      "Iteration: 446/8000, Loss: 0.129984170198.\n",
      "Iteration: 447/8000, Loss: 0.129962772131.\n",
      "Iteration: 448/8000, Loss: 0.129941627383.\n",
      "Iteration: 449/8000, Loss: 0.129920780659.\n",
      "Iteration: 450/8000, Loss: 0.129900157452.\n",
      "Iteration: 451/8000, Loss: 0.129879802465.\n",
      "Iteration: 452/8000, Loss: 0.129859685898.\n",
      "Iteration: 453/8000, Loss: 0.12983982265.\n",
      "Iteration: 454/8000, Loss: 0.129820197821.\n",
      "Iteration: 455/8000, Loss: 0.129800796509.\n",
      "Iteration: 456/8000, Loss: 0.129781633615.\n",
      "Iteration: 457/8000, Loss: 0.12976269424.\n",
      "Iteration: 458/8000, Loss: 0.129743993282.\n",
      "Iteration: 459/8000, Loss: 0.129725500941.\n",
      "Iteration: 460/8000, Loss: 0.129707217216.\n",
      "Iteration: 461/8000, Loss: 0.129689157009.\n",
      "Iteration: 462/8000, Loss: 0.129671290517.\n",
      "Iteration: 463/8000, Loss: 0.129653632641.\n",
      "Iteration: 464/8000, Loss: 0.129636183381.\n",
      "Iteration: 465/8000, Loss: 0.129618912935.\n",
      "Iteration: 466/8000, Loss: 0.129601866007.\n",
      "Iteration: 467/8000, Loss: 0.129584997892.\n",
      "Iteration: 468/8000, Loss: 0.129568308592.\n",
      "Iteration: 469/8000, Loss: 0.129551813006.\n",
      "Iteration: 470/8000, Loss: 0.129535496235.\n",
      "Iteration: 471/8000, Loss: 0.129519358277.\n",
      "Iteration: 472/8000, Loss: 0.129503399134.\n",
      "Iteration: 473/8000, Loss: 0.129487618804.\n",
      "Iteration: 474/8000, Loss: 0.129472002387.\n",
      "Iteration: 475/8000, Loss: 0.129456549883.\n",
      "Iteration: 476/8000, Loss: 0.129441261292.\n",
      "Iteration: 477/8000, Loss: 0.129426151514.\n",
      "Iteration: 478/8000, Loss: 0.129411175847.\n",
      "Iteration: 479/8000, Loss: 0.129396364093.\n",
      "Iteration: 480/8000, Loss: 0.129381731153.\n",
      "Iteration: 481/8000, Loss: 0.129367232323.\n",
      "Iteration: 482/8000, Loss: 0.129352882504.\n",
      "Iteration: 483/8000, Loss: 0.129338681698.\n",
      "Iteration: 484/8000, Loss: 0.129324629903.\n",
      "Iteration: 485/8000, Loss: 0.129310727119.\n",
      "Iteration: 486/8000, Loss: 0.129296943545.\n",
      "Iteration: 487/8000, Loss: 0.129283323884.\n",
      "Iteration: 488/8000, Loss: 0.129269823432.\n",
      "Iteration: 489/8000, Loss: 0.12925645709.\n",
      "Iteration: 490/8000, Loss: 0.129243254662.\n",
      "Iteration: 491/8000, Loss: 0.12923014164.\n",
      "Iteration: 492/8000, Loss: 0.129217177629.\n",
      "Iteration: 493/8000, Loss: 0.12920434773.\n",
      "Iteration: 494/8000, Loss: 0.129191622138.\n",
      "Iteration: 495/8000, Loss: 0.129179030657.\n",
      "Iteration: 496/8000, Loss: 0.129166573286.\n",
      "Iteration: 497/8000, Loss: 0.129154205322.\n",
      "Iteration: 498/8000, Loss: 0.12914198637.\n",
      "Iteration: 499/8000, Loss: 0.129129856825.\n",
      "Iteration: 500/8000, Loss: 0.129117876291.\n",
      "Iteration: 501/8000, Loss: 0.129105985165.\n",
      "Iteration: 502/8000, Loss: 0.129094213247.\n",
      "Iteration: 503/8000, Loss: 0.129082530737.\n",
      "Iteration: 504/8000, Loss: 0.129070982337.\n",
      "Iteration: 505/8000, Loss: 0.129059523344.\n",
      "Iteration: 506/8000, Loss: 0.129048198462.\n",
      "Iteration: 507/8000, Loss: 0.129036933184.\n",
      "Iteration: 508/8000, Loss: 0.129025787115.\n",
      "Iteration: 509/8000, Loss: 0.129014760256.\n",
      "Iteration: 510/8000, Loss: 0.129003822803.\n",
      "Iteration: 511/8000, Loss: 0.128992974758.\n",
      "Iteration: 512/8000, Loss: 0.128982231021.\n",
      "Iteration: 513/8000, Loss: 0.128971576691.\n",
      "Iteration: 514/8000, Loss: 0.128961026669.\n",
      "Iteration: 515/8000, Loss: 0.128950566053.\n",
      "Iteration: 516/8000, Loss: 0.128940194845.\n",
      "Iteration: 517/8000, Loss: 0.128929913044.\n",
      "Iteration: 518/8000, Loss: 0.12891972065.\n",
      "Iteration: 519/8000, Loss: 0.128909617662.\n",
      "Iteration: 520/8000, Loss: 0.128899604082.\n",
      "Iteration: 521/8000, Loss: 0.128889679909.\n",
      "Iteration: 522/8000, Loss: 0.128879830241.\n",
      "Iteration: 523/8000, Loss: 0.128870069981.\n",
      "Iteration: 524/8000, Loss: 0.128860399127.\n",
      "Iteration: 525/8000, Loss: 0.12885081768.\n",
      "Iteration: 526/8000, Loss: 0.128841295838.\n",
      "Iteration: 527/8000, Loss: 0.128831863403.\n",
      "Iteration: 528/8000, Loss: 0.128822505474.\n",
      "Iteration: 529/8000, Loss: 0.128813222051.\n",
      "Iteration: 530/8000, Loss: 0.128804013133.\n",
      "Iteration: 531/8000, Loss: 0.128794893622.\n",
      "Iteration: 532/8000, Loss: 0.128785848618.\n",
      "Iteration: 533/8000, Loss: 0.128776863217.\n",
      "Iteration: 534/8000, Loss: 0.128767967224.\n",
      "Iteration: 535/8000, Loss: 0.128759130836.\n",
      "Iteration: 536/8000, Loss: 0.128750383854.\n",
      "Iteration: 537/8000, Loss: 0.128741681576.\n",
      "Iteration: 538/8000, Loss: 0.128733068705.\n",
      "Iteration: 539/8000, Loss: 0.128724515438.\n",
      "Iteration: 540/8000, Loss: 0.128716036677.\n",
      "Iteration: 541/8000, Loss: 0.128707617521.\n",
      "Iteration: 542/8000, Loss: 0.128699272871.\n",
      "Iteration: 543/8000, Loss: 0.128690987825.\n",
      "Iteration: 544/8000, Loss: 0.128682777286.\n",
      "Iteration: 545/8000, Loss: 0.12867462635.\n",
      "Iteration: 546/8000, Loss: 0.12866653502.\n",
      "Iteration: 547/8000, Loss: 0.128658503294.\n",
      "Iteration: 548/8000, Loss: 0.128650546074.\n",
      "Iteration: 549/8000, Loss: 0.128642633557.\n",
      "Iteration: 550/8000, Loss: 0.128634795547.\n",
      "Iteration: 551/8000, Loss: 0.128627002239.\n",
      "Iteration: 552/8000, Loss: 0.128619268537.\n",
      "Iteration: 553/8000, Loss: 0.128611624241.\n",
      "Iteration: 554/8000, Loss: 0.128604009748.\n",
      "Iteration: 555/8000, Loss: 0.128596454859.\n",
      "Iteration: 556/8000, Loss: 0.128588959575.\n",
      "Iteration: 557/8000, Loss: 0.128581523895.\n",
      "Iteration: 558/8000, Loss: 0.12857414782.\n",
      "Iteration: 559/8000, Loss: 0.128566816449.\n",
      "Iteration: 560/8000, Loss: 0.128559544683.\n",
      "Iteration: 561/8000, Loss: 0.12855233252.\n",
      "Iteration: 562/8000, Loss: 0.128545165062.\n",
      "Iteration: 563/8000, Loss: 0.128538042307.\n",
      "Iteration: 564/8000, Loss: 0.128530994058.\n",
      "Iteration: 565/8000, Loss: 0.128523975611.\n",
      "Iteration: 566/8000, Loss: 0.128517001867.\n",
      "Iteration: 567/8000, Loss: 0.128510117531.\n",
      "Iteration: 568/8000, Loss: 0.128503233194.\n",
      "Iteration: 569/8000, Loss: 0.128496438265.\n",
      "Iteration: 570/8000, Loss: 0.128489673138.\n",
      "Iteration: 571/8000, Loss: 0.128482952714.\n",
      "Iteration: 572/8000, Loss: 0.128476276994.\n",
      "Iteration: 573/8000, Loss: 0.128469675779.\n",
      "Iteration: 574/8000, Loss: 0.128463104367.\n",
      "Iteration: 575/8000, Loss: 0.128456562757.\n",
      "Iteration: 576/8000, Loss: 0.128450110555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 577/8000, Loss: 0.128443658352.\n",
      "Iteration: 578/8000, Loss: 0.128437265754.\n",
      "Iteration: 579/8000, Loss: 0.12843093276.\n",
      "Iteration: 580/8000, Loss: 0.128424629569.\n",
      "Iteration: 581/8000, Loss: 0.128418371081.\n",
      "Iteration: 582/8000, Loss: 0.128412157297.\n",
      "Iteration: 583/8000, Loss: 0.128405988216.\n",
      "Iteration: 584/8000, Loss: 0.128399848938.\n",
      "Iteration: 585/8000, Loss: 0.128393769264.\n",
      "Iteration: 586/8000, Loss: 0.128387719393.\n",
      "Iteration: 587/8000, Loss: 0.128381699324.\n",
      "Iteration: 588/8000, Loss: 0.128375738859.\n",
      "Iteration: 589/8000, Loss: 0.128369837999.\n",
      "Iteration: 590/8000, Loss: 0.12836393714.\n",
      "Iteration: 591/8000, Loss: 0.128358095884.\n",
      "Iteration: 592/8000, Loss: 0.128352284431.\n",
      "Iteration: 593/8000, Loss: 0.128346532583.\n",
      "Iteration: 594/8000, Loss: 0.128340780735.\n",
      "Iteration: 595/8000, Loss: 0.128335088491.\n",
      "Iteration: 596/8000, Loss: 0.128329440951.\n",
      "Iteration: 597/8000, Loss: 0.128323823214.\n",
      "Iteration: 598/8000, Loss: 0.128318235278.\n",
      "Iteration: 599/8000, Loss: 0.128312692046.\n",
      "Iteration: 600/8000, Loss: 0.128307178617.\n",
      "Iteration: 601/8000, Loss: 0.128301724792.\n",
      "Iteration: 602/8000, Loss: 0.128296285868.\n",
      "Iteration: 603/8000, Loss: 0.128290876746.\n",
      "Iteration: 604/8000, Loss: 0.128285512328.\n",
      "Iteration: 605/8000, Loss: 0.128280162811.\n",
      "Iteration: 606/8000, Loss: 0.128274872899.\n",
      "Iteration: 607/8000, Loss: 0.128269612789.\n",
      "Iteration: 608/8000, Loss: 0.12826436758.\n",
      "Iteration: 609/8000, Loss: 0.128259181976.\n",
      "Iteration: 610/8000, Loss: 0.128254026175.\n",
      "Iteration: 611/8000, Loss: 0.128248885274.\n",
      "Iteration: 612/8000, Loss: 0.128243789077.\n",
      "Iteration: 613/8000, Loss: 0.128238707781.\n",
      "Iteration: 614/8000, Loss: 0.128233656287.\n",
      "Iteration: 615/8000, Loss: 0.128228664398.\n",
      "Iteration: 616/8000, Loss: 0.128223702312.\n",
      "Iteration: 617/8000, Loss: 0.128218770027.\n",
      "Iteration: 618/8000, Loss: 0.128213852644.\n",
      "Iteration: 619/8000, Loss: 0.128208950162.\n",
      "Iteration: 620/8000, Loss: 0.128204107285.\n",
      "Iteration: 621/8000, Loss: 0.128199279308.\n",
      "Iteration: 622/8000, Loss: 0.128194496036.\n",
      "Iteration: 623/8000, Loss: 0.128189727664.\n",
      "Iteration: 624/8000, Loss: 0.128185003996.\n",
      "Iteration: 625/8000, Loss: 0.128180295229.\n",
      "Iteration: 626/8000, Loss: 0.128175601363.\n",
      "Iteration: 627/8000, Loss: 0.128170967102.\n",
      "Iteration: 628/8000, Loss: 0.128166347742.\n",
      "Iteration: 629/8000, Loss: 0.128161743283.\n",
      "Iteration: 630/8000, Loss: 0.128157183528.\n",
      "Iteration: 631/8000, Loss: 0.128152638674.\n",
      "Iteration: 632/8000, Loss: 0.128148123622.\n",
      "Iteration: 633/8000, Loss: 0.128143653274.\n",
      "Iteration: 634/8000, Loss: 0.128139182925.\n",
      "Iteration: 635/8000, Loss: 0.12813475728.\n",
      "Iteration: 636/8000, Loss: 0.128130346537.\n",
      "Iteration: 637/8000, Loss: 0.128125965595.\n",
      "Iteration: 638/8000, Loss: 0.128121599555.\n",
      "Iteration: 639/8000, Loss: 0.128117278218.\n",
      "Iteration: 640/8000, Loss: 0.128112986684.\n",
      "Iteration: 641/8000, Loss: 0.128108695149.\n",
      "Iteration: 642/8000, Loss: 0.128104448318.\n",
      "Iteration: 643/8000, Loss: 0.12810023129.\n",
      "Iteration: 644/8000, Loss: 0.128096014261.\n",
      "Iteration: 645/8000, Loss: 0.128091827035.\n",
      "Iteration: 646/8000, Loss: 0.128087669611.\n",
      "Iteration: 647/8000, Loss: 0.128083541989.\n",
      "Iteration: 648/8000, Loss: 0.128079414368.\n",
      "Iteration: 649/8000, Loss: 0.12807533145.\n",
      "Iteration: 650/8000, Loss: 0.128071278334.\n",
      "Iteration: 651/8000, Loss: 0.12806725502.\n",
      "Iteration: 652/8000, Loss: 0.128063231707.\n",
      "Iteration: 653/8000, Loss: 0.128059223294.\n",
      "Iteration: 654/8000, Loss: 0.128055259585.\n",
      "Iteration: 655/8000, Loss: 0.128051295877.\n",
      "Iteration: 656/8000, Loss: 0.128047376871.\n",
      "Iteration: 657/8000, Loss: 0.128043472767.\n",
      "Iteration: 658/8000, Loss: 0.128039598465.\n",
      "Iteration: 659/8000, Loss: 0.128035724163.\n",
      "Iteration: 660/8000, Loss: 0.128031894565.\n",
      "Iteration: 661/8000, Loss: 0.128028064966.\n",
      "Iteration: 662/8000, Loss: 0.12802426517.\n",
      "Iteration: 663/8000, Loss: 0.128020495176.\n",
      "Iteration: 664/8000, Loss: 0.128016725183.\n",
      "Iteration: 665/8000, Loss: 0.128012999892.\n",
      "Iteration: 666/8000, Loss: 0.128009274602.\n",
      "Iteration: 667/8000, Loss: 0.128005594015.\n",
      "Iteration: 668/8000, Loss: 0.128001898527.\n",
      "Iteration: 669/8000, Loss: 0.127998247743.\n",
      "Iteration: 670/8000, Loss: 0.127994611859.\n",
      "Iteration: 671/8000, Loss: 0.127991005778.\n",
      "Iteration: 672/8000, Loss: 0.127987414598.\n",
      "Iteration: 673/8000, Loss: 0.127983823419.\n",
      "Iteration: 674/8000, Loss: 0.127980276942.\n",
      "Iteration: 675/8000, Loss: 0.127976715565.\n",
      "Iteration: 676/8000, Loss: 0.127973213792.\n",
      "Iteration: 677/8000, Loss: 0.127969712019.\n",
      "Iteration: 678/8000, Loss: 0.127966225147.\n",
      "Iteration: 679/8000, Loss: 0.127962768078.\n",
      "Iteration: 680/8000, Loss: 0.127959311008.\n",
      "Iteration: 681/8000, Loss: 0.127955883741.\n",
      "Iteration: 682/8000, Loss: 0.127952486277.\n",
      "Iteration: 683/8000, Loss: 0.127949088812.\n",
      "Iteration: 684/8000, Loss: 0.127945721149.\n",
      "Iteration: 685/8000, Loss: 0.127942353487.\n",
      "Iteration: 686/8000, Loss: 0.127939015627.\n",
      "Iteration: 687/8000, Loss: 0.127935692668.\n",
      "Iteration: 688/8000, Loss: 0.127932399511.\n",
      "Iteration: 689/8000, Loss: 0.127929091454.\n",
      "Iteration: 690/8000, Loss: 0.127925828099.\n",
      "Iteration: 691/8000, Loss: 0.127922579646.\n",
      "Iteration: 692/8000, Loss: 0.127919331193.\n",
      "Iteration: 693/8000, Loss: 0.127916097641.\n",
      "Iteration: 694/8000, Loss: 0.127912908792.\n",
      "Iteration: 695/8000, Loss: 0.127909719944.\n",
      "Iteration: 696/8000, Loss: 0.127906545997.\n",
      "Iteration: 697/8000, Loss: 0.127903416753.\n",
      "Iteration: 698/8000, Loss: 0.127900257707.\n",
      "Iteration: 699/8000, Loss: 0.127897143364.\n",
      "Iteration: 700/8000, Loss: 0.12789401412.\n",
      "Iteration: 701/8000, Loss: 0.12789092958.\n",
      "Iteration: 702/8000, Loss: 0.127887845039.\n",
      "Iteration: 703/8000, Loss: 0.127884790301.\n",
      "Iteration: 704/8000, Loss: 0.127881765366.\n",
      "Iteration: 705/8000, Loss: 0.127878725529.\n",
      "Iteration: 706/8000, Loss: 0.127875715494.\n",
      "Iteration: 707/8000, Loss: 0.12787270546.\n",
      "Iteration: 708/8000, Loss: 0.127869725227.\n",
      "Iteration: 709/8000, Loss: 0.127866744995.\n",
      "Iteration: 710/8000, Loss: 0.127863794565.\n",
      "Iteration: 711/8000, Loss: 0.127860859036.\n",
      "Iteration: 712/8000, Loss: 0.127857923508.\n",
      "Iteration: 713/8000, Loss: 0.127855017781.\n",
      "Iteration: 714/8000, Loss: 0.127852126956.\n",
      "Iteration: 715/8000, Loss: 0.127849236131.\n",
      "Iteration: 716/8000, Loss: 0.127846360207.\n",
      "Iteration: 717/8000, Loss: 0.127843514085.\n",
      "Iteration: 718/8000, Loss: 0.127840682864.\n",
      "Iteration: 719/8000, Loss: 0.127837836742.\n",
      "Iteration: 720/8000, Loss: 0.127835035324.\n",
      "Iteration: 721/8000, Loss: 0.127832233906.\n",
      "Iteration: 722/8000, Loss: 0.127829432487.\n",
      "Iteration: 723/8000, Loss: 0.127826660872.\n",
      "Iteration: 724/8000, Loss: 0.127823904157.\n",
      "Iteration: 725/8000, Loss: 0.127821177244.\n",
      "Iteration: 726/8000, Loss: 0.127818435431.\n",
      "Iteration: 727/8000, Loss: 0.127815708518.\n",
      "Iteration: 728/8000, Loss: 0.127812981606.\n",
      "Iteration: 729/8000, Loss: 0.127810299397.\n",
      "Iteration: 730/8000, Loss: 0.127807617188.\n",
      "Iteration: 731/8000, Loss: 0.12780494988.\n",
      "Iteration: 732/8000, Loss: 0.127802282572.\n",
      "Iteration: 733/8000, Loss: 0.127799645066.\n",
      "Iteration: 734/8000, Loss: 0.127797022462.\n",
      "Iteration: 735/8000, Loss: 0.127794384956.\n",
      "Iteration: 736/8000, Loss: 0.127791792154.\n",
      "Iteration: 737/8000, Loss: 0.127789199352.\n",
      "Iteration: 738/8000, Loss: 0.12778660655.\n",
      "Iteration: 739/8000, Loss: 0.127784028649.\n",
      "Iteration: 740/8000, Loss: 0.127781480551.\n",
      "Iteration: 741/8000, Loss: 0.127778917551.\n",
      "Iteration: 742/8000, Loss: 0.127776399255.\n",
      "Iteration: 743/8000, Loss: 0.127773866057.\n",
      "Iteration: 744/8000, Loss: 0.127771347761.\n",
      "Iteration: 745/8000, Loss: 0.127768844366.\n",
      "Iteration: 746/8000, Loss: 0.127766355872.\n",
      "Iteration: 747/8000, Loss: 0.127763882279.\n",
      "Iteration: 748/8000, Loss: 0.127761408687.\n",
      "Iteration: 749/8000, Loss: 0.127758964896.\n",
      "Iteration: 750/8000, Loss: 0.127756521106.\n",
      "Iteration: 751/8000, Loss: 0.127754092216.\n",
      "Iteration: 752/8000, Loss: 0.127751648426.\n",
      "Iteration: 753/8000, Loss: 0.127749249339.\n",
      "Iteration: 754/8000, Loss: 0.127746850252.\n",
      "Iteration: 755/8000, Loss: 0.127744466066.\n",
      "Iteration: 756/8000, Loss: 0.127742081881.\n",
      "Iteration: 757/8000, Loss: 0.127739712596.\n",
      "Iteration: 758/8000, Loss: 0.127737358212.\n",
      "Iteration: 759/8000, Loss: 0.127735003829.\n",
      "Iteration: 760/8000, Loss: 0.127732679248.\n",
      "Iteration: 761/8000, Loss: 0.127730339766.\n",
      "Iteration: 762/8000, Loss: 0.127728030086.\n",
      "Iteration: 763/8000, Loss: 0.127725720406.\n",
      "Iteration: 764/8000, Loss: 0.127723425627.\n",
      "Iteration: 765/8000, Loss: 0.127721145749.\n",
      "Iteration: 766/8000, Loss: 0.127718865871.\n",
      "Iteration: 767/8000, Loss: 0.127716600895.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 768/8000, Loss: 0.127714335918.\n",
      "Iteration: 769/8000, Loss: 0.127712115645.\n",
      "Iteration: 770/8000, Loss: 0.12770986557.\n",
      "Iteration: 771/8000, Loss: 0.127707630396.\n",
      "Iteration: 772/8000, Loss: 0.127705425024.\n",
      "Iteration: 773/8000, Loss: 0.127703219652.\n",
      "Iteration: 774/8000, Loss: 0.127701029181.\n",
      "Iteration: 775/8000, Loss: 0.127698838711.\n",
      "Iteration: 776/8000, Loss: 0.127696663141.\n",
      "Iteration: 777/8000, Loss: 0.127694487572.\n",
      "Iteration: 778/8000, Loss: 0.127692326903.\n",
      "Iteration: 779/8000, Loss: 0.127690181136.\n",
      "Iteration: 780/8000, Loss: 0.127688035369.\n",
      "Iteration: 781/8000, Loss: 0.127685904503.\n",
      "Iteration: 782/8000, Loss: 0.127683773637.\n",
      "Iteration: 783/8000, Loss: 0.127681672573.\n",
      "Iteration: 784/8000, Loss: 0.127679571509.\n",
      "Iteration: 785/8000, Loss: 0.127677485347.\n",
      "Iteration: 786/8000, Loss: 0.127675384283.\n",
      "Iteration: 787/8000, Loss: 0.12767329812.\n",
      "Iteration: 788/8000, Loss: 0.12767124176.\n",
      "Iteration: 789/8000, Loss: 0.1276691854.\n",
      "Iteration: 790/8000, Loss: 0.12766712904.\n",
      "Iteration: 791/8000, Loss: 0.127665087581.\n",
      "Iteration: 792/8000, Loss: 0.127663046122.\n",
      "Iteration: 793/8000, Loss: 0.127661019564.\n",
      "Iteration: 794/8000, Loss: 0.127659007907.\n",
      "Iteration: 795/8000, Loss: 0.12765699625.\n",
      "Iteration: 796/8000, Loss: 0.127654999495.\n",
      "Iteration: 797/8000, Loss: 0.127653002739.\n",
      "Iteration: 798/8000, Loss: 0.127651035786.\n",
      "Iteration: 799/8000, Loss: 0.12764903903.\n",
      "Iteration: 800/8000, Loss: 0.127647072077.\n",
      "Iteration: 801/8000, Loss: 0.127645120025.\n",
      "Iteration: 802/8000, Loss: 0.127643167973.\n",
      "Iteration: 803/8000, Loss: 0.12764121592.\n",
      "Iteration: 804/8000, Loss: 0.127639293671.\n",
      "Iteration: 805/8000, Loss: 0.12763735652.\n",
      "Iteration: 806/8000, Loss: 0.12763543427.\n",
      "Iteration: 807/8000, Loss: 0.127633526921.\n",
      "Iteration: 808/8000, Loss: 0.127631634474.\n",
      "Iteration: 809/8000, Loss: 0.127629727125.\n",
      "Iteration: 810/8000, Loss: 0.127627849579.\n",
      "Iteration: 811/8000, Loss: 0.127625972033.\n",
      "Iteration: 812/8000, Loss: 0.127624094486.\n",
      "Iteration: 813/8000, Loss: 0.12762221694.\n",
      "Iteration: 814/8000, Loss: 0.127620369196.\n",
      "Iteration: 815/8000, Loss: 0.127618521452.\n",
      "Iteration: 816/8000, Loss: 0.127616673708.\n",
      "Iteration: 817/8000, Loss: 0.127614840865.\n",
      "Iteration: 818/8000, Loss: 0.127613008022.\n",
      "Iteration: 819/8000, Loss: 0.127611190081.\n",
      "Iteration: 820/8000, Loss: 0.127609372139.\n",
      "Iteration: 821/8000, Loss: 0.127607569098.\n",
      "Iteration: 822/8000, Loss: 0.127605766058.\n",
      "Iteration: 823/8000, Loss: 0.127603977919.\n",
      "Iteration: 824/8000, Loss: 0.12760220468.\n",
      "Iteration: 825/8000, Loss: 0.127600416541.\n",
      "Iteration: 826/8000, Loss: 0.127598643303.\n",
      "Iteration: 827/8000, Loss: 0.127596884966.\n",
      "Iteration: 828/8000, Loss: 0.127595126629.\n",
      "Iteration: 829/8000, Loss: 0.127593368292.\n",
      "Iteration: 830/8000, Loss: 0.127591639757.\n",
      "Iteration: 831/8000, Loss: 0.127589896321.\n",
      "Iteration: 832/8000, Loss: 0.127588152885.\n",
      "Iteration: 833/8000, Loss: 0.127586439252.\n",
      "Iteration: 834/8000, Loss: 0.127584725618.\n",
      "Iteration: 835/8000, Loss: 0.127583026886.\n",
      "Iteration: 836/8000, Loss: 0.127581313252.\n",
      "Iteration: 837/8000, Loss: 0.12757961452.\n",
      "Iteration: 838/8000, Loss: 0.127577930689.\n",
      "Iteration: 839/8000, Loss: 0.127576246858.\n",
      "Iteration: 840/8000, Loss: 0.127574563026.\n",
      "Iteration: 841/8000, Loss: 0.127572894096.\n",
      "Iteration: 842/8000, Loss: 0.127571254969.\n",
      "Iteration: 843/8000, Loss: 0.127569571137.\n",
      "Iteration: 844/8000, Loss: 0.127567917109.\n",
      "Iteration: 845/8000, Loss: 0.127566277981.\n",
      "Iteration: 846/8000, Loss: 0.127564653754.\n",
      "Iteration: 847/8000, Loss: 0.127563014627.\n",
      "Iteration: 848/8000, Loss: 0.1275613904.\n",
      "Iteration: 849/8000, Loss: 0.127559766173.\n",
      "Iteration: 850/8000, Loss: 0.127558156848.\n",
      "Iteration: 851/8000, Loss: 0.127556562424.\n",
      "Iteration: 852/8000, Loss: 0.127554953098.\n",
      "Iteration: 853/8000, Loss: 0.127553343773.\n",
      "Iteration: 854/8000, Loss: 0.127551749349.\n",
      "Iteration: 855/8000, Loss: 0.127550184727.\n",
      "Iteration: 856/8000, Loss: 0.127548605204.\n",
      "Iteration: 857/8000, Loss: 0.127547025681.\n",
      "Iteration: 858/8000, Loss: 0.12754547596.\n",
      "Iteration: 859/8000, Loss: 0.127543896437.\n",
      "Iteration: 860/8000, Loss: 0.127542346716.\n",
      "Iteration: 861/8000, Loss: 0.127540796995.\n",
      "Iteration: 862/8000, Loss: 0.127539247274.\n",
      "Iteration: 863/8000, Loss: 0.127537712455.\n",
      "Iteration: 864/8000, Loss: 0.127536192536.\n",
      "Iteration: 865/8000, Loss: 0.127534657717.\n",
      "Iteration: 866/8000, Loss: 0.127533152699.\n",
      "Iteration: 867/8000, Loss: 0.127531647682.\n",
      "Iteration: 868/8000, Loss: 0.127530127764.\n",
      "Iteration: 869/8000, Loss: 0.127528622746.\n",
      "Iteration: 870/8000, Loss: 0.127527117729.\n",
      "Iteration: 871/8000, Loss: 0.127525627613.\n",
      "Iteration: 872/8000, Loss: 0.127524152398.\n",
      "Iteration: 873/8000, Loss: 0.127522677183.\n",
      "Iteration: 874/8000, Loss: 0.127521187067.\n",
      "Iteration: 875/8000, Loss: 0.127519726753.\n",
      "Iteration: 876/8000, Loss: 0.127518266439.\n",
      "Iteration: 877/8000, Loss: 0.127516806126.\n",
      "Iteration: 878/8000, Loss: 0.127515360713.\n",
      "Iteration: 879/8000, Loss: 0.1275139153.\n",
      "Iteration: 880/8000, Loss: 0.127512454987.\n",
      "Iteration: 881/8000, Loss: 0.127511024475.\n",
      "Iteration: 882/8000, Loss: 0.127509579062.\n",
      "Iteration: 883/8000, Loss: 0.127508163452.\n",
      "Iteration: 884/8000, Loss: 0.127506732941.\n",
      "Iteration: 885/8000, Loss: 0.12750531733.\n",
      "Iteration: 886/8000, Loss: 0.12750390172.\n",
      "Iteration: 887/8000, Loss: 0.12750248611.\n",
      "Iteration: 888/8000, Loss: 0.127501085401.\n",
      "Iteration: 889/8000, Loss: 0.127499699593.\n",
      "Iteration: 890/8000, Loss: 0.127498298883.\n",
      "Iteration: 891/8000, Loss: 0.127496913075.\n",
      "Iteration: 892/8000, Loss: 0.127495527267.\n",
      "Iteration: 893/8000, Loss: 0.127494156361.\n",
      "Iteration: 894/8000, Loss: 0.127492785454.\n",
      "Iteration: 895/8000, Loss: 0.127491414547.\n",
      "Iteration: 896/8000, Loss: 0.127490058541.\n",
      "Iteration: 897/8000, Loss: 0.127488702536.\n",
      "Iteration: 898/8000, Loss: 0.127487361431.\n",
      "Iteration: 899/8000, Loss: 0.127485990524.\n",
      "Iteration: 900/8000, Loss: 0.12748464942.\n",
      "Iteration: 901/8000, Loss: 0.127483323216.\n",
      "Iteration: 902/8000, Loss: 0.127481982112.\n",
      "Iteration: 903/8000, Loss: 0.127480655909.\n",
      "Iteration: 904/8000, Loss: 0.127479314804.\n",
      "Iteration: 905/8000, Loss: 0.127478003502.\n",
      "Iteration: 906/8000, Loss: 0.1274766922.\n",
      "Iteration: 907/8000, Loss: 0.127475380898.\n",
      "Iteration: 908/8000, Loss: 0.127474069595.\n",
      "Iteration: 909/8000, Loss: 0.127472773194.\n",
      "Iteration: 910/8000, Loss: 0.127471476793.\n",
      "Iteration: 911/8000, Loss: 0.127470195293.\n",
      "Iteration: 912/8000, Loss: 0.127468913794.\n",
      "Iteration: 913/8000, Loss: 0.127467617393.\n",
      "Iteration: 914/8000, Loss: 0.127466350794.\n",
      "Iteration: 915/8000, Loss: 0.127465069294.\n",
      "Iteration: 916/8000, Loss: 0.127463787794.\n",
      "Iteration: 917/8000, Loss: 0.127462536097.\n",
      "Iteration: 918/8000, Loss: 0.127461269498.\n",
      "Iteration: 919/8000, Loss: 0.1274600178.\n",
      "Iteration: 920/8000, Loss: 0.127458751202.\n",
      "Iteration: 921/8000, Loss: 0.127457499504.\n",
      "Iteration: 922/8000, Loss: 0.127456277609.\n",
      "Iteration: 923/8000, Loss: 0.127455025911.\n",
      "Iteration: 924/8000, Loss: 0.127453789115.\n",
      "Iteration: 925/8000, Loss: 0.127452552319.\n",
      "Iteration: 926/8000, Loss: 0.127451330423.\n",
      "Iteration: 927/8000, Loss: 0.127450108528.\n",
      "Iteration: 928/8000, Loss: 0.127448901534.\n",
      "Iteration: 929/8000, Loss: 0.127447679639.\n",
      "Iteration: 930/8000, Loss: 0.127446457744.\n",
      "Iteration: 931/8000, Loss: 0.12744525075.\n",
      "Iteration: 932/8000, Loss: 0.127444058657.\n",
      "Iteration: 933/8000, Loss: 0.127442866564.\n",
      "Iteration: 934/8000, Loss: 0.127441674471.\n",
      "Iteration: 935/8000, Loss: 0.127440482378.\n",
      "Iteration: 936/8000, Loss: 0.127439290285.\n",
      "Iteration: 937/8000, Loss: 0.127438113093.\n",
      "Iteration: 938/8000, Loss: 0.127436935902.\n",
      "Iteration: 939/8000, Loss: 0.12743575871.\n",
      "Iteration: 940/8000, Loss: 0.127434581518.\n",
      "Iteration: 941/8000, Loss: 0.127433434129.\n",
      "Iteration: 942/8000, Loss: 0.127432271838.\n",
      "Iteration: 943/8000, Loss: 0.127431109548.\n",
      "Iteration: 944/8000, Loss: 0.127429962158.\n",
      "Iteration: 945/8000, Loss: 0.127428814769.\n",
      "Iteration: 946/8000, Loss: 0.127427667379.\n",
      "Iteration: 947/8000, Loss: 0.12742651999.\n",
      "Iteration: 948/8000, Loss: 0.127425387502.\n",
      "Iteration: 949/8000, Loss: 0.127424240112.\n",
      "Iteration: 950/8000, Loss: 0.127423107624.\n",
      "Iteration: 951/8000, Loss: 0.127421990037.\n",
      "Iteration: 952/8000, Loss: 0.127420857549.\n",
      "Iteration: 953/8000, Loss: 0.127419739962.\n",
      "Iteration: 954/8000, Loss: 0.127418637276.\n",
      "Iteration: 955/8000, Loss: 0.127417519689.\n",
      "Iteration: 956/8000, Loss: 0.127416417003.\n",
      "Iteration: 957/8000, Loss: 0.127415299416.\n",
      "Iteration: 958/8000, Loss: 0.12741419673.\n",
      "Iteration: 959/8000, Loss: 0.127413094044.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 960/8000, Loss: 0.127412006259.\n",
      "Iteration: 961/8000, Loss: 0.127410918474.\n",
      "Iteration: 962/8000, Loss: 0.127409830689.\n",
      "Iteration: 963/8000, Loss: 0.127408757806.\n",
      "Iteration: 964/8000, Loss: 0.127407670021.\n",
      "Iteration: 965/8000, Loss: 0.127406597137.\n",
      "Iteration: 966/8000, Loss: 0.127405524254.\n",
      "Iteration: 967/8000, Loss: 0.12740445137.\n",
      "Iteration: 968/8000, Loss: 0.127403393388.\n",
      "Iteration: 969/8000, Loss: 0.127402320504.\n",
      "Iteration: 970/8000, Loss: 0.127401262522.\n",
      "Iteration: 971/8000, Loss: 0.12740021944.\n",
      "Iteration: 972/8000, Loss: 0.127399176359.\n",
      "Iteration: 973/8000, Loss: 0.127398133278.\n",
      "Iteration: 974/8000, Loss: 0.127397075295.\n",
      "Iteration: 975/8000, Loss: 0.127396047115.\n",
      "Iteration: 976/8000, Loss: 0.127395004034.\n",
      "Iteration: 977/8000, Loss: 0.127393960953.\n",
      "Iteration: 978/8000, Loss: 0.127392932773.\n",
      "Iteration: 979/8000, Loss: 0.127391904593.\n",
      "Iteration: 980/8000, Loss: 0.127390891314.\n",
      "Iteration: 981/8000, Loss: 0.127389863133.\n",
      "Iteration: 982/8000, Loss: 0.127388849854.\n",
      "Iteration: 983/8000, Loss: 0.127387821674.\n",
      "Iteration: 984/8000, Loss: 0.127386823297.\n",
      "Iteration: 985/8000, Loss: 0.127385824919.\n",
      "Iteration: 986/8000, Loss: 0.127384796739.\n",
      "Iteration: 987/8000, Loss: 0.127383813262.\n",
      "Iteration: 988/8000, Loss: 0.127382814884.\n",
      "Iteration: 989/8000, Loss: 0.127381816506.\n",
      "Iteration: 990/8000, Loss: 0.12738083303.\n",
      "Iteration: 991/8000, Loss: 0.127379834652.\n",
      "Iteration: 992/8000, Loss: 0.127378851175.\n",
      "Iteration: 993/8000, Loss: 0.127377867699.\n",
      "Iteration: 994/8000, Loss: 0.127376899123.\n",
      "Iteration: 995/8000, Loss: 0.127375915647.\n",
      "Iteration: 996/8000, Loss: 0.127374947071.\n",
      "Iteration: 997/8000, Loss: 0.127373993397.\n",
      "Iteration: 998/8000, Loss: 0.127373024821.\n",
      "Iteration: 999/8000, Loss: 0.127372056246.\n",
      "Iteration: 1000/8000, Loss: 0.127371102571.\n",
      "Iteration: 1001/8000, Loss: 0.127370148897.\n",
      "Iteration: 1002/8000, Loss: 0.127369180322.\n",
      "Iteration: 1003/8000, Loss: 0.127368226647.\n",
      "Iteration: 1004/8000, Loss: 0.127367287874.\n",
      "Iteration: 1005/8000, Loss: 0.1273663342.\n",
      "Iteration: 1006/8000, Loss: 0.127365410328.\n",
      "Iteration: 1007/8000, Loss: 0.127364471555.\n",
      "Iteration: 1008/8000, Loss: 0.12736351788.\n",
      "Iteration: 1009/8000, Loss: 0.127362594008.\n",
      "Iteration: 1010/8000, Loss: 0.127361655235.\n",
      "Iteration: 1011/8000, Loss: 0.127360746264.\n",
      "Iteration: 1012/8000, Loss: 0.127359807491.\n",
      "Iteration: 1013/8000, Loss: 0.127358883619.\n",
      "Iteration: 1014/8000, Loss: 0.12735798955.\n",
      "Iteration: 1015/8000, Loss: 0.127357065678.\n",
      "Iteration: 1016/8000, Loss: 0.127356141806.\n",
      "Iteration: 1017/8000, Loss: 0.127355247736.\n",
      "Iteration: 1018/8000, Loss: 0.127354338765.\n",
      "Iteration: 1019/8000, Loss: 0.127353429794.\n",
      "Iteration: 1020/8000, Loss: 0.127352535725.\n",
      "Iteration: 1021/8000, Loss: 0.127351626754.\n",
      "Iteration: 1022/8000, Loss: 0.127350747585.\n",
      "Iteration: 1023/8000, Loss: 0.127349853516.\n",
      "Iteration: 1024/8000, Loss: 0.127348959446.\n",
      "Iteration: 1025/8000, Loss: 0.127348065376.\n",
      "Iteration: 1026/8000, Loss: 0.127347186208.\n",
      "Iteration: 1027/8000, Loss: 0.127346307039.\n",
      "Iteration: 1028/8000, Loss: 0.127345442772.\n",
      "Iteration: 1029/8000, Loss: 0.127344563603.\n",
      "Iteration: 1030/8000, Loss: 0.127343684435.\n",
      "Iteration: 1031/8000, Loss: 0.127342820168.\n",
      "Iteration: 1032/8000, Loss: 0.1273419559.\n",
      "Iteration: 1033/8000, Loss: 0.127341076732.\n",
      "Iteration: 1034/8000, Loss: 0.127340227365.\n",
      "Iteration: 1035/8000, Loss: 0.127339363098.\n",
      "Iteration: 1036/8000, Loss: 0.127338513732.\n",
      "Iteration: 1037/8000, Loss: 0.127337664366.\n",
      "Iteration: 1038/8000, Loss: 0.127336800098.\n",
      "Iteration: 1039/8000, Loss: 0.127335965633.\n",
      "Iteration: 1040/8000, Loss: 0.127335116267.\n",
      "Iteration: 1041/8000, Loss: 0.127334281802.\n",
      "Iteration: 1042/8000, Loss: 0.127333432436.\n",
      "Iteration: 1043/8000, Loss: 0.127332597971.\n",
      "Iteration: 1044/8000, Loss: 0.127331763506.\n",
      "Iteration: 1045/8000, Loss: 0.127330929041.\n",
      "Iteration: 1046/8000, Loss: 0.127330094576.\n",
      "Iteration: 1047/8000, Loss: 0.127329260111.\n",
      "Iteration: 1048/8000, Loss: 0.127328440547.\n",
      "Iteration: 1049/8000, Loss: 0.127327620983.\n",
      "Iteration: 1050/8000, Loss: 0.127326801419.\n",
      "Iteration: 1051/8000, Loss: 0.127325981855.\n",
      "Iteration: 1052/8000, Loss: 0.127325162292.\n",
      "Iteration: 1053/8000, Loss: 0.127324357629.\n",
      "Iteration: 1054/8000, Loss: 0.127323538065.\n",
      "Iteration: 1055/8000, Loss: 0.127322733402.\n",
      "Iteration: 1056/8000, Loss: 0.127321943641.\n",
      "Iteration: 1057/8000, Loss: 0.127321124077.\n",
      "Iteration: 1058/8000, Loss: 0.127320334315.\n",
      "Iteration: 1059/8000, Loss: 0.127319544554.\n",
      "Iteration: 1060/8000, Loss: 0.127318739891.\n",
      "Iteration: 1061/8000, Loss: 0.12731795013.\n",
      "Iteration: 1062/8000, Loss: 0.127317145467.\n",
      "Iteration: 1063/8000, Loss: 0.127316385508.\n",
      "Iteration: 1064/8000, Loss: 0.127315580845.\n",
      "Iteration: 1065/8000, Loss: 0.127314805984.\n",
      "Iteration: 1066/8000, Loss: 0.127314031124.\n",
      "Iteration: 1067/8000, Loss: 0.127313241363.\n",
      "Iteration: 1068/8000, Loss: 0.127312466502.\n",
      "Iteration: 1069/8000, Loss: 0.127311676741.\n",
      "Iteration: 1070/8000, Loss: 0.127310916781.\n",
      "Iteration: 1071/8000, Loss: 0.127310156822.\n",
      "Iteration: 1072/8000, Loss: 0.127309381962.\n",
      "Iteration: 1073/8000, Loss: 0.127308622003.\n",
      "Iteration: 1074/8000, Loss: 0.127307862043.\n",
      "Iteration: 1075/8000, Loss: 0.127307087183.\n",
      "Iteration: 1076/8000, Loss: 0.127306342125.\n",
      "Iteration: 1077/8000, Loss: 0.127305597067.\n",
      "Iteration: 1078/8000, Loss: 0.127304822206.\n",
      "Iteration: 1079/8000, Loss: 0.12730409205.\n",
      "Iteration: 1080/8000, Loss: 0.12730333209.\n",
      "Iteration: 1081/8000, Loss: 0.127302587032.\n",
      "Iteration: 1082/8000, Loss: 0.127301841974.\n",
      "Iteration: 1083/8000, Loss: 0.127301111817.\n",
      "Iteration: 1084/8000, Loss: 0.127300366759.\n",
      "Iteration: 1085/8000, Loss: 0.127299621701.\n",
      "Iteration: 1086/8000, Loss: 0.127298891544.\n",
      "Iteration: 1087/8000, Loss: 0.127298161387.\n",
      "Iteration: 1088/8000, Loss: 0.127297431231.\n",
      "Iteration: 1089/8000, Loss: 0.127296701074.\n",
      "Iteration: 1090/8000, Loss: 0.127295970917.\n",
      "Iteration: 1091/8000, Loss: 0.127295255661.\n",
      "Iteration: 1092/8000, Loss: 0.127294525504.\n",
      "Iteration: 1093/8000, Loss: 0.127293810248.\n",
      "Iteration: 1094/8000, Loss: 0.127293080091.\n",
      "Iteration: 1095/8000, Loss: 0.127292364836.\n",
      "Iteration: 1096/8000, Loss: 0.127291664481.\n",
      "Iteration: 1097/8000, Loss: 0.127290934324.\n",
      "Iteration: 1098/8000, Loss: 0.127290248871.\n",
      "Iteration: 1099/8000, Loss: 0.127289533615.\n",
      "Iteration: 1100/8000, Loss: 0.127288818359.\n",
      "Iteration: 1101/8000, Loss: 0.127288103104.\n",
      "Iteration: 1102/8000, Loss: 0.12728741765.\n",
      "Iteration: 1103/8000, Loss: 0.127286717296.\n",
      "Iteration: 1104/8000, Loss: 0.127286031842.\n",
      "Iteration: 1105/8000, Loss: 0.127285331488.\n",
      "Iteration: 1106/8000, Loss: 0.127284646034.\n",
      "Iteration: 1107/8000, Loss: 0.127283930779.\n",
      "Iteration: 1108/8000, Loss: 0.127283260226.\n",
      "Iteration: 1109/8000, Loss: 0.127282574773.\n",
      "Iteration: 1110/8000, Loss: 0.127281889319.\n",
      "Iteration: 1111/8000, Loss: 0.127281203866.\n",
      "Iteration: 1112/8000, Loss: 0.127280533314.\n",
      "Iteration: 1113/8000, Loss: 0.127279832959.\n",
      "Iteration: 1114/8000, Loss: 0.127279162407.\n",
      "Iteration: 1115/8000, Loss: 0.127278491855.\n",
      "Iteration: 1116/8000, Loss: 0.127277821302.\n",
      "Iteration: 1117/8000, Loss: 0.127277135849.\n",
      "Iteration: 1118/8000, Loss: 0.127276480198.\n",
      "Iteration: 1119/8000, Loss: 0.127275809646.\n",
      "Iteration: 1120/8000, Loss: 0.127275139093.\n",
      "Iteration: 1121/8000, Loss: 0.127274483442.\n",
      "Iteration: 1122/8000, Loss: 0.12727381289.\n",
      "Iteration: 1123/8000, Loss: 0.127273157239.\n",
      "Iteration: 1124/8000, Loss: 0.127272501588.\n",
      "Iteration: 1125/8000, Loss: 0.127271845937.\n",
      "Iteration: 1126/8000, Loss: 0.127271190286.\n",
      "Iteration: 1127/8000, Loss: 0.127270534635.\n",
      "Iteration: 1128/8000, Loss: 0.127269878983.\n",
      "Iteration: 1129/8000, Loss: 0.127269253135.\n",
      "Iteration: 1130/8000, Loss: 0.127268582582.\n",
      "Iteration: 1131/8000, Loss: 0.127267956734.\n",
      "Iteration: 1132/8000, Loss: 0.127267301083.\n",
      "Iteration: 1133/8000, Loss: 0.127266660333.\n",
      "Iteration: 1134/8000, Loss: 0.127266019583.\n",
      "Iteration: 1135/8000, Loss: 0.127265393734.\n",
      "Iteration: 1136/8000, Loss: 0.127264752984.\n",
      "Iteration: 1137/8000, Loss: 0.127264112234.\n",
      "Iteration: 1138/8000, Loss: 0.127263471484.\n",
      "Iteration: 1139/8000, Loss: 0.127262845635.\n",
      "Iteration: 1140/8000, Loss: 0.127262234688.\n",
      "Iteration: 1141/8000, Loss: 0.127261608839.\n",
      "Iteration: 1142/8000, Loss: 0.127260968089.\n",
      "Iteration: 1143/8000, Loss: 0.127260357141.\n",
      "Iteration: 1144/8000, Loss: 0.127259731293.\n",
      "Iteration: 1145/8000, Loss: 0.127259120345.\n",
      "Iteration: 1146/8000, Loss: 0.127258479595.\n",
      "Iteration: 1147/8000, Loss: 0.127257868648.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1148/8000, Loss: 0.1272572577.\n",
      "Iteration: 1149/8000, Loss: 0.127256646752.\n",
      "Iteration: 1150/8000, Loss: 0.127256035805.\n",
      "Iteration: 1151/8000, Loss: 0.127255439758.\n",
      "Iteration: 1152/8000, Loss: 0.127254828811.\n",
      "Iteration: 1153/8000, Loss: 0.127254217863.\n",
      "Iteration: 1154/8000, Loss: 0.127253606915.\n",
      "Iteration: 1155/8000, Loss: 0.127253010869.\n",
      "Iteration: 1156/8000, Loss: 0.127252399921.\n",
      "Iteration: 1157/8000, Loss: 0.127251803875.\n",
      "Iteration: 1158/8000, Loss: 0.127251207829.\n",
      "Iteration: 1159/8000, Loss: 0.127250611782.\n",
      "Iteration: 1160/8000, Loss: 0.127250015736.\n",
      "Iteration: 1161/8000, Loss: 0.12724943459.\n",
      "Iteration: 1162/8000, Loss: 0.127248838544.\n",
      "Iteration: 1163/8000, Loss: 0.127248242497.\n",
      "Iteration: 1164/8000, Loss: 0.127247646451.\n",
      "Iteration: 1165/8000, Loss: 0.127247065306.\n",
      "Iteration: 1166/8000, Loss: 0.12724648416.\n",
      "Iteration: 1167/8000, Loss: 0.127245903015.\n",
      "Iteration: 1168/8000, Loss: 0.127245306969.\n",
      "Iteration: 1169/8000, Loss: 0.127244740725.\n",
      "Iteration: 1170/8000, Loss: 0.127244159579.\n",
      "Iteration: 1171/8000, Loss: 0.127243578434.\n",
      "Iteration: 1172/8000, Loss: 0.12724301219.\n",
      "Iteration: 1173/8000, Loss: 0.127242431045.\n",
      "Iteration: 1174/8000, Loss: 0.1272418648.\n",
      "Iteration: 1175/8000, Loss: 0.127241283655.\n",
      "Iteration: 1176/8000, Loss: 0.127240732312.\n",
      "Iteration: 1177/8000, Loss: 0.127240166068.\n",
      "Iteration: 1178/8000, Loss: 0.127239599824.\n",
      "Iteration: 1179/8000, Loss: 0.12723903358.\n",
      "Iteration: 1180/8000, Loss: 0.127238467336.\n",
      "Iteration: 1181/8000, Loss: 0.127237901092.\n",
      "Iteration: 1182/8000, Loss: 0.127237349749.\n",
      "Iteration: 1183/8000, Loss: 0.127236798406.\n",
      "Iteration: 1184/8000, Loss: 0.127236232162.\n",
      "Iteration: 1185/8000, Loss: 0.127235665917.\n",
      "Iteration: 1186/8000, Loss: 0.127235114574.\n",
      "Iteration: 1187/8000, Loss: 0.127234563231.\n",
      "Iteration: 1188/8000, Loss: 0.127234011889.\n",
      "Iteration: 1189/8000, Loss: 0.127233475447.\n",
      "Iteration: 1190/8000, Loss: 0.127232924104.\n",
      "Iteration: 1191/8000, Loss: 0.127232372761.\n",
      "Iteration: 1192/8000, Loss: 0.127231836319.\n",
      "Iteration: 1193/8000, Loss: 0.127231284976.\n",
      "Iteration: 1194/8000, Loss: 0.127230733633.\n",
      "Iteration: 1195/8000, Loss: 0.127230212092.\n",
      "Iteration: 1196/8000, Loss: 0.127229675651.\n",
      "Iteration: 1197/8000, Loss: 0.127229139209.\n",
      "Iteration: 1198/8000, Loss: 0.127228602767.\n",
      "Iteration: 1199/8000, Loss: 0.127228051424.\n",
      "Iteration: 1200/8000, Loss: 0.127227529883.\n",
      "Iteration: 1201/8000, Loss: 0.127226993442.\n",
      "Iteration: 1202/8000, Loss: 0.127226471901.\n",
      "Iteration: 1203/8000, Loss: 0.127225935459.\n",
      "Iteration: 1204/8000, Loss: 0.127225399017.\n",
      "Iteration: 1205/8000, Loss: 0.127224877477.\n",
      "Iteration: 1206/8000, Loss: 0.127224355936.\n",
      "Iteration: 1207/8000, Loss: 0.127223834395.\n",
      "Iteration: 1208/8000, Loss: 0.127223312855.\n",
      "Iteration: 1209/8000, Loss: 0.127222791314.\n",
      "Iteration: 1210/8000, Loss: 0.127222269773.\n",
      "Iteration: 1211/8000, Loss: 0.127221763134.\n",
      "Iteration: 1212/8000, Loss: 0.127221241593.\n",
      "Iteration: 1213/8000, Loss: 0.127220720053.\n",
      "Iteration: 1214/8000, Loss: 0.127220213413.\n",
      "Iteration: 1215/8000, Loss: 0.127219691873.\n",
      "Iteration: 1216/8000, Loss: 0.127219200134.\n",
      "Iteration: 1217/8000, Loss: 0.127218693495.\n",
      "Iteration: 1218/8000, Loss: 0.127218157053.\n",
      "Iteration: 1219/8000, Loss: 0.127217650414.\n",
      "Iteration: 1220/8000, Loss: 0.127217158675.\n",
      "Iteration: 1221/8000, Loss: 0.127216652036.\n",
      "Iteration: 1222/8000, Loss: 0.127216145396.\n",
      "Iteration: 1223/8000, Loss: 0.127215653658.\n",
      "Iteration: 1224/8000, Loss: 0.127215147018.\n",
      "Iteration: 1225/8000, Loss: 0.12721465528.\n",
      "Iteration: 1226/8000, Loss: 0.127214148641.\n",
      "Iteration: 1227/8000, Loss: 0.127213656902.\n",
      "Iteration: 1228/8000, Loss: 0.127213150263.\n",
      "Iteration: 1229/8000, Loss: 0.127212673426.\n",
      "Iteration: 1230/8000, Loss: 0.127212166786.\n",
      "Iteration: 1231/8000, Loss: 0.127211675048.\n",
      "Iteration: 1232/8000, Loss: 0.127211198211.\n",
      "Iteration: 1233/8000, Loss: 0.127210691571.\n",
      "Iteration: 1234/8000, Loss: 0.127210214734.\n",
      "Iteration: 1235/8000, Loss: 0.127209722996.\n",
      "Iteration: 1236/8000, Loss: 0.127209231257.\n",
      "Iteration: 1237/8000, Loss: 0.12720875442.\n",
      "Iteration: 1238/8000, Loss: 0.127208277583.\n",
      "Iteration: 1239/8000, Loss: 0.127207785845.\n",
      "Iteration: 1240/8000, Loss: 0.127207309008.\n",
      "Iteration: 1241/8000, Loss: 0.12720683217.\n",
      "Iteration: 1242/8000, Loss: 0.127206355333.\n",
      "Iteration: 1243/8000, Loss: 0.127205878496.\n",
      "Iteration: 1244/8000, Loss: 0.127205401659.\n",
      "Iteration: 1245/8000, Loss: 0.127204924822.\n",
      "Iteration: 1246/8000, Loss: 0.127204447985.\n",
      "Iteration: 1247/8000, Loss: 0.127203986049.\n",
      "Iteration: 1248/8000, Loss: 0.127203509212.\n",
      "Iteration: 1249/8000, Loss: 0.127203047276.\n",
      "Iteration: 1250/8000, Loss: 0.127202570438.\n",
      "Iteration: 1251/8000, Loss: 0.127202108502.\n",
      "Iteration: 1252/8000, Loss: 0.127201631665.\n",
      "Iteration: 1253/8000, Loss: 0.12720118463.\n",
      "Iteration: 1254/8000, Loss: 0.127200722694.\n",
      "Iteration: 1255/8000, Loss: 0.127200245857.\n",
      "Iteration: 1256/8000, Loss: 0.127199783921.\n",
      "Iteration: 1257/8000, Loss: 0.127199336886.\n",
      "Iteration: 1258/8000, Loss: 0.127198860049.\n",
      "Iteration: 1259/8000, Loss: 0.127198413014.\n",
      "Iteration: 1260/8000, Loss: 0.127197951078.\n",
      "Iteration: 1261/8000, Loss: 0.127197489142.\n",
      "Iteration: 1262/8000, Loss: 0.127197042108.\n",
      "Iteration: 1263/8000, Loss: 0.127196609974.\n",
      "Iteration: 1264/8000, Loss: 0.127196148038.\n",
      "Iteration: 1265/8000, Loss: 0.127195686102.\n",
      "Iteration: 1266/8000, Loss: 0.127195239067.\n",
      "Iteration: 1267/8000, Loss: 0.127194792032.\n",
      "Iteration: 1268/8000, Loss: 0.127194344997.\n",
      "Iteration: 1269/8000, Loss: 0.127193897963.\n",
      "Iteration: 1270/8000, Loss: 0.127193450928.\n",
      "Iteration: 1271/8000, Loss: 0.127193003893.\n",
      "Iteration: 1272/8000, Loss: 0.127192556858.\n",
      "Iteration: 1273/8000, Loss: 0.127192139626.\n",
      "Iteration: 1274/8000, Loss: 0.127191692591.\n",
      "Iteration: 1275/8000, Loss: 0.127191230655.\n",
      "Iteration: 1276/8000, Loss: 0.127190813422.\n",
      "Iteration: 1277/8000, Loss: 0.127190366387.\n",
      "Iteration: 1278/8000, Loss: 0.127189934254.\n",
      "Iteration: 1279/8000, Loss: 0.12718950212.\n",
      "Iteration: 1280/8000, Loss: 0.127189069986.\n",
      "Iteration: 1281/8000, Loss: 0.127188622952.\n",
      "Iteration: 1282/8000, Loss: 0.127188205719.\n",
      "Iteration: 1283/8000, Loss: 0.127187773585.\n",
      "Iteration: 1284/8000, Loss: 0.127187341452.\n",
      "Iteration: 1285/8000, Loss: 0.127186909318.\n",
      "Iteration: 1286/8000, Loss: 0.127186477184.\n",
      "Iteration: 1287/8000, Loss: 0.127186059952.\n",
      "Iteration: 1288/8000, Loss: 0.127185627818.\n",
      "Iteration: 1289/8000, Loss: 0.127185195684.\n",
      "Iteration: 1290/8000, Loss: 0.127184778452.\n",
      "Iteration: 1291/8000, Loss: 0.127184361219.\n",
      "Iteration: 1292/8000, Loss: 0.127183943987.\n",
      "Iteration: 1293/8000, Loss: 0.127183511853.\n",
      "Iteration: 1294/8000, Loss: 0.127183094621.\n",
      "Iteration: 1295/8000, Loss: 0.127182662487.\n",
      "Iteration: 1296/8000, Loss: 0.127182260156.\n",
      "Iteration: 1297/8000, Loss: 0.127181842923.\n",
      "Iteration: 1298/8000, Loss: 0.127181425691.\n",
      "Iteration: 1299/8000, Loss: 0.127181023359.\n",
      "Iteration: 1300/8000, Loss: 0.127180591226.\n",
      "Iteration: 1301/8000, Loss: 0.127180173993.\n",
      "Iteration: 1302/8000, Loss: 0.127179771662.\n",
      "Iteration: 1303/8000, Loss: 0.127179354429.\n",
      "Iteration: 1304/8000, Loss: 0.127178952098.\n",
      "Iteration: 1305/8000, Loss: 0.127178549767.\n",
      "Iteration: 1306/8000, Loss: 0.127178147435.\n",
      "Iteration: 1307/8000, Loss: 0.127177730203.\n",
      "Iteration: 1308/8000, Loss: 0.127177327871.\n",
      "Iteration: 1309/8000, Loss: 0.127176910639.\n",
      "Iteration: 1310/8000, Loss: 0.127176508307.\n",
      "Iteration: 1311/8000, Loss: 0.127176105976.\n",
      "Iteration: 1312/8000, Loss: 0.127175703645.\n",
      "Iteration: 1313/8000, Loss: 0.127175301313.\n",
      "Iteration: 1314/8000, Loss: 0.127174913883.\n",
      "Iteration: 1315/8000, Loss: 0.127174511552.\n",
      "Iteration: 1316/8000, Loss: 0.127174109221.\n",
      "Iteration: 1317/8000, Loss: 0.12717372179.\n",
      "Iteration: 1318/8000, Loss: 0.127173319459.\n",
      "Iteration: 1319/8000, Loss: 0.127172932029.\n",
      "Iteration: 1320/8000, Loss: 0.127172529697.\n",
      "Iteration: 1321/8000, Loss: 0.127172142267.\n",
      "Iteration: 1322/8000, Loss: 0.127171739936.\n",
      "Iteration: 1323/8000, Loss: 0.127171352506.\n",
      "Iteration: 1324/8000, Loss: 0.127170965075.\n",
      "Iteration: 1325/8000, Loss: 0.127170562744.\n",
      "Iteration: 1326/8000, Loss: 0.127170175314.\n",
      "Iteration: 1327/8000, Loss: 0.127169787884.\n",
      "Iteration: 1328/8000, Loss: 0.127169415355.\n",
      "Iteration: 1329/8000, Loss: 0.127169013023.\n",
      "Iteration: 1330/8000, Loss: 0.127168640494.\n",
      "Iteration: 1331/8000, Loss: 0.127168253064.\n",
      "Iteration: 1332/8000, Loss: 0.127167880535.\n",
      "Iteration: 1333/8000, Loss: 0.127167493105.\n",
      "Iteration: 1334/8000, Loss: 0.127167105675.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1335/8000, Loss: 0.127166718245.\n",
      "Iteration: 1336/8000, Loss: 0.127166330814.\n",
      "Iteration: 1337/8000, Loss: 0.127165958285.\n",
      "Iteration: 1338/8000, Loss: 0.127165585756.\n",
      "Iteration: 1339/8000, Loss: 0.127165213227.\n",
      "Iteration: 1340/8000, Loss: 0.127164840698.\n",
      "Iteration: 1341/8000, Loss: 0.127164468169.\n",
      "Iteration: 1342/8000, Loss: 0.127164080739.\n",
      "Iteration: 1343/8000, Loss: 0.12716370821.\n",
      "Iteration: 1344/8000, Loss: 0.127163350582.\n",
      "Iteration: 1345/8000, Loss: 0.127162963152.\n",
      "Iteration: 1346/8000, Loss: 0.127162605524.\n",
      "Iteration: 1347/8000, Loss: 0.127162218094.\n",
      "Iteration: 1348/8000, Loss: 0.127161860466.\n",
      "Iteration: 1349/8000, Loss: 0.127161487937.\n",
      "Iteration: 1350/8000, Loss: 0.127161130309.\n",
      "Iteration: 1351/8000, Loss: 0.12716075778.\n",
      "Iteration: 1352/8000, Loss: 0.12716037035.\n",
      "Iteration: 1353/8000, Loss: 0.127160027623.\n",
      "Iteration: 1354/8000, Loss: 0.127159655094.\n",
      "Iteration: 1355/8000, Loss: 0.127159282565.\n",
      "Iteration: 1356/8000, Loss: 0.127158939838.\n",
      "Iteration: 1357/8000, Loss: 0.127158582211.\n",
      "Iteration: 1358/8000, Loss: 0.127158224583.\n",
      "Iteration: 1359/8000, Loss: 0.127157852054.\n",
      "Iteration: 1360/8000, Loss: 0.127157494426.\n",
      "Iteration: 1361/8000, Loss: 0.127157136798.\n",
      "Iteration: 1362/8000, Loss: 0.12715677917.\n",
      "Iteration: 1363/8000, Loss: 0.127156421542.\n",
      "Iteration: 1364/8000, Loss: 0.127156063914.\n",
      "Iteration: 1365/8000, Loss: 0.127155721188.\n",
      "Iteration: 1366/8000, Loss: 0.127155348659.\n",
      "Iteration: 1367/8000, Loss: 0.127155005932.\n",
      "Iteration: 1368/8000, Loss: 0.127154648304.\n",
      "Iteration: 1369/8000, Loss: 0.127154305577.\n",
      "Iteration: 1370/8000, Loss: 0.127153962851.\n",
      "Iteration: 1371/8000, Loss: 0.127153605223.\n",
      "Iteration: 1372/8000, Loss: 0.127153262496.\n",
      "Iteration: 1373/8000, Loss: 0.127152919769.\n",
      "Iteration: 1374/8000, Loss: 0.127152562141.\n",
      "Iteration: 1375/8000, Loss: 0.127152204514.\n",
      "Iteration: 1376/8000, Loss: 0.127151861787.\n",
      "Iteration: 1377/8000, Loss: 0.12715151906.\n",
      "Iteration: 1378/8000, Loss: 0.127151176333.\n",
      "Iteration: 1379/8000, Loss: 0.127150818706.\n",
      "Iteration: 1380/8000, Loss: 0.12715049088.\n",
      "Iteration: 1381/8000, Loss: 0.127150148153.\n",
      "Iteration: 1382/8000, Loss: 0.127149790525.\n",
      "Iteration: 1383/8000, Loss: 0.1271494627.\n",
      "Iteration: 1384/8000, Loss: 0.127149134874.\n",
      "Iteration: 1385/8000, Loss: 0.127148777246.\n",
      "Iteration: 1386/8000, Loss: 0.127148449421.\n",
      "Iteration: 1387/8000, Loss: 0.127148106694.\n",
      "Iteration: 1388/8000, Loss: 0.127147763968.\n",
      "Iteration: 1389/8000, Loss: 0.127147436142.\n",
      "Iteration: 1390/8000, Loss: 0.127147078514.\n",
      "Iteration: 1391/8000, Loss: 0.12714676559.\n",
      "Iteration: 1392/8000, Loss: 0.127146422863.\n",
      "Iteration: 1393/8000, Loss: 0.127146095037.\n",
      "Iteration: 1394/8000, Loss: 0.127145767212.\n",
      "Iteration: 1395/8000, Loss: 0.127145424485.\n",
      "Iteration: 1396/8000, Loss: 0.127145111561.\n",
      "Iteration: 1397/8000, Loss: 0.127144768834.\n",
      "Iteration: 1398/8000, Loss: 0.127144441009.\n",
      "Iteration: 1399/8000, Loss: 0.127144098282.\n",
      "Iteration: 1400/8000, Loss: 0.127143785357.\n",
      "Iteration: 1401/8000, Loss: 0.127143457532.\n",
      "Iteration: 1402/8000, Loss: 0.127143129706.\n",
      "Iteration: 1403/8000, Loss: 0.127142801881.\n",
      "Iteration: 1404/8000, Loss: 0.127142474055.\n",
      "Iteration: 1405/8000, Loss: 0.127142161131.\n",
      "Iteration: 1406/8000, Loss: 0.127141833305.\n",
      "Iteration: 1407/8000, Loss: 0.127141520381.\n",
      "Iteration: 1408/8000, Loss: 0.127141177654.\n",
      "Iteration: 1409/8000, Loss: 0.12714086473.\n",
      "Iteration: 1410/8000, Loss: 0.127140536904.\n",
      "Iteration: 1411/8000, Loss: 0.12714022398.\n",
      "Iteration: 1412/8000, Loss: 0.127139896154.\n",
      "Iteration: 1413/8000, Loss: 0.12713958323.\n",
      "Iteration: 1414/8000, Loss: 0.127139270306.\n",
      "Iteration: 1415/8000, Loss: 0.12713894248.\n",
      "Iteration: 1416/8000, Loss: 0.127138629556.\n",
      "Iteration: 1417/8000, Loss: 0.127138316631.\n",
      "Iteration: 1418/8000, Loss: 0.127138003707.\n",
      "Iteration: 1419/8000, Loss: 0.127137690783.\n",
      "Iteration: 1420/8000, Loss: 0.127137377858.\n",
      "Iteration: 1421/8000, Loss: 0.127137064934.\n",
      "Iteration: 1422/8000, Loss: 0.127136752009.\n",
      "Iteration: 1423/8000, Loss: 0.127136439085.\n",
      "Iteration: 1424/8000, Loss: 0.127136126161.\n",
      "Iteration: 1425/8000, Loss: 0.127135813236.\n",
      "Iteration: 1426/8000, Loss: 0.127135500312.\n",
      "Iteration: 1427/8000, Loss: 0.127135202289.\n",
      "Iteration: 1428/8000, Loss: 0.127134889364.\n",
      "Iteration: 1429/8000, Loss: 0.127134591341.\n",
      "Iteration: 1430/8000, Loss: 0.127134263515.\n",
      "Iteration: 1431/8000, Loss: 0.127133965492.\n",
      "Iteration: 1432/8000, Loss: 0.127133652568.\n",
      "Iteration: 1433/8000, Loss: 0.127133354545.\n",
      "Iteration: 1434/8000, Loss: 0.12713304162.\n",
      "Iteration: 1435/8000, Loss: 0.127132743597.\n",
      "Iteration: 1436/8000, Loss: 0.127132445574.\n",
      "Iteration: 1437/8000, Loss: 0.127132132649.\n",
      "Iteration: 1438/8000, Loss: 0.127131849527.\n",
      "Iteration: 1439/8000, Loss: 0.127131536603.\n",
      "Iteration: 1440/8000, Loss: 0.12713123858.\n",
      "Iteration: 1441/8000, Loss: 0.127130940557.\n",
      "Iteration: 1442/8000, Loss: 0.127130642533.\n",
      "Iteration: 1443/8000, Loss: 0.12713034451.\n",
      "Iteration: 1444/8000, Loss: 0.127130031586.\n",
      "Iteration: 1445/8000, Loss: 0.127129733562.\n",
      "Iteration: 1446/8000, Loss: 0.12712945044.\n",
      "Iteration: 1447/8000, Loss: 0.127129137516.\n",
      "Iteration: 1448/8000, Loss: 0.127128869295.\n",
      "Iteration: 1449/8000, Loss: 0.127128556371.\n",
      "Iteration: 1450/8000, Loss: 0.127128258348.\n",
      "Iteration: 1451/8000, Loss: 0.127127975225.\n",
      "Iteration: 1452/8000, Loss: 0.127127677202.\n",
      "Iteration: 1453/8000, Loss: 0.127127379179.\n",
      "Iteration: 1454/8000, Loss: 0.127127096057.\n",
      "Iteration: 1455/8000, Loss: 0.127126812935.\n",
      "Iteration: 1456/8000, Loss: 0.127126514912.\n",
      "Iteration: 1457/8000, Loss: 0.127126216888.\n",
      "Iteration: 1458/8000, Loss: 0.127125933766.\n",
      "Iteration: 1459/8000, Loss: 0.127125635743.\n",
      "Iteration: 1460/8000, Loss: 0.127125352621.\n",
      "Iteration: 1461/8000, Loss: 0.127125069499.\n",
      "Iteration: 1462/8000, Loss: 0.127124786377.\n",
      "Iteration: 1463/8000, Loss: 0.127124488354.\n",
      "Iteration: 1464/8000, Loss: 0.127124220133.\n",
      "Iteration: 1465/8000, Loss: 0.12712392211.\n",
      "Iteration: 1466/8000, Loss: 0.127123638988.\n",
      "Iteration: 1467/8000, Loss: 0.127123355865.\n",
      "Iteration: 1468/8000, Loss: 0.127123072743.\n",
      "Iteration: 1469/8000, Loss: 0.127122789621.\n",
      "Iteration: 1470/8000, Loss: 0.127122506499.\n",
      "Iteration: 1471/8000, Loss: 0.127122238278.\n",
      "Iteration: 1472/8000, Loss: 0.127121955156.\n",
      "Iteration: 1473/8000, Loss: 0.127121657133.\n",
      "Iteration: 1474/8000, Loss: 0.127121388912.\n",
      "Iteration: 1475/8000, Loss: 0.12712110579.\n",
      "Iteration: 1476/8000, Loss: 0.127120822668.\n",
      "Iteration: 1477/8000, Loss: 0.127120554447.\n",
      "Iteration: 1478/8000, Loss: 0.127120271325.\n",
      "Iteration: 1479/8000, Loss: 0.127120003104.\n",
      "Iteration: 1480/8000, Loss: 0.127119719982.\n",
      "Iteration: 1481/8000, Loss: 0.127119451761.\n",
      "Iteration: 1482/8000, Loss: 0.127119168639.\n",
      "Iteration: 1483/8000, Loss: 0.127118900418.\n",
      "Iteration: 1484/8000, Loss: 0.127118617296.\n",
      "Iteration: 1485/8000, Loss: 0.127118349075.\n",
      "Iteration: 1486/8000, Loss: 0.127118080854.\n",
      "Iteration: 1487/8000, Loss: 0.127117797732.\n",
      "Iteration: 1488/8000, Loss: 0.127117529511.\n",
      "Iteration: 1489/8000, Loss: 0.127117261291.\n",
      "Iteration: 1490/8000, Loss: 0.12711699307.\n",
      "Iteration: 1491/8000, Loss: 0.127116709948.\n",
      "Iteration: 1492/8000, Loss: 0.127116456628.\n",
      "Iteration: 1493/8000, Loss: 0.127116173506.\n",
      "Iteration: 1494/8000, Loss: 0.127115920186.\n",
      "Iteration: 1495/8000, Loss: 0.127115637064.\n",
      "Iteration: 1496/8000, Loss: 0.127115383744.\n",
      "Iteration: 1497/8000, Loss: 0.127115100622.\n",
      "Iteration: 1498/8000, Loss: 0.127114847302.\n",
      "Iteration: 1499/8000, Loss: 0.127114579082.\n",
      "Iteration: 1500/8000, Loss: 0.127114325762.\n",
      "Iteration: 1501/8000, Loss: 0.12711404264.\n",
      "Iteration: 1502/8000, Loss: 0.127113774419.\n",
      "Iteration: 1503/8000, Loss: 0.127113521099.\n",
      "Iteration: 1504/8000, Loss: 0.127113252878.\n",
      "Iteration: 1505/8000, Loss: 0.127112999558.\n",
      "Iteration: 1506/8000, Loss: 0.127112731338.\n",
      "Iteration: 1507/8000, Loss: 0.127112478018.\n",
      "Iteration: 1508/8000, Loss: 0.127112209797.\n",
      "Iteration: 1509/8000, Loss: 0.127111956477.\n",
      "Iteration: 1510/8000, Loss: 0.127111703157.\n",
      "Iteration: 1511/8000, Loss: 0.127111434937.\n",
      "Iteration: 1512/8000, Loss: 0.127111181617.\n",
      "Iteration: 1513/8000, Loss: 0.127110913396.\n",
      "Iteration: 1514/8000, Loss: 0.127110660076.\n",
      "Iteration: 1515/8000, Loss: 0.127110391855.\n",
      "Iteration: 1516/8000, Loss: 0.127110153437.\n",
      "Iteration: 1517/8000, Loss: 0.127109900117.\n",
      "Iteration: 1518/8000, Loss: 0.127109646797.\n",
      "Iteration: 1519/8000, Loss: 0.127109378576.\n",
      "Iteration: 1520/8000, Loss: 0.127109125257.\n",
      "Iteration: 1521/8000, Loss: 0.127108871937.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1522/8000, Loss: 0.127108618617.\n",
      "Iteration: 1523/8000, Loss: 0.127108365297.\n",
      "Iteration: 1524/8000, Loss: 0.127108111978.\n",
      "Iteration: 1525/8000, Loss: 0.127107858658.\n",
      "Iteration: 1526/8000, Loss: 0.127107605338.\n",
      "Iteration: 1527/8000, Loss: 0.12710736692.\n",
      "Iteration: 1528/8000, Loss: 0.1271071136.\n",
      "Iteration: 1529/8000, Loss: 0.12710686028.\n",
      "Iteration: 1530/8000, Loss: 0.12710660696.\n",
      "Iteration: 1531/8000, Loss: 0.127106368542.\n",
      "Iteration: 1532/8000, Loss: 0.127106115222.\n",
      "Iteration: 1533/8000, Loss: 0.127105861902.\n",
      "Iteration: 1534/8000, Loss: 0.127105623484.\n",
      "Iteration: 1535/8000, Loss: 0.127105355263.\n",
      "Iteration: 1536/8000, Loss: 0.127105116844.\n",
      "Iteration: 1537/8000, Loss: 0.127104878426.\n",
      "Iteration: 1538/8000, Loss: 0.127104625106.\n",
      "Iteration: 1539/8000, Loss: 0.127104386687.\n",
      "Iteration: 1540/8000, Loss: 0.127104133368.\n",
      "Iteration: 1541/8000, Loss: 0.127103894949.\n",
      "Iteration: 1542/8000, Loss: 0.12710365653.\n",
      "Iteration: 1543/8000, Loss: 0.127103418112.\n",
      "Iteration: 1544/8000, Loss: 0.127103164792.\n",
      "Iteration: 1545/8000, Loss: 0.127102926373.\n",
      "Iteration: 1546/8000, Loss: 0.127102687955.\n",
      "Iteration: 1547/8000, Loss: 0.127102434635.\n",
      "Iteration: 1548/8000, Loss: 0.127102196217.\n",
      "Iteration: 1549/8000, Loss: 0.127101957798.\n",
      "Iteration: 1550/8000, Loss: 0.127101719379.\n",
      "Iteration: 1551/8000, Loss: 0.127101480961.\n",
      "Iteration: 1552/8000, Loss: 0.127101242542.\n",
      "Iteration: 1553/8000, Loss: 0.127101004124.\n",
      "Iteration: 1554/8000, Loss: 0.127100765705.\n",
      "Iteration: 1555/8000, Loss: 0.127100542188.\n",
      "Iteration: 1556/8000, Loss: 0.127100288868.\n",
      "Iteration: 1557/8000, Loss: 0.127100050449.\n",
      "Iteration: 1558/8000, Loss: 0.127099826932.\n",
      "Iteration: 1559/8000, Loss: 0.127099588513.\n",
      "Iteration: 1560/8000, Loss: 0.127099350095.\n",
      "Iteration: 1561/8000, Loss: 0.127099111676.\n",
      "Iteration: 1562/8000, Loss: 0.127098888159.\n",
      "Iteration: 1563/8000, Loss: 0.12709864974.\n",
      "Iteration: 1564/8000, Loss: 0.127098411322.\n",
      "Iteration: 1565/8000, Loss: 0.127098202705.\n",
      "Iteration: 1566/8000, Loss: 0.127097949386.\n",
      "Iteration: 1567/8000, Loss: 0.127097725868.\n",
      "Iteration: 1568/8000, Loss: 0.12709748745.\n",
      "Iteration: 1569/8000, Loss: 0.127097249031.\n",
      "Iteration: 1570/8000, Loss: 0.127097025514.\n",
      "Iteration: 1571/8000, Loss: 0.127096801996.\n",
      "Iteration: 1572/8000, Loss: 0.127096563578.\n",
      "Iteration: 1573/8000, Loss: 0.12709634006.\n",
      "Iteration: 1574/8000, Loss: 0.127096101642.\n",
      "Iteration: 1575/8000, Loss: 0.127095878124.\n",
      "Iteration: 1576/8000, Loss: 0.127095654607.\n",
      "Iteration: 1577/8000, Loss: 0.127095431089.\n",
      "Iteration: 1578/8000, Loss: 0.127095192671.\n",
      "Iteration: 1579/8000, Loss: 0.127094969153.\n",
      "Iteration: 1580/8000, Loss: 0.127094745636.\n",
      "Iteration: 1581/8000, Loss: 0.127094522119.\n",
      "Iteration: 1582/8000, Loss: 0.127094298601.\n",
      "Iteration: 1583/8000, Loss: 0.127094060183.\n",
      "Iteration: 1584/8000, Loss: 0.127093851566.\n",
      "Iteration: 1585/8000, Loss: 0.127093613148.\n",
      "Iteration: 1586/8000, Loss: 0.127093404531.\n",
      "Iteration: 1587/8000, Loss: 0.127093166113.\n",
      "Iteration: 1588/8000, Loss: 0.127092957497.\n",
      "Iteration: 1589/8000, Loss: 0.127092719078.\n",
      "Iteration: 1590/8000, Loss: 0.127092510462.\n",
      "Iteration: 1591/8000, Loss: 0.127092286944.\n",
      "Iteration: 1592/8000, Loss: 0.127092063427.\n",
      "Iteration: 1593/8000, Loss: 0.127091854811.\n",
      "Iteration: 1594/8000, Loss: 0.127091616392.\n",
      "Iteration: 1595/8000, Loss: 0.127091392875.\n",
      "Iteration: 1596/8000, Loss: 0.12709119916.\n",
      "Iteration: 1597/8000, Loss: 0.127090960741.\n",
      "Iteration: 1598/8000, Loss: 0.127090752125.\n",
      "Iteration: 1599/8000, Loss: 0.127090543509.\n",
      "Iteration: 1600/8000, Loss: 0.127090319991.\n",
      "Iteration: 1601/8000, Loss: 0.127090081573.\n",
      "Iteration: 1602/8000, Loss: 0.127089887857.\n",
      "Iteration: 1603/8000, Loss: 0.12708966434.\n",
      "Iteration: 1604/8000, Loss: 0.127089440823.\n",
      "Iteration: 1605/8000, Loss: 0.127089247108.\n",
      "Iteration: 1606/8000, Loss: 0.127089008689.\n",
      "Iteration: 1607/8000, Loss: 0.127088800073.\n",
      "Iteration: 1608/8000, Loss: 0.127088591456.\n",
      "Iteration: 1609/8000, Loss: 0.127088367939.\n",
      "Iteration: 1610/8000, Loss: 0.127088174224.\n",
      "Iteration: 1611/8000, Loss: 0.127087950706.\n",
      "Iteration: 1612/8000, Loss: 0.12708774209.\n",
      "Iteration: 1613/8000, Loss: 0.127087518573.\n",
      "Iteration: 1614/8000, Loss: 0.127087309957.\n",
      "Iteration: 1615/8000, Loss: 0.12708710134.\n",
      "Iteration: 1616/8000, Loss: 0.127086892724.\n",
      "Iteration: 1617/8000, Loss: 0.127086684108.\n",
      "Iteration: 1618/8000, Loss: 0.12708646059.\n",
      "Iteration: 1619/8000, Loss: 0.127086266875.\n",
      "Iteration: 1620/8000, Loss: 0.127086043358.\n",
      "Iteration: 1621/8000, Loss: 0.127085849643.\n",
      "Iteration: 1622/8000, Loss: 0.127085626125.\n",
      "Iteration: 1623/8000, Loss: 0.127085417509.\n",
      "Iteration: 1624/8000, Loss: 0.127085223794.\n",
      "Iteration: 1625/8000, Loss: 0.127085015178.\n",
      "Iteration: 1626/8000, Loss: 0.127084806561.\n",
      "Iteration: 1627/8000, Loss: 0.127084583044.\n",
      "Iteration: 1628/8000, Loss: 0.127084389329.\n",
      "Iteration: 1629/8000, Loss: 0.127084180713.\n",
      "Iteration: 1630/8000, Loss: 0.127083986998.\n",
      "Iteration: 1631/8000, Loss: 0.12708376348.\n",
      "Iteration: 1632/8000, Loss: 0.127083569765.\n",
      "Iteration: 1633/8000, Loss: 0.127083361149.\n",
      "Iteration: 1634/8000, Loss: 0.127083152533.\n",
      "Iteration: 1635/8000, Loss: 0.127082943916.\n",
      "Iteration: 1636/8000, Loss: 0.127082750201.\n",
      "Iteration: 1637/8000, Loss: 0.127082541585.\n",
      "Iteration: 1638/8000, Loss: 0.12708234787.\n",
      "Iteration: 1639/8000, Loss: 0.127082139254.\n",
      "Iteration: 1640/8000, Loss: 0.127081930637.\n",
      "Iteration: 1641/8000, Loss: 0.127081736922.\n",
      "Iteration: 1642/8000, Loss: 0.127081543207.\n",
      "Iteration: 1643/8000, Loss: 0.127081334591.\n",
      "Iteration: 1644/8000, Loss: 0.127081125975.\n",
      "Iteration: 1645/8000, Loss: 0.12708093226.\n",
      "Iteration: 1646/8000, Loss: 0.127080738544.\n",
      "Iteration: 1647/8000, Loss: 0.127080529928.\n",
      "Iteration: 1648/8000, Loss: 0.127080336213.\n",
      "Iteration: 1649/8000, Loss: 0.127080142498.\n",
      "Iteration: 1650/8000, Loss: 0.127079933882.\n",
      "Iteration: 1651/8000, Loss: 0.127079740167.\n",
      "Iteration: 1652/8000, Loss: 0.127079546452.\n",
      "Iteration: 1653/8000, Loss: 0.127079352736.\n",
      "Iteration: 1654/8000, Loss: 0.127079159021.\n",
      "Iteration: 1655/8000, Loss: 0.127078950405.\n",
      "Iteration: 1656/8000, Loss: 0.12707875669.\n",
      "Iteration: 1657/8000, Loss: 0.127078562975.\n",
      "Iteration: 1658/8000, Loss: 0.127078354359.\n",
      "Iteration: 1659/8000, Loss: 0.127078160644.\n",
      "Iteration: 1660/8000, Loss: 0.12707798183.\n",
      "Iteration: 1661/8000, Loss: 0.127077788115.\n",
      "Iteration: 1662/8000, Loss: 0.127077594399.\n",
      "Iteration: 1663/8000, Loss: 0.127077400684.\n",
      "Iteration: 1664/8000, Loss: 0.127077206969.\n",
      "Iteration: 1665/8000, Loss: 0.127077013254.\n",
      "Iteration: 1666/8000, Loss: 0.127076819539.\n",
      "Iteration: 1667/8000, Loss: 0.127076610923.\n",
      "Iteration: 1668/8000, Loss: 0.12707644701.\n",
      "Iteration: 1669/8000, Loss: 0.127076238394.\n",
      "Iteration: 1670/8000, Loss: 0.127076044679.\n",
      "Iteration: 1671/8000, Loss: 0.127075850964.\n",
      "Iteration: 1672/8000, Loss: 0.12707567215.\n",
      "Iteration: 1673/8000, Loss: 0.127075493336.\n",
      "Iteration: 1674/8000, Loss: 0.127075284719.\n",
      "Iteration: 1675/8000, Loss: 0.127075105906.\n",
      "Iteration: 1676/8000, Loss: 0.12707491219.\n",
      "Iteration: 1677/8000, Loss: 0.127074733377.\n",
      "Iteration: 1678/8000, Loss: 0.127074539661.\n",
      "Iteration: 1679/8000, Loss: 0.127074345946.\n",
      "Iteration: 1680/8000, Loss: 0.127074152231.\n",
      "Iteration: 1681/8000, Loss: 0.127073973417.\n",
      "Iteration: 1682/8000, Loss: 0.127073794603.\n",
      "Iteration: 1683/8000, Loss: 0.127073585987.\n",
      "Iteration: 1684/8000, Loss: 0.127073407173.\n",
      "Iteration: 1685/8000, Loss: 0.127073228359.\n",
      "Iteration: 1686/8000, Loss: 0.127073049545.\n",
      "Iteration: 1687/8000, Loss: 0.12707285583.\n",
      "Iteration: 1688/8000, Loss: 0.127072662115.\n",
      "Iteration: 1689/8000, Loss: 0.127072483301.\n",
      "Iteration: 1690/8000, Loss: 0.127072304487.\n",
      "Iteration: 1691/8000, Loss: 0.127072125673.\n",
      "Iteration: 1692/8000, Loss: 0.127071946859.\n",
      "Iteration: 1693/8000, Loss: 0.127071768045.\n",
      "Iteration: 1694/8000, Loss: 0.12707157433.\n",
      "Iteration: 1695/8000, Loss: 0.127071380615.\n",
      "Iteration: 1696/8000, Loss: 0.127071201801.\n",
      "Iteration: 1697/8000, Loss: 0.127071022987.\n",
      "Iteration: 1698/8000, Loss: 0.127070829272.\n",
      "Iteration: 1699/8000, Loss: 0.127070665359.\n",
      "Iteration: 1700/8000, Loss: 0.127070471644.\n",
      "Iteration: 1701/8000, Loss: 0.127070307732.\n",
      "Iteration: 1702/8000, Loss: 0.127070128918.\n",
      "Iteration: 1703/8000, Loss: 0.127069935203.\n",
      "Iteration: 1704/8000, Loss: 0.127069756389.\n",
      "Iteration: 1705/8000, Loss: 0.127069592476.\n",
      "Iteration: 1706/8000, Loss: 0.12706938386.\n",
      "Iteration: 1707/8000, Loss: 0.127069219947.\n",
      "Iteration: 1708/8000, Loss: 0.127069056034.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1709/8000, Loss: 0.127068862319.\n",
      "Iteration: 1710/8000, Loss: 0.127068683505.\n",
      "Iteration: 1711/8000, Loss: 0.127068504691.\n",
      "Iteration: 1712/8000, Loss: 0.127068325877.\n",
      "Iteration: 1713/8000, Loss: 0.127068147063.\n",
      "Iteration: 1714/8000, Loss: 0.12706798315.\n",
      "Iteration: 1715/8000, Loss: 0.127067789435.\n",
      "Iteration: 1716/8000, Loss: 0.127067625523.\n",
      "Iteration: 1717/8000, Loss: 0.127067446709.\n",
      "Iteration: 1718/8000, Loss: 0.127067282796.\n",
      "Iteration: 1719/8000, Loss: 0.127067103982.\n",
      "Iteration: 1720/8000, Loss: 0.127066910267.\n",
      "Iteration: 1721/8000, Loss: 0.127066746354.\n",
      "Iteration: 1722/8000, Loss: 0.127066582441.\n",
      "Iteration: 1723/8000, Loss: 0.127066403627.\n",
      "Iteration: 1724/8000, Loss: 0.127066224813.\n",
      "Iteration: 1725/8000, Loss: 0.127066046.\n",
      "Iteration: 1726/8000, Loss: 0.127065882087.\n",
      "Iteration: 1727/8000, Loss: 0.127065703273.\n",
      "Iteration: 1728/8000, Loss: 0.12706553936.\n",
      "Iteration: 1729/8000, Loss: 0.127065375447.\n",
      "Iteration: 1730/8000, Loss: 0.127065196633.\n",
      "Iteration: 1731/8000, Loss: 0.127065017819.\n",
      "Iteration: 1732/8000, Loss: 0.127064853907.\n",
      "Iteration: 1733/8000, Loss: 0.127064675093.\n",
      "Iteration: 1734/8000, Loss: 0.127064526081.\n",
      "Iteration: 1735/8000, Loss: 0.127064347267.\n",
      "Iteration: 1736/8000, Loss: 0.127064168453.\n",
      "Iteration: 1737/8000, Loss: 0.127063989639.\n",
      "Iteration: 1738/8000, Loss: 0.127063840628.\n",
      "Iteration: 1739/8000, Loss: 0.127063646913.\n",
      "Iteration: 1740/8000, Loss: 0.127063497901.\n",
      "Iteration: 1741/8000, Loss: 0.127063333988.\n",
      "Iteration: 1742/8000, Loss: 0.127063155174.\n",
      "Iteration: 1743/8000, Loss: 0.127062991261.\n",
      "Iteration: 1744/8000, Loss: 0.127062827349.\n",
      "Iteration: 1745/8000, Loss: 0.127062663436.\n",
      "Iteration: 1746/8000, Loss: 0.127062484622.\n",
      "Iteration: 1747/8000, Loss: 0.127062320709.\n",
      "Iteration: 1748/8000, Loss: 0.127062141895.\n",
      "Iteration: 1749/8000, Loss: 0.127061992884.\n",
      "Iteration: 1750/8000, Loss: 0.12706181407.\n",
      "Iteration: 1751/8000, Loss: 0.127061665058.\n",
      "Iteration: 1752/8000, Loss: 0.127061501145.\n",
      "Iteration: 1753/8000, Loss: 0.127061322331.\n",
      "Iteration: 1754/8000, Loss: 0.12706117332.\n",
      "Iteration: 1755/8000, Loss: 0.127061009407.\n",
      "Iteration: 1756/8000, Loss: 0.127060830593.\n",
      "Iteration: 1757/8000, Loss: 0.127060651779.\n",
      "Iteration: 1758/8000, Loss: 0.127060502768.\n",
      "Iteration: 1759/8000, Loss: 0.127060353756.\n",
      "Iteration: 1760/8000, Loss: 0.127060189843.\n",
      "Iteration: 1761/8000, Loss: 0.12706002593.\n",
      "Iteration: 1762/8000, Loss: 0.127059847116.\n",
      "Iteration: 1763/8000, Loss: 0.127059698105.\n",
      "Iteration: 1764/8000, Loss: 0.127059534192.\n",
      "Iteration: 1765/8000, Loss: 0.127059370279.\n",
      "Iteration: 1766/8000, Loss: 0.127059206367.\n",
      "Iteration: 1767/8000, Loss: 0.127059057355.\n",
      "Iteration: 1768/8000, Loss: 0.127058893442.\n",
      "Iteration: 1769/8000, Loss: 0.127058729529.\n",
      "Iteration: 1770/8000, Loss: 0.127058565617.\n",
      "Iteration: 1771/8000, Loss: 0.127058401704.\n",
      "Iteration: 1772/8000, Loss: 0.127058237791.\n",
      "Iteration: 1773/8000, Loss: 0.127058088779.\n",
      "Iteration: 1774/8000, Loss: 0.127057939768.\n",
      "Iteration: 1775/8000, Loss: 0.127057775855.\n",
      "Iteration: 1776/8000, Loss: 0.127057611942.\n",
      "Iteration: 1777/8000, Loss: 0.12705744803.\n",
      "Iteration: 1778/8000, Loss: 0.127057284117.\n",
      "Iteration: 1779/8000, Loss: 0.127057135105.\n",
      "Iteration: 1780/8000, Loss: 0.127056986094.\n",
      "Iteration: 1781/8000, Loss: 0.127056822181.\n",
      "Iteration: 1782/8000, Loss: 0.127056658268.\n",
      "Iteration: 1783/8000, Loss: 0.127056509256.\n",
      "Iteration: 1784/8000, Loss: 0.127056330442.\n",
      "Iteration: 1785/8000, Loss: 0.127056181431.\n",
      "Iteration: 1786/8000, Loss: 0.127056032419.\n",
      "Iteration: 1787/8000, Loss: 0.127055883408.\n",
      "Iteration: 1788/8000, Loss: 0.127055749297.\n",
      "Iteration: 1789/8000, Loss: 0.127055585384.\n",
      "Iteration: 1790/8000, Loss: 0.127055421472.\n",
      "Iteration: 1791/8000, Loss: 0.127055257559.\n",
      "Iteration: 1792/8000, Loss: 0.127055123448.\n",
      "Iteration: 1793/8000, Loss: 0.127054959536.\n",
      "Iteration: 1794/8000, Loss: 0.127054795623.\n",
      "Iteration: 1795/8000, Loss: 0.127054646611.\n",
      "Iteration: 1796/8000, Loss: 0.1270544976.\n",
      "Iteration: 1797/8000, Loss: 0.127054333687.\n",
      "Iteration: 1798/8000, Loss: 0.127054184675.\n",
      "Iteration: 1799/8000, Loss: 0.127054050565.\n",
      "Iteration: 1800/8000, Loss: 0.127053871751.\n",
      "Iteration: 1801/8000, Loss: 0.12705373764.\n",
      "Iteration: 1802/8000, Loss: 0.127053588629.\n",
      "Iteration: 1803/8000, Loss: 0.127053424716.\n",
      "Iteration: 1804/8000, Loss: 0.127053260803.\n",
      "Iteration: 1805/8000, Loss: 0.127053126693.\n",
      "Iteration: 1806/8000, Loss: 0.127052977681.\n",
      "Iteration: 1807/8000, Loss: 0.12705282867.\n",
      "Iteration: 1808/8000, Loss: 0.127052664757.\n",
      "Iteration: 1809/8000, Loss: 0.127052515745.\n",
      "Iteration: 1810/8000, Loss: 0.127052366734.\n",
      "Iteration: 1811/8000, Loss: 0.127052217722.\n",
      "Iteration: 1812/8000, Loss: 0.12705206871.\n",
      "Iteration: 1813/8000, Loss: 0.127051919699.\n",
      "Iteration: 1814/8000, Loss: 0.127051770687.\n",
      "Iteration: 1815/8000, Loss: 0.127051636577.\n",
      "Iteration: 1816/8000, Loss: 0.127051487565.\n",
      "Iteration: 1817/8000, Loss: 0.127051338553.\n",
      "Iteration: 1818/8000, Loss: 0.127051174641.\n",
      "Iteration: 1819/8000, Loss: 0.12705104053.\n",
      "Iteration: 1820/8000, Loss: 0.127050876617.\n",
      "Iteration: 1821/8000, Loss: 0.127050757408.\n",
      "Iteration: 1822/8000, Loss: 0.127050593495.\n",
      "Iteration: 1823/8000, Loss: 0.127050459385.\n",
      "Iteration: 1824/8000, Loss: 0.127050310373.\n",
      "Iteration: 1825/8000, Loss: 0.127050161362.\n",
      "Iteration: 1826/8000, Loss: 0.12705001235.\n",
      "Iteration: 1827/8000, Loss: 0.127049863338.\n",
      "Iteration: 1828/8000, Loss: 0.127049714327.\n",
      "Iteration: 1829/8000, Loss: 0.127049580216.\n",
      "Iteration: 1830/8000, Loss: 0.127049431205.\n",
      "Iteration: 1831/8000, Loss: 0.127049282193.\n",
      "Iteration: 1832/8000, Loss: 0.127049148083.\n",
      "Iteration: 1833/8000, Loss: 0.127048999071.\n",
      "Iteration: 1834/8000, Loss: 0.12704885006.\n",
      "Iteration: 1835/8000, Loss: 0.127048701048.\n",
      "Iteration: 1836/8000, Loss: 0.127048566937.\n",
      "Iteration: 1837/8000, Loss: 0.127048432827.\n",
      "Iteration: 1838/8000, Loss: 0.127048283815.\n",
      "Iteration: 1839/8000, Loss: 0.127048134804.\n",
      "Iteration: 1840/8000, Loss: 0.127048000693.\n",
      "Iteration: 1841/8000, Loss: 0.127047851682.\n",
      "Iteration: 1842/8000, Loss: 0.127047717571.\n",
      "Iteration: 1843/8000, Loss: 0.12704756856.\n",
      "Iteration: 1844/8000, Loss: 0.127047434449.\n",
      "Iteration: 1845/8000, Loss: 0.127047285438.\n",
      "Iteration: 1846/8000, Loss: 0.127047136426.\n",
      "Iteration: 1847/8000, Loss: 0.127047002316.\n",
      "Iteration: 1848/8000, Loss: 0.127046868205.\n",
      "Iteration: 1849/8000, Loss: 0.127046734095.\n",
      "Iteration: 1850/8000, Loss: 0.127046585083.\n",
      "Iteration: 1851/8000, Loss: 0.127046450973.\n",
      "Iteration: 1852/8000, Loss: 0.127046301961.\n",
      "Iteration: 1853/8000, Loss: 0.12704616785.\n",
      "Iteration: 1854/8000, Loss: 0.12704603374.\n",
      "Iteration: 1855/8000, Loss: 0.127045884728.\n",
      "Iteration: 1856/8000, Loss: 0.127045750618.\n",
      "Iteration: 1857/8000, Loss: 0.127045601606.\n",
      "Iteration: 1858/8000, Loss: 0.127045467496.\n",
      "Iteration: 1859/8000, Loss: 0.127045333385.\n",
      "Iteration: 1860/8000, Loss: 0.127045199275.\n",
      "Iteration: 1861/8000, Loss: 0.127045065165.\n",
      "Iteration: 1862/8000, Loss: 0.127044916153.\n",
      "Iteration: 1863/8000, Loss: 0.127044782043.\n",
      "Iteration: 1864/8000, Loss: 0.127044647932.\n",
      "Iteration: 1865/8000, Loss: 0.12704449892.\n",
      "Iteration: 1866/8000, Loss: 0.12704436481.\n",
      "Iteration: 1867/8000, Loss: 0.1270442307.\n",
      "Iteration: 1868/8000, Loss: 0.127044096589.\n",
      "Iteration: 1869/8000, Loss: 0.127043962479.\n",
      "Iteration: 1870/8000, Loss: 0.127043828368.\n",
      "Iteration: 1871/8000, Loss: 0.127043679357.\n",
      "Iteration: 1872/8000, Loss: 0.127043560147.\n",
      "Iteration: 1873/8000, Loss: 0.127043426037.\n",
      "Iteration: 1874/8000, Loss: 0.127043277025.\n",
      "Iteration: 1875/8000, Loss: 0.127043157816.\n",
      "Iteration: 1876/8000, Loss: 0.127043023705.\n",
      "Iteration: 1877/8000, Loss: 0.127042889595.\n",
      "Iteration: 1878/8000, Loss: 0.127042740583.\n",
      "Iteration: 1879/8000, Loss: 0.127042621374.\n",
      "Iteration: 1880/8000, Loss: 0.127042472363.\n",
      "Iteration: 1881/8000, Loss: 0.127042353153.\n",
      "Iteration: 1882/8000, Loss: 0.127042219043.\n",
      "Iteration: 1883/8000, Loss: 0.127042070031.\n",
      "Iteration: 1884/8000, Loss: 0.127041950822.\n",
      "Iteration: 1885/8000, Loss: 0.127041816711.\n",
      "Iteration: 1886/8000, Loss: 0.127041682601.\n",
      "Iteration: 1887/8000, Loss: 0.127041548491.\n",
      "Iteration: 1888/8000, Loss: 0.127041429281.\n",
      "Iteration: 1889/8000, Loss: 0.127041295171.\n",
      "Iteration: 1890/8000, Loss: 0.127041146159.\n",
      "Iteration: 1891/8000, Loss: 0.127041041851.\n",
      "Iteration: 1892/8000, Loss: 0.127040907741.\n",
      "Iteration: 1893/8000, Loss: 0.12704077363.\n",
      "Iteration: 1894/8000, Loss: 0.12704063952.\n",
      "Iteration: 1895/8000, Loss: 0.127040505409.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1896/8000, Loss: 0.127040371299.\n",
      "Iteration: 1897/8000, Loss: 0.127040237188.\n",
      "Iteration: 1898/8000, Loss: 0.127040117979.\n",
      "Iteration: 1899/8000, Loss: 0.127039983869.\n",
      "Iteration: 1900/8000, Loss: 0.127039864659.\n",
      "Iteration: 1901/8000, Loss: 0.127039730549.\n",
      "Iteration: 1902/8000, Loss: 0.12703961134.\n",
      "Iteration: 1903/8000, Loss: 0.127039462328.\n",
      "Iteration: 1904/8000, Loss: 0.127039343119.\n",
      "Iteration: 1905/8000, Loss: 0.127039223909.\n",
      "Iteration: 1906/8000, Loss: 0.127039089799.\n",
      "Iteration: 1907/8000, Loss: 0.127038955688.\n",
      "Iteration: 1908/8000, Loss: 0.127038836479.\n",
      "Iteration: 1909/8000, Loss: 0.127038702369.\n",
      "Iteration: 1910/8000, Loss: 0.127038583159.\n",
      "Iteration: 1911/8000, Loss: 0.127038449049.\n",
      "Iteration: 1912/8000, Loss: 0.127038314939.\n",
      "Iteration: 1913/8000, Loss: 0.127038195729.\n",
      "Iteration: 1914/8000, Loss: 0.127038046718.\n",
      "Iteration: 1915/8000, Loss: 0.12703794241.\n",
      "Iteration: 1916/8000, Loss: 0.127037808299.\n",
      "Iteration: 1917/8000, Loss: 0.127037703991.\n",
      "Iteration: 1918/8000, Loss: 0.12703756988.\n",
      "Iteration: 1919/8000, Loss: 0.12703743577.\n",
      "Iteration: 1920/8000, Loss: 0.127037316561.\n",
      "Iteration: 1921/8000, Loss: 0.127037197351.\n",
      "Iteration: 1922/8000, Loss: 0.127037063241.\n",
      "Iteration: 1923/8000, Loss: 0.127036929131.\n",
      "Iteration: 1924/8000, Loss: 0.127036809921.\n",
      "Iteration: 1925/8000, Loss: 0.127036690712.\n",
      "Iteration: 1926/8000, Loss: 0.127036556602.\n",
      "Iteration: 1927/8000, Loss: 0.127036437392.\n",
      "Iteration: 1928/8000, Loss: 0.127036318183.\n",
      "Iteration: 1929/8000, Loss: 0.127036198974.\n",
      "Iteration: 1930/8000, Loss: 0.127036049962.\n",
      "Iteration: 1931/8000, Loss: 0.127035945654.\n",
      "Iteration: 1932/8000, Loss: 0.127035811543.\n",
      "Iteration: 1933/8000, Loss: 0.127035692334.\n",
      "Iteration: 1934/8000, Loss: 0.127035573125.\n",
      "Iteration: 1935/8000, Loss: 0.127035439014.\n",
      "Iteration: 1936/8000, Loss: 0.127035334706.\n",
      "Iteration: 1937/8000, Loss: 0.127035215497.\n",
      "Iteration: 1938/8000, Loss: 0.127035081387.\n",
      "Iteration: 1939/8000, Loss: 0.127034962177.\n",
      "Iteration: 1940/8000, Loss: 0.127034828067.\n",
      "Iteration: 1941/8000, Loss: 0.127034723759.\n",
      "Iteration: 1942/8000, Loss: 0.127034604549.\n",
      "Iteration: 1943/8000, Loss: 0.12703448534.\n",
      "Iteration: 1944/8000, Loss: 0.127034366131.\n",
      "Iteration: 1945/8000, Loss: 0.12703423202.\n",
      "Iteration: 1946/8000, Loss: 0.127034112811.\n",
      "Iteration: 1947/8000, Loss: 0.127034008503.\n",
      "Iteration: 1948/8000, Loss: 0.127033874393.\n",
      "Iteration: 1949/8000, Loss: 0.127033755183.\n",
      "Iteration: 1950/8000, Loss: 0.127033621073.\n",
      "Iteration: 1951/8000, Loss: 0.127033516765.\n",
      "Iteration: 1952/8000, Loss: 0.127033412457.\n",
      "Iteration: 1953/8000, Loss: 0.127033278346.\n",
      "Iteration: 1954/8000, Loss: 0.127033159137.\n",
      "Iteration: 1955/8000, Loss: 0.127033039927.\n",
      "Iteration: 1956/8000, Loss: 0.127032920718.\n",
      "Iteration: 1957/8000, Loss: 0.127032801509.\n",
      "Iteration: 1958/8000, Loss: 0.1270326823.\n",
      "Iteration: 1959/8000, Loss: 0.12703256309.\n",
      "Iteration: 1960/8000, Loss: 0.127032443881.\n",
      "Iteration: 1961/8000, Loss: 0.127032324672.\n",
      "Iteration: 1962/8000, Loss: 0.127032220364.\n",
      "Iteration: 1963/8000, Loss: 0.127032101154.\n",
      "Iteration: 1964/8000, Loss: 0.127031981945.\n",
      "Iteration: 1965/8000, Loss: 0.127031862736.\n",
      "Iteration: 1966/8000, Loss: 0.127031758428.\n",
      "Iteration: 1967/8000, Loss: 0.127031639218.\n",
      "Iteration: 1968/8000, Loss: 0.127031520009.\n",
      "Iteration: 1969/8000, Loss: 0.1270314008.\n",
      "Iteration: 1970/8000, Loss: 0.12703128159.\n",
      "Iteration: 1971/8000, Loss: 0.127031162381.\n",
      "Iteration: 1972/8000, Loss: 0.127031058073.\n",
      "Iteration: 1973/8000, Loss: 0.127030938864.\n",
      "Iteration: 1974/8000, Loss: 0.127030819654.\n",
      "Iteration: 1975/8000, Loss: 0.127030700445.\n",
      "Iteration: 1976/8000, Loss: 0.127030596137.\n",
      "Iteration: 1977/8000, Loss: 0.127030476928.\n",
      "Iteration: 1978/8000, Loss: 0.12703037262.\n",
      "Iteration: 1979/8000, Loss: 0.12703025341.\n",
      "Iteration: 1980/8000, Loss: 0.127030134201.\n",
      "Iteration: 1981/8000, Loss: 0.127030014992.\n",
      "Iteration: 1982/8000, Loss: 0.127029910684.\n",
      "Iteration: 1983/8000, Loss: 0.127029791474.\n",
      "Iteration: 1984/8000, Loss: 0.127029672265.\n",
      "Iteration: 1985/8000, Loss: 0.127029567957.\n",
      "Iteration: 1986/8000, Loss: 0.127029448748.\n",
      "Iteration: 1987/8000, Loss: 0.127029329538.\n",
      "Iteration: 1988/8000, Loss: 0.127029210329.\n",
      "Iteration: 1989/8000, Loss: 0.127029106021.\n",
      "Iteration: 1990/8000, Loss: 0.127029001713.\n",
      "Iteration: 1991/8000, Loss: 0.127028882504.\n",
      "Iteration: 1992/8000, Loss: 0.127028778195.\n",
      "Iteration: 1993/8000, Loss: 0.127028658986.\n",
      "Iteration: 1994/8000, Loss: 0.127028554678.\n",
      "Iteration: 1995/8000, Loss: 0.127028435469.\n",
      "Iteration: 1996/8000, Loss: 0.127028316259.\n",
      "Iteration: 1997/8000, Loss: 0.127028211951.\n",
      "Iteration: 1998/8000, Loss: 0.127028107643.\n",
      "Iteration: 1999/8000, Loss: 0.127027988434.\n",
      "Iteration: 2000/8000, Loss: 0.127027884126.\n",
      "Iteration: 2001/8000, Loss: 0.127027779818.\n",
      "Iteration: 2002/8000, Loss: 0.127027660608.\n",
      "Iteration: 2003/8000, Loss: 0.127027541399.\n",
      "Iteration: 2004/8000, Loss: 0.127027451992.\n",
      "Iteration: 2005/8000, Loss: 0.127027347684.\n",
      "Iteration: 2006/8000, Loss: 0.127027213573.\n",
      "Iteration: 2007/8000, Loss: 0.127027109265.\n",
      "Iteration: 2008/8000, Loss: 0.127027004957.\n",
      "Iteration: 2009/8000, Loss: 0.127026900649.\n",
      "Iteration: 2010/8000, Loss: 0.12702678144.\n",
      "Iteration: 2011/8000, Loss: 0.127026677132.\n",
      "Iteration: 2012/8000, Loss: 0.127026572824.\n",
      "Iteration: 2013/8000, Loss: 0.127026453614.\n",
      "Iteration: 2014/8000, Loss: 0.127026364207.\n",
      "Iteration: 2015/8000, Loss: 0.127026244998.\n",
      "Iteration: 2016/8000, Loss: 0.12702614069.\n",
      "Iteration: 2017/8000, Loss: 0.127026021481.\n",
      "Iteration: 2018/8000, Loss: 0.127025917172.\n",
      "Iteration: 2019/8000, Loss: 0.127025812864.\n",
      "Iteration: 2020/8000, Loss: 0.127025708556.\n",
      "Iteration: 2021/8000, Loss: 0.127025604248.\n",
      "Iteration: 2022/8000, Loss: 0.127025485039.\n",
      "Iteration: 2023/8000, Loss: 0.127025380731.\n",
      "Iteration: 2024/8000, Loss: 0.127025276423.\n",
      "Iteration: 2025/8000, Loss: 0.127025157213.\n",
      "Iteration: 2026/8000, Loss: 0.127025052905.\n",
      "Iteration: 2027/8000, Loss: 0.127024963498.\n",
      "Iteration: 2028/8000, Loss: 0.12702485919.\n",
      "Iteration: 2029/8000, Loss: 0.127024739981.\n",
      "Iteration: 2030/8000, Loss: 0.127024635673.\n",
      "Iteration: 2031/8000, Loss: 0.127024531364.\n",
      "Iteration: 2032/8000, Loss: 0.127024427056.\n",
      "Iteration: 2033/8000, Loss: 0.127024322748.\n",
      "Iteration: 2034/8000, Loss: 0.12702421844.\n",
      "Iteration: 2035/8000, Loss: 0.127024114132.\n",
      "Iteration: 2036/8000, Loss: 0.127023994923.\n",
      "Iteration: 2037/8000, Loss: 0.127023905516.\n",
      "Iteration: 2038/8000, Loss: 0.127023786306.\n",
      "Iteration: 2039/8000, Loss: 0.127023696899.\n",
      "Iteration: 2040/8000, Loss: 0.12702357769.\n",
      "Iteration: 2041/8000, Loss: 0.127023488283.\n",
      "Iteration: 2042/8000, Loss: 0.127023369074.\n",
      "Iteration: 2043/8000, Loss: 0.127023279667.\n",
      "Iteration: 2044/8000, Loss: 0.127023175359.\n",
      "Iteration: 2045/8000, Loss: 0.127023056149.\n",
      "Iteration: 2046/8000, Loss: 0.127022951841.\n",
      "Iteration: 2047/8000, Loss: 0.127022847533.\n",
      "Iteration: 2048/8000, Loss: 0.127022743225.\n",
      "Iteration: 2049/8000, Loss: 0.127022653818.\n",
      "Iteration: 2050/8000, Loss: 0.12702254951.\n",
      "Iteration: 2051/8000, Loss: 0.127022445202.\n",
      "Iteration: 2052/8000, Loss: 0.127022340894.\n",
      "Iteration: 2053/8000, Loss: 0.127022236586.\n",
      "Iteration: 2054/8000, Loss: 0.127022147179.\n",
      "Iteration: 2055/8000, Loss: 0.127022027969.\n",
      "Iteration: 2056/8000, Loss: 0.127021923661.\n",
      "Iteration: 2057/8000, Loss: 0.127021834254.\n",
      "Iteration: 2058/8000, Loss: 0.127021729946.\n",
      "Iteration: 2059/8000, Loss: 0.127021625638.\n",
      "Iteration: 2060/8000, Loss: 0.12702152133.\n",
      "Iteration: 2061/8000, Loss: 0.127021431923.\n",
      "Iteration: 2062/8000, Loss: 0.127021327615.\n",
      "Iteration: 2063/8000, Loss: 0.127021223307.\n",
      "Iteration: 2064/8000, Loss: 0.1270211339.\n",
      "Iteration: 2065/8000, Loss: 0.12702101469.\n",
      "Iteration: 2066/8000, Loss: 0.127020925283.\n",
      "Iteration: 2067/8000, Loss: 0.127020806074.\n",
      "Iteration: 2068/8000, Loss: 0.127020716667.\n",
      "Iteration: 2069/8000, Loss: 0.127020612359.\n",
      "Iteration: 2070/8000, Loss: 0.127020522952.\n",
      "Iteration: 2071/8000, Loss: 0.127020418644.\n",
      "Iteration: 2072/8000, Loss: 0.127020329237.\n",
      "Iteration: 2073/8000, Loss: 0.127020210028.\n",
      "Iteration: 2074/8000, Loss: 0.127020120621.\n",
      "Iteration: 2075/8000, Loss: 0.127020016313.\n",
      "Iteration: 2076/8000, Loss: 0.127019912004.\n",
      "Iteration: 2077/8000, Loss: 0.127019822598.\n",
      "Iteration: 2078/8000, Loss: 0.127019733191.\n",
      "Iteration: 2079/8000, Loss: 0.127019628882.\n",
      "Iteration: 2080/8000, Loss: 0.127019524574.\n",
      "Iteration: 2081/8000, Loss: 0.127019435167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2082/8000, Loss: 0.127019330859.\n",
      "Iteration: 2083/8000, Loss: 0.127019241452.\n",
      "Iteration: 2084/8000, Loss: 0.127019137144.\n",
      "Iteration: 2085/8000, Loss: 0.127019032836.\n",
      "Iteration: 2086/8000, Loss: 0.127018943429.\n",
      "Iteration: 2087/8000, Loss: 0.127018839121.\n",
      "Iteration: 2088/8000, Loss: 0.127018749714.\n",
      "Iteration: 2089/8000, Loss: 0.127018660307.\n",
      "Iteration: 2090/8000, Loss: 0.127018555999.\n",
      "Iteration: 2091/8000, Loss: 0.127018451691.\n",
      "Iteration: 2092/8000, Loss: 0.127018362284.\n",
      "Iteration: 2093/8000, Loss: 0.127018257976.\n",
      "Iteration: 2094/8000, Loss: 0.127018168569.\n",
      "Iteration: 2095/8000, Loss: 0.12701806426.\n",
      "Iteration: 2096/8000, Loss: 0.127017974854.\n",
      "Iteration: 2097/8000, Loss: 0.127017885447.\n",
      "Iteration: 2098/8000, Loss: 0.127017781138.\n",
      "Iteration: 2099/8000, Loss: 0.12701767683.\n",
      "Iteration: 2100/8000, Loss: 0.127017587423.\n",
      "Iteration: 2101/8000, Loss: 0.127017483115.\n",
      "Iteration: 2102/8000, Loss: 0.127017393708.\n",
      "Iteration: 2103/8000, Loss: 0.127017304301.\n",
      "Iteration: 2104/8000, Loss: 0.127017199993.\n",
      "Iteration: 2105/8000, Loss: 0.127017110586.\n",
      "Iteration: 2106/8000, Loss: 0.127017021179.\n",
      "Iteration: 2107/8000, Loss: 0.127016916871.\n",
      "Iteration: 2108/8000, Loss: 0.127016842365.\n",
      "Iteration: 2109/8000, Loss: 0.127016738057.\n",
      "Iteration: 2110/8000, Loss: 0.127016633749.\n",
      "Iteration: 2111/8000, Loss: 0.127016544342.\n",
      "Iteration: 2112/8000, Loss: 0.127016454935.\n",
      "Iteration: 2113/8000, Loss: 0.127016365528.\n",
      "Iteration: 2114/8000, Loss: 0.127016276121.\n",
      "Iteration: 2115/8000, Loss: 0.127016171813.\n",
      "Iteration: 2116/8000, Loss: 0.127016082406.\n",
      "Iteration: 2117/8000, Loss: 0.127015992999.\n",
      "Iteration: 2118/8000, Loss: 0.127015888691.\n",
      "Iteration: 2119/8000, Loss: 0.127015799284.\n",
      "Iteration: 2120/8000, Loss: 0.127015709877.\n",
      "Iteration: 2121/8000, Loss: 0.127015605569.\n",
      "Iteration: 2122/8000, Loss: 0.127015516162.\n",
      "Iteration: 2123/8000, Loss: 0.127015411854.\n",
      "Iteration: 2124/8000, Loss: 0.127015337348.\n",
      "Iteration: 2125/8000, Loss: 0.127015247941.\n",
      "Iteration: 2126/8000, Loss: 0.127015143633.\n",
      "Iteration: 2127/8000, Loss: 0.127015054226.\n",
      "Iteration: 2128/8000, Loss: 0.12701497972.\n",
      "Iteration: 2129/8000, Loss: 0.127014890313.\n",
      "Iteration: 2130/8000, Loss: 0.127014786005.\n",
      "Iteration: 2131/8000, Loss: 0.127014681697.\n",
      "Iteration: 2132/8000, Loss: 0.12701459229.\n",
      "Iteration: 2133/8000, Loss: 0.127014502883.\n",
      "Iteration: 2134/8000, Loss: 0.127014413476.\n",
      "Iteration: 2135/8000, Loss: 0.127014324069.\n",
      "Iteration: 2136/8000, Loss: 0.127014234662.\n",
      "Iteration: 2137/8000, Loss: 0.127014145255.\n",
      "Iteration: 2138/8000, Loss: 0.127014055848.\n",
      "Iteration: 2139/8000, Loss: 0.127013966441.\n",
      "Iteration: 2140/8000, Loss: 0.127013862133.\n",
      "Iteration: 2141/8000, Loss: 0.127013772726.\n",
      "Iteration: 2142/8000, Loss: 0.12701369822.\n",
      "Iteration: 2143/8000, Loss: 0.127013608813.\n",
      "Iteration: 2144/8000, Loss: 0.127013504505.\n",
      "Iteration: 2145/8000, Loss: 0.127013429999.\n",
      "Iteration: 2146/8000, Loss: 0.127013325691.\n",
      "Iteration: 2147/8000, Loss: 0.127013251185.\n",
      "Iteration: 2148/8000, Loss: 0.127013161778.\n",
      "Iteration: 2149/8000, Loss: 0.127013072371.\n",
      "Iteration: 2150/8000, Loss: 0.127012953162.\n",
      "Iteration: 2151/8000, Loss: 0.127012893558.\n",
      "Iteration: 2152/8000, Loss: 0.127012804151.\n",
      "Iteration: 2153/8000, Loss: 0.127012714744.\n",
      "Iteration: 2154/8000, Loss: 0.127012625337.\n",
      "Iteration: 2155/8000, Loss: 0.12701253593.\n",
      "Iteration: 2156/8000, Loss: 0.127012431622.\n",
      "Iteration: 2157/8000, Loss: 0.127012372017.\n",
      "Iteration: 2158/8000, Loss: 0.127012267709.\n",
      "Iteration: 2159/8000, Loss: 0.127012193203.\n",
      "Iteration: 2160/8000, Loss: 0.127012088895.\n",
      "Iteration: 2161/8000, Loss: 0.127011999488.\n",
      "Iteration: 2162/8000, Loss: 0.127011910081.\n",
      "Iteration: 2163/8000, Loss: 0.127011835575.\n",
      "Iteration: 2164/8000, Loss: 0.127011746168.\n",
      "Iteration: 2165/8000, Loss: 0.127011656761.\n",
      "Iteration: 2166/8000, Loss: 0.127011567354.\n",
      "Iteration: 2167/8000, Loss: 0.127011477947.\n",
      "Iteration: 2168/8000, Loss: 0.12701138854.\n",
      "Iteration: 2169/8000, Loss: 0.127011314034.\n",
      "Iteration: 2170/8000, Loss: 0.127011209726.\n",
      "Iteration: 2171/8000, Loss: 0.127011135221.\n",
      "Iteration: 2172/8000, Loss: 0.127011060715.\n",
      "Iteration: 2173/8000, Loss: 0.127010971308.\n",
      "Iteration: 2174/8000, Loss: 0.127010881901.\n",
      "Iteration: 2175/8000, Loss: 0.127010792494.\n",
      "Iteration: 2176/8000, Loss: 0.127010703087.\n",
      "Iteration: 2177/8000, Loss: 0.127010628581.\n",
      "Iteration: 2178/8000, Loss: 0.127010524273.\n",
      "Iteration: 2179/8000, Loss: 0.127010449767.\n",
      "Iteration: 2180/8000, Loss: 0.12701036036.\n",
      "Iteration: 2181/8000, Loss: 0.127010285854.\n",
      "Iteration: 2182/8000, Loss: 0.127010196447.\n",
      "Iteration: 2183/8000, Loss: 0.12701010704.\n",
      "Iteration: 2184/8000, Loss: 0.127010017633.\n",
      "Iteration: 2185/8000, Loss: 0.127009943128.\n",
      "Iteration: 2186/8000, Loss: 0.12700983882.\n",
      "Iteration: 2187/8000, Loss: 0.127009764314.\n",
      "Iteration: 2188/8000, Loss: 0.127009674907.\n",
      "Iteration: 2189/8000, Loss: 0.127009600401.\n",
      "Iteration: 2190/8000, Loss: 0.127009510994.\n",
      "Iteration: 2191/8000, Loss: 0.127009421587.\n",
      "Iteration: 2192/8000, Loss: 0.127009347081.\n",
      "Iteration: 2193/8000, Loss: 0.127009257674.\n",
      "Iteration: 2194/8000, Loss: 0.127009183168.\n",
      "Iteration: 2195/8000, Loss: 0.12700907886.\n",
      "Iteration: 2196/8000, Loss: 0.127009004354.\n",
      "Iteration: 2197/8000, Loss: 0.127008929849.\n",
      "Iteration: 2198/8000, Loss: 0.127008840442.\n",
      "Iteration: 2199/8000, Loss: 0.127008751035.\n",
      "Iteration: 2200/8000, Loss: 0.127008676529.\n",
      "Iteration: 2201/8000, Loss: 0.127008587122.\n",
      "Iteration: 2202/8000, Loss: 0.127008512616.\n",
      "Iteration: 2203/8000, Loss: 0.127008423209.\n",
      "Iteration: 2204/8000, Loss: 0.127008333802.\n",
      "Iteration: 2205/8000, Loss: 0.127008259296.\n",
      "Iteration: 2206/8000, Loss: 0.127008184791.\n",
      "Iteration: 2207/8000, Loss: 0.127008095384.\n",
      "Iteration: 2208/8000, Loss: 0.127008020878.\n",
      "Iteration: 2209/8000, Loss: 0.127007931471.\n",
      "Iteration: 2210/8000, Loss: 0.127007842064.\n",
      "Iteration: 2211/8000, Loss: 0.127007767558.\n",
      "Iteration: 2212/8000, Loss: 0.127007678151.\n",
      "Iteration: 2213/8000, Loss: 0.127007603645.\n",
      "Iteration: 2214/8000, Loss: 0.12700752914.\n",
      "Iteration: 2215/8000, Loss: 0.127007439733.\n",
      "Iteration: 2216/8000, Loss: 0.127007365227.\n",
      "Iteration: 2217/8000, Loss: 0.12700727582.\n",
      "Iteration: 2218/8000, Loss: 0.127007201314.\n",
      "Iteration: 2219/8000, Loss: 0.127007126808.\n",
      "Iteration: 2220/8000, Loss: 0.127007037401.\n",
      "Iteration: 2221/8000, Loss: 0.127006962895.\n",
      "Iteration: 2222/8000, Loss: 0.127006873488.\n",
      "Iteration: 2223/8000, Loss: 0.127006784081.\n",
      "Iteration: 2224/8000, Loss: 0.127006709576.\n",
      "Iteration: 2225/8000, Loss: 0.12700663507.\n",
      "Iteration: 2226/8000, Loss: 0.127006560564.\n",
      "Iteration: 2227/8000, Loss: 0.127006471157.\n",
      "Iteration: 2228/8000, Loss: 0.127006396651.\n",
      "Iteration: 2229/8000, Loss: 0.127006307244.\n",
      "Iteration: 2230/8000, Loss: 0.127006232738.\n",
      "Iteration: 2231/8000, Loss: 0.127006158233.\n",
      "Iteration: 2232/8000, Loss: 0.127006068826.\n",
      "Iteration: 2233/8000, Loss: 0.12700599432.\n",
      "Iteration: 2234/8000, Loss: 0.127005919814.\n",
      "Iteration: 2235/8000, Loss: 0.127005830407.\n",
      "Iteration: 2236/8000, Loss: 0.127005741.\n",
      "Iteration: 2237/8000, Loss: 0.127005681396.\n",
      "Iteration: 2238/8000, Loss: 0.12700560689.\n",
      "Iteration: 2239/8000, Loss: 0.127005517483.\n",
      "Iteration: 2240/8000, Loss: 0.127005442977.\n",
      "Iteration: 2241/8000, Loss: 0.127005368471.\n",
      "Iteration: 2242/8000, Loss: 0.127005279064.\n",
      "Iteration: 2243/8000, Loss: 0.12700521946.\n",
      "Iteration: 2244/8000, Loss: 0.127005130053.\n",
      "Iteration: 2245/8000, Loss: 0.127005055547.\n",
      "Iteration: 2246/8000, Loss: 0.127004951239.\n",
      "Iteration: 2247/8000, Loss: 0.127004891634.\n",
      "Iteration: 2248/8000, Loss: 0.127004832029.\n",
      "Iteration: 2249/8000, Loss: 0.127004742622.\n",
      "Iteration: 2250/8000, Loss: 0.127004653215.\n",
      "Iteration: 2251/8000, Loss: 0.127004593611.\n",
      "Iteration: 2252/8000, Loss: 0.127004504204.\n",
      "Iteration: 2253/8000, Loss: 0.127004429698.\n",
      "Iteration: 2254/8000, Loss: 0.127004355192.\n",
      "Iteration: 2255/8000, Loss: 0.127004280686.\n",
      "Iteration: 2256/8000, Loss: 0.127004191279.\n",
      "Iteration: 2257/8000, Loss: 0.127004116774.\n",
      "Iteration: 2258/8000, Loss: 0.127004042268.\n",
      "Iteration: 2259/8000, Loss: 0.127003967762.\n",
      "Iteration: 2260/8000, Loss: 0.127003878355.\n",
      "Iteration: 2261/8000, Loss: 0.127003803849.\n",
      "Iteration: 2262/8000, Loss: 0.127003729343.\n",
      "Iteration: 2263/8000, Loss: 0.127003669739.\n",
      "Iteration: 2264/8000, Loss: 0.127003580332.\n",
      "Iteration: 2265/8000, Loss: 0.127003490925.\n",
      "Iteration: 2266/8000, Loss: 0.12700343132.\n",
      "Iteration: 2267/8000, Loss: 0.127003341913.\n",
      "Iteration: 2268/8000, Loss: 0.127003282309.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2269/8000, Loss: 0.127003192902.\n",
      "Iteration: 2270/8000, Loss: 0.127003133297.\n",
      "Iteration: 2271/8000, Loss: 0.12700304389.\n",
      "Iteration: 2272/8000, Loss: 0.127002984285.\n",
      "Iteration: 2273/8000, Loss: 0.12700290978.\n",
      "Iteration: 2274/8000, Loss: 0.127002820373.\n",
      "Iteration: 2275/8000, Loss: 0.127002760768.\n",
      "Iteration: 2276/8000, Loss: 0.127002671361.\n",
      "Iteration: 2277/8000, Loss: 0.127002581954.\n",
      "Iteration: 2278/8000, Loss: 0.127002522349.\n",
      "Iteration: 2279/8000, Loss: 0.127002447844.\n",
      "Iteration: 2280/8000, Loss: 0.127002388239.\n",
      "Iteration: 2281/8000, Loss: 0.127002298832.\n",
      "Iteration: 2282/8000, Loss: 0.127002224326.\n",
      "Iteration: 2283/8000, Loss: 0.12700214982.\n",
      "Iteration: 2284/8000, Loss: 0.127002075315.\n",
      "Iteration: 2285/8000, Loss: 0.12700201571.\n",
      "Iteration: 2286/8000, Loss: 0.127001926303.\n",
      "Iteration: 2287/8000, Loss: 0.127001851797.\n",
      "Iteration: 2288/8000, Loss: 0.127001777291.\n",
      "Iteration: 2289/8000, Loss: 0.127001702785.\n",
      "Iteration: 2290/8000, Loss: 0.127001643181.\n",
      "Iteration: 2291/8000, Loss: 0.127001553774.\n",
      "Iteration: 2292/8000, Loss: 0.127001494169.\n",
      "Iteration: 2293/8000, Loss: 0.127001419663.\n",
      "Iteration: 2294/8000, Loss: 0.127001345158.\n",
      "Iteration: 2295/8000, Loss: 0.127001270652.\n",
      "Iteration: 2296/8000, Loss: 0.127001196146.\n",
      "Iteration: 2297/8000, Loss: 0.12700112164.\n",
      "Iteration: 2298/8000, Loss: 0.127001047134.\n",
      "Iteration: 2299/8000, Loss: 0.127000972629.\n",
      "Iteration: 2300/8000, Loss: 0.127000898123.\n",
      "Iteration: 2301/8000, Loss: 0.127000838518.\n",
      "Iteration: 2302/8000, Loss: 0.127000764012.\n",
      "Iteration: 2303/8000, Loss: 0.127000674605.\n",
      "Iteration: 2304/8000, Loss: 0.1270006001.\n",
      "Iteration: 2305/8000, Loss: 0.127000540495.\n",
      "Iteration: 2306/8000, Loss: 0.127000465989.\n",
      "Iteration: 2307/8000, Loss: 0.127000391483.\n",
      "Iteration: 2308/8000, Loss: 0.127000316978.\n",
      "Iteration: 2309/8000, Loss: 0.127000257373.\n",
      "Iteration: 2310/8000, Loss: 0.127000182867.\n",
      "Iteration: 2311/8000, Loss: 0.127000123262.\n",
      "Iteration: 2312/8000, Loss: 0.127000048757.\n",
      "Iteration: 2313/8000, Loss: 0.12699995935.\n",
      "Iteration: 2314/8000, Loss: 0.126999899745.\n",
      "Iteration: 2315/8000, Loss: 0.126999825239.\n",
      "Iteration: 2316/8000, Loss: 0.126999750733.\n",
      "Iteration: 2317/8000, Loss: 0.126999676228.\n",
      "Iteration: 2318/8000, Loss: 0.126999616623.\n",
      "Iteration: 2319/8000, Loss: 0.126999542117.\n",
      "Iteration: 2320/8000, Loss: 0.126999467611.\n",
      "Iteration: 2321/8000, Loss: 0.126999408007.\n",
      "Iteration: 2322/8000, Loss: 0.126999333501.\n",
      "Iteration: 2323/8000, Loss: 0.126999258995.\n",
      "Iteration: 2324/8000, Loss: 0.12699919939.\n",
      "Iteration: 2325/8000, Loss: 0.126999109983.\n",
      "Iteration: 2326/8000, Loss: 0.126999050379.\n",
      "Iteration: 2327/8000, Loss: 0.126998975873.\n",
      "Iteration: 2328/8000, Loss: 0.126998916268.\n",
      "Iteration: 2329/8000, Loss: 0.126998841763.\n",
      "Iteration: 2330/8000, Loss: 0.126998782158.\n",
      "Iteration: 2331/8000, Loss: 0.126998692751.\n",
      "Iteration: 2332/8000, Loss: 0.126998633146.\n",
      "Iteration: 2333/8000, Loss: 0.126998543739.\n",
      "Iteration: 2334/8000, Loss: 0.126998484135.\n",
      "Iteration: 2335/8000, Loss: 0.126998409629.\n",
      "Iteration: 2336/8000, Loss: 0.126998350024.\n",
      "Iteration: 2337/8000, Loss: 0.12699829042.\n",
      "Iteration: 2338/8000, Loss: 0.126998215914.\n",
      "Iteration: 2339/8000, Loss: 0.126998156309.\n",
      "Iteration: 2340/8000, Loss: 0.126998081803.\n",
      "Iteration: 2341/8000, Loss: 0.126998007298.\n",
      "Iteration: 2342/8000, Loss: 0.126997932792.\n",
      "Iteration: 2343/8000, Loss: 0.126997873187.\n",
      "Iteration: 2344/8000, Loss: 0.126997798681.\n",
      "Iteration: 2345/8000, Loss: 0.126997709274.\n",
      "Iteration: 2346/8000, Loss: 0.126997664571.\n",
      "Iteration: 2347/8000, Loss: 0.126997604966.\n",
      "Iteration: 2348/8000, Loss: 0.12699753046.\n",
      "Iteration: 2349/8000, Loss: 0.126997455955.\n",
      "Iteration: 2350/8000, Loss: 0.126997381449.\n",
      "Iteration: 2351/8000, Loss: 0.126997321844.\n",
      "Iteration: 2352/8000, Loss: 0.126997247338.\n",
      "Iteration: 2353/8000, Loss: 0.126997187734.\n",
      "Iteration: 2354/8000, Loss: 0.126997128129.\n",
      "Iteration: 2355/8000, Loss: 0.126997038722.\n",
      "Iteration: 2356/8000, Loss: 0.126996994019.\n",
      "Iteration: 2357/8000, Loss: 0.126996919513.\n",
      "Iteration: 2358/8000, Loss: 0.126996845007.\n",
      "Iteration: 2359/8000, Loss: 0.126996785402.\n",
      "Iteration: 2360/8000, Loss: 0.126996710896.\n",
      "Iteration: 2361/8000, Loss: 0.126996636391.\n",
      "Iteration: 2362/8000, Loss: 0.126996591687.\n",
      "Iteration: 2363/8000, Loss: 0.12699650228.\n",
      "Iteration: 2364/8000, Loss: 0.126996457577.\n",
      "Iteration: 2365/8000, Loss: 0.126996383071.\n",
      "Iteration: 2366/8000, Loss: 0.126996308565.\n",
      "Iteration: 2367/8000, Loss: 0.12699624896.\n",
      "Iteration: 2368/8000, Loss: 0.126996174455.\n",
      "Iteration: 2369/8000, Loss: 0.126996099949.\n",
      "Iteration: 2370/8000, Loss: 0.126996040344.\n",
      "Iteration: 2371/8000, Loss: 0.12699598074.\n",
      "Iteration: 2372/8000, Loss: 0.126995906234.\n",
      "Iteration: 2373/8000, Loss: 0.126995846629.\n",
      "Iteration: 2374/8000, Loss: 0.126995787024.\n",
      "Iteration: 2375/8000, Loss: 0.126995712519.\n",
      "Iteration: 2376/8000, Loss: 0.126995652914.\n",
      "Iteration: 2377/8000, Loss: 0.126995578408.\n",
      "Iteration: 2378/8000, Loss: 0.126995518804.\n",
      "Iteration: 2379/8000, Loss: 0.126995459199.\n",
      "Iteration: 2380/8000, Loss: 0.126995384693.\n",
      "Iteration: 2381/8000, Loss: 0.126995325089.\n",
      "Iteration: 2382/8000, Loss: 0.126995265484.\n",
      "Iteration: 2383/8000, Loss: 0.126995190978.\n",
      "Iteration: 2384/8000, Loss: 0.126995146275.\n",
      "Iteration: 2385/8000, Loss: 0.126995071769.\n",
      "Iteration: 2386/8000, Loss: 0.126994997263.\n",
      "Iteration: 2387/8000, Loss: 0.126994937658.\n",
      "Iteration: 2388/8000, Loss: 0.126994863153.\n",
      "Iteration: 2389/8000, Loss: 0.126994818449.\n",
      "Iteration: 2390/8000, Loss: 0.126994743943.\n",
      "Iteration: 2391/8000, Loss: 0.126994669437.\n",
      "Iteration: 2392/8000, Loss: 0.126994609833.\n",
      "Iteration: 2393/8000, Loss: 0.126994535327.\n",
      "Iteration: 2394/8000, Loss: 0.126994475722.\n",
      "Iteration: 2395/8000, Loss: 0.126994416118.\n",
      "Iteration: 2396/8000, Loss: 0.126994356513.\n",
      "Iteration: 2397/8000, Loss: 0.126994282007.\n",
      "Iteration: 2398/8000, Loss: 0.126994222403.\n",
      "Iteration: 2399/8000, Loss: 0.126994162798.\n",
      "Iteration: 2400/8000, Loss: 0.126994088292.\n",
      "Iteration: 2401/8000, Loss: 0.126994043589.\n",
      "Iteration: 2402/8000, Loss: 0.126993969083.\n",
      "Iteration: 2403/8000, Loss: 0.126993909478.\n",
      "Iteration: 2404/8000, Loss: 0.126993849874.\n",
      "Iteration: 2405/8000, Loss: 0.126993775368.\n",
      "Iteration: 2406/8000, Loss: 0.126993715763.\n",
      "Iteration: 2407/8000, Loss: 0.126993656158.\n",
      "Iteration: 2408/8000, Loss: 0.126993581653.\n",
      "Iteration: 2409/8000, Loss: 0.126993522048.\n",
      "Iteration: 2410/8000, Loss: 0.126993462443.\n",
      "Iteration: 2411/8000, Loss: 0.126993387938.\n",
      "Iteration: 2412/8000, Loss: 0.126993328333.\n",
      "Iteration: 2413/8000, Loss: 0.126993268728.\n",
      "Iteration: 2414/8000, Loss: 0.126993209124.\n",
      "Iteration: 2415/8000, Loss: 0.126993149519.\n",
      "Iteration: 2416/8000, Loss: 0.126993075013.\n",
      "Iteration: 2417/8000, Loss: 0.12699303031.\n",
      "Iteration: 2418/8000, Loss: 0.126992955804.\n",
      "Iteration: 2419/8000, Loss: 0.126992896199.\n",
      "Iteration: 2420/8000, Loss: 0.126992836595.\n",
      "Iteration: 2421/8000, Loss: 0.126992762089.\n",
      "Iteration: 2422/8000, Loss: 0.126992702484.\n",
      "Iteration: 2423/8000, Loss: 0.126992657781.\n",
      "Iteration: 2424/8000, Loss: 0.126992583275.\n",
      "Iteration: 2425/8000, Loss: 0.12699252367.\n",
      "Iteration: 2426/8000, Loss: 0.126992464066.\n",
      "Iteration: 2427/8000, Loss: 0.12699238956.\n",
      "Iteration: 2428/8000, Loss: 0.126992329955.\n",
      "Iteration: 2429/8000, Loss: 0.126992285252.\n",
      "Iteration: 2430/8000, Loss: 0.126992225647.\n",
      "Iteration: 2431/8000, Loss: 0.126992166042.\n",
      "Iteration: 2432/8000, Loss: 0.126992091537.\n",
      "Iteration: 2433/8000, Loss: 0.126992031932.\n",
      "Iteration: 2434/8000, Loss: 0.126991957426.\n",
      "Iteration: 2435/8000, Loss: 0.126991912723.\n",
      "Iteration: 2436/8000, Loss: 0.126991838217.\n",
      "Iteration: 2437/8000, Loss: 0.126991778612.\n",
      "Iteration: 2438/8000, Loss: 0.126991733909.\n",
      "Iteration: 2439/8000, Loss: 0.126991659403.\n",
      "Iteration: 2440/8000, Loss: 0.126991599798.\n",
      "Iteration: 2441/8000, Loss: 0.126991540194.\n",
      "Iteration: 2442/8000, Loss: 0.126991480589.\n",
      "Iteration: 2443/8000, Loss: 0.126991420984.\n",
      "Iteration: 2444/8000, Loss: 0.12699136138.\n",
      "Iteration: 2445/8000, Loss: 0.126991301775.\n",
      "Iteration: 2446/8000, Loss: 0.12699124217.\n",
      "Iteration: 2447/8000, Loss: 0.126991182566.\n",
      "Iteration: 2448/8000, Loss: 0.126991122961.\n",
      "Iteration: 2449/8000, Loss: 0.126991063356.\n",
      "Iteration: 2450/8000, Loss: 0.126991003752.\n",
      "Iteration: 2451/8000, Loss: 0.126990944147.\n",
      "Iteration: 2452/8000, Loss: 0.126990869641.\n",
      "Iteration: 2453/8000, Loss: 0.126990810037.\n",
      "Iteration: 2454/8000, Loss: 0.126990750432.\n",
      "Iteration: 2455/8000, Loss: 0.126990705729.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2456/8000, Loss: 0.126990631223.\n",
      "Iteration: 2457/8000, Loss: 0.126990586519.\n",
      "Iteration: 2458/8000, Loss: 0.126990526915.\n",
      "Iteration: 2459/8000, Loss: 0.12699046731.\n",
      "Iteration: 2460/8000, Loss: 0.126990407705.\n",
      "Iteration: 2461/8000, Loss: 0.126990348101.\n",
      "Iteration: 2462/8000, Loss: 0.126990288496.\n",
      "Iteration: 2463/8000, Loss: 0.12699021399.\n",
      "Iteration: 2464/8000, Loss: 0.126990169287.\n",
      "Iteration: 2465/8000, Loss: 0.126990109682.\n",
      "Iteration: 2466/8000, Loss: 0.126990050077.\n",
      "Iteration: 2467/8000, Loss: 0.126989990473.\n",
      "Iteration: 2468/8000, Loss: 0.126989930868.\n",
      "Iteration: 2469/8000, Loss: 0.126989871264.\n",
      "Iteration: 2470/8000, Loss: 0.126989811659.\n",
      "Iteration: 2471/8000, Loss: 0.126989752054.\n",
      "Iteration: 2472/8000, Loss: 0.12698969245.\n",
      "Iteration: 2473/8000, Loss: 0.126989632845.\n",
      "Iteration: 2474/8000, Loss: 0.12698957324.\n",
      "Iteration: 2475/8000, Loss: 0.126989513636.\n",
      "Iteration: 2476/8000, Loss: 0.126989468932.\n",
      "Iteration: 2477/8000, Loss: 0.126989394426.\n",
      "Iteration: 2478/8000, Loss: 0.126989349723.\n",
      "Iteration: 2479/8000, Loss: 0.126989290118.\n",
      "Iteration: 2480/8000, Loss: 0.126989215612.\n",
      "Iteration: 2481/8000, Loss: 0.12698918581.\n",
      "Iteration: 2482/8000, Loss: 0.126989111304.\n",
      "Iteration: 2483/8000, Loss: 0.1269890517.\n",
      "Iteration: 2484/8000, Loss: 0.126989006996.\n",
      "Iteration: 2485/8000, Loss: 0.126988947392.\n",
      "Iteration: 2486/8000, Loss: 0.126988887787.\n",
      "Iteration: 2487/8000, Loss: 0.126988857985.\n",
      "Iteration: 2488/8000, Loss: 0.126988783479.\n",
      "Iteration: 2489/8000, Loss: 0.126988723874.\n",
      "Iteration: 2490/8000, Loss: 0.126988664269.\n",
      "Iteration: 2491/8000, Loss: 0.126988589764.\n",
      "Iteration: 2492/8000, Loss: 0.12698854506.\n",
      "Iteration: 2493/8000, Loss: 0.126988485456.\n",
      "Iteration: 2494/8000, Loss: 0.126988425851.\n",
      "Iteration: 2495/8000, Loss: 0.126988381147.\n",
      "Iteration: 2496/8000, Loss: 0.126988306642.\n",
      "Iteration: 2497/8000, Loss: 0.126988261938.\n",
      "Iteration: 2498/8000, Loss: 0.126988202333.\n",
      "Iteration: 2499/8000, Loss: 0.12698815763.\n",
      "Iteration: 2500/8000, Loss: 0.126988083124.\n",
      "Iteration: 2501/8000, Loss: 0.126988038421.\n",
      "Iteration: 2502/8000, Loss: 0.126987978816.\n",
      "Iteration: 2503/8000, Loss: 0.126987919211.\n",
      "Iteration: 2504/8000, Loss: 0.126987874508.\n",
      "Iteration: 2505/8000, Loss: 0.126987814903.\n",
      "Iteration: 2506/8000, Loss: 0.126987755299.\n",
      "Iteration: 2507/8000, Loss: 0.126987695694.\n",
      "Iteration: 2508/8000, Loss: 0.126987636089.\n",
      "Iteration: 2509/8000, Loss: 0.126987576485.\n",
      "Iteration: 2510/8000, Loss: 0.126987531781.\n",
      "Iteration: 2511/8000, Loss: 0.126987472177.\n",
      "Iteration: 2512/8000, Loss: 0.126987427473.\n",
      "Iteration: 2513/8000, Loss: 0.126987367868.\n",
      "Iteration: 2514/8000, Loss: 0.126987308264.\n",
      "Iteration: 2515/8000, Loss: 0.126987248659.\n",
      "Iteration: 2516/8000, Loss: 0.126987189054.\n",
      "Iteration: 2517/8000, Loss: 0.126987144351.\n",
      "Iteration: 2518/8000, Loss: 0.126987099648.\n",
      "Iteration: 2519/8000, Loss: 0.126987040043.\n",
      "Iteration: 2520/8000, Loss: 0.126986980438.\n",
      "Iteration: 2521/8000, Loss: 0.126986920834.\n",
      "Iteration: 2522/8000, Loss: 0.126986861229.\n",
      "Iteration: 2523/8000, Loss: 0.126986801624.\n",
      "Iteration: 2524/8000, Loss: 0.126986756921.\n",
      "Iteration: 2525/8000, Loss: 0.126986712217.\n",
      "Iteration: 2526/8000, Loss: 0.126986652613.\n",
      "Iteration: 2527/8000, Loss: 0.126986593008.\n",
      "Iteration: 2528/8000, Loss: 0.126986548305.\n",
      "Iteration: 2529/8000, Loss: 0.1269864887.\n",
      "Iteration: 2530/8000, Loss: 0.126986443996.\n",
      "Iteration: 2531/8000, Loss: 0.126986369491.\n",
      "Iteration: 2532/8000, Loss: 0.126986324787.\n",
      "Iteration: 2533/8000, Loss: 0.126986265182.\n",
      "Iteration: 2534/8000, Loss: 0.126986205578.\n",
      "Iteration: 2535/8000, Loss: 0.126986160874.\n",
      "Iteration: 2536/8000, Loss: 0.126986116171.\n",
      "Iteration: 2537/8000, Loss: 0.126986041665.\n",
      "Iteration: 2538/8000, Loss: 0.126985996962.\n",
      "Iteration: 2539/8000, Loss: 0.126985937357.\n",
      "Iteration: 2540/8000, Loss: 0.126985907555.\n",
      "Iteration: 2541/8000, Loss: 0.12698584795.\n",
      "Iteration: 2542/8000, Loss: 0.126985788345.\n",
      "Iteration: 2543/8000, Loss: 0.126985728741.\n",
      "Iteration: 2544/8000, Loss: 0.126985669136.\n",
      "Iteration: 2545/8000, Loss: 0.126985624433.\n",
      "Iteration: 2546/8000, Loss: 0.126985579729.\n",
      "Iteration: 2547/8000, Loss: 0.126985520124.\n",
      "Iteration: 2548/8000, Loss: 0.12698546052.\n",
      "Iteration: 2549/8000, Loss: 0.126985415816.\n",
      "Iteration: 2550/8000, Loss: 0.126985341311.\n",
      "Iteration: 2551/8000, Loss: 0.126985311508.\n",
      "Iteration: 2552/8000, Loss: 0.126985251904.\n",
      "Iteration: 2553/8000, Loss: 0.1269852072.\n",
      "Iteration: 2554/8000, Loss: 0.126985147595.\n",
      "Iteration: 2555/8000, Loss: 0.126985102892.\n",
      "Iteration: 2556/8000, Loss: 0.126985043287.\n",
      "Iteration: 2557/8000, Loss: 0.126984983683.\n",
      "Iteration: 2558/8000, Loss: 0.126984924078.\n",
      "Iteration: 2559/8000, Loss: 0.126984879375.\n",
      "Iteration: 2560/8000, Loss: 0.126984834671.\n",
      "Iteration: 2561/8000, Loss: 0.126984775066.\n",
      "Iteration: 2562/8000, Loss: 0.126984730363.\n",
      "Iteration: 2563/8000, Loss: 0.126984685659.\n",
      "Iteration: 2564/8000, Loss: 0.126984626055.\n",
      "Iteration: 2565/8000, Loss: 0.126984581351.\n",
      "Iteration: 2566/8000, Loss: 0.126984521747.\n",
      "Iteration: 2567/8000, Loss: 0.126984462142.\n",
      "Iteration: 2568/8000, Loss: 0.126984417439.\n",
      "Iteration: 2569/8000, Loss: 0.126984357834.\n",
      "Iteration: 2570/8000, Loss: 0.12698431313.\n",
      "Iteration: 2571/8000, Loss: 0.126984253526.\n",
      "Iteration: 2572/8000, Loss: 0.126984208822.\n",
      "Iteration: 2573/8000, Loss: 0.126984149218.\n",
      "Iteration: 2574/8000, Loss: 0.126984104514.\n",
      "Iteration: 2575/8000, Loss: 0.126984059811.\n",
      "Iteration: 2576/8000, Loss: 0.126984000206.\n",
      "Iteration: 2577/8000, Loss: 0.126983940601.\n",
      "Iteration: 2578/8000, Loss: 0.126983895898.\n",
      "Iteration: 2579/8000, Loss: 0.126983851194.\n",
      "Iteration: 2580/8000, Loss: 0.12698379159.\n",
      "Iteration: 2581/8000, Loss: 0.126983746886.\n",
      "Iteration: 2582/8000, Loss: 0.126983702183.\n",
      "Iteration: 2583/8000, Loss: 0.126983642578.\n",
      "Iteration: 2584/8000, Loss: 0.126983582973.\n",
      "Iteration: 2585/8000, Loss: 0.126983553171.\n",
      "Iteration: 2586/8000, Loss: 0.126983493567.\n",
      "Iteration: 2587/8000, Loss: 0.126983433962.\n",
      "Iteration: 2588/8000, Loss: 0.126983389258.\n",
      "Iteration: 2589/8000, Loss: 0.126983329654.\n",
      "Iteration: 2590/8000, Loss: 0.12698328495.\n",
      "Iteration: 2591/8000, Loss: 0.126983225346.\n",
      "Iteration: 2592/8000, Loss: 0.126983195543.\n",
      "Iteration: 2593/8000, Loss: 0.126983135939.\n",
      "Iteration: 2594/8000, Loss: 0.126983091235.\n",
      "Iteration: 2595/8000, Loss: 0.126983016729.\n",
      "Iteration: 2596/8000, Loss: 0.126982986927.\n",
      "Iteration: 2597/8000, Loss: 0.126982927322.\n",
      "Iteration: 2598/8000, Loss: 0.126982867718.\n",
      "Iteration: 2599/8000, Loss: 0.126982823014.\n",
      "Iteration: 2600/8000, Loss: 0.126982778311.\n",
      "Iteration: 2601/8000, Loss: 0.126982718706.\n",
      "Iteration: 2602/8000, Loss: 0.126982688904.\n",
      "Iteration: 2603/8000, Loss: 0.126982629299.\n",
      "Iteration: 2604/8000, Loss: 0.126982584596.\n",
      "Iteration: 2605/8000, Loss: 0.126982539892.\n",
      "Iteration: 2606/8000, Loss: 0.126982495189.\n",
      "Iteration: 2607/8000, Loss: 0.126982420683.\n",
      "Iteration: 2608/8000, Loss: 0.126982390881.\n",
      "Iteration: 2609/8000, Loss: 0.126982331276.\n",
      "Iteration: 2610/8000, Loss: 0.126982286572.\n",
      "Iteration: 2611/8000, Loss: 0.126982226968.\n",
      "Iteration: 2612/8000, Loss: 0.126982182264.\n",
      "Iteration: 2613/8000, Loss: 0.126982137561.\n",
      "Iteration: 2614/8000, Loss: 0.126982077956.\n",
      "Iteration: 2615/8000, Loss: 0.126982033253.\n",
      "Iteration: 2616/8000, Loss: 0.126981988549.\n",
      "Iteration: 2617/8000, Loss: 0.126981943846.\n",
      "Iteration: 2618/8000, Loss: 0.126981899142.\n",
      "Iteration: 2619/8000, Loss: 0.126981839538.\n",
      "Iteration: 2620/8000, Loss: 0.126981794834.\n",
      "Iteration: 2621/8000, Loss: 0.126981735229.\n",
      "Iteration: 2622/8000, Loss: 0.126981690526.\n",
      "Iteration: 2623/8000, Loss: 0.126981645823.\n",
      "Iteration: 2624/8000, Loss: 0.126981601119.\n",
      "Iteration: 2625/8000, Loss: 0.126981556416.\n",
      "Iteration: 2626/8000, Loss: 0.126981496811.\n",
      "Iteration: 2627/8000, Loss: 0.126981452107.\n",
      "Iteration: 2628/8000, Loss: 0.126981407404.\n",
      "Iteration: 2629/8000, Loss: 0.126981347799.\n",
      "Iteration: 2630/8000, Loss: 0.126981303096.\n",
      "Iteration: 2631/8000, Loss: 0.126981258392.\n",
      "Iteration: 2632/8000, Loss: 0.126981213689.\n",
      "Iteration: 2633/8000, Loss: 0.126981168985.\n",
      "Iteration: 2634/8000, Loss: 0.126981109381.\n",
      "Iteration: 2635/8000, Loss: 0.126981064677.\n",
      "Iteration: 2636/8000, Loss: 0.126981019974.\n",
      "Iteration: 2637/8000, Loss: 0.12698097527.\n",
      "Iteration: 2638/8000, Loss: 0.126980915666.\n",
      "Iteration: 2639/8000, Loss: 0.126980885863.\n",
      "Iteration: 2640/8000, Loss: 0.126980826259.\n",
      "Iteration: 2641/8000, Loss: 0.126980781555.\n",
      "Iteration: 2642/8000, Loss: 0.126980736852.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2643/8000, Loss: 0.126980677247.\n",
      "Iteration: 2644/8000, Loss: 0.126980647445.\n",
      "Iteration: 2645/8000, Loss: 0.126980572939.\n",
      "Iteration: 2646/8000, Loss: 0.126980558038.\n",
      "Iteration: 2647/8000, Loss: 0.126980498433.\n",
      "Iteration: 2648/8000, Loss: 0.12698045373.\n",
      "Iteration: 2649/8000, Loss: 0.126980409026.\n",
      "Iteration: 2650/8000, Loss: 0.126980349422.\n",
      "Iteration: 2651/8000, Loss: 0.126980304718.\n",
      "Iteration: 2652/8000, Loss: 0.126980245113.\n",
      "Iteration: 2653/8000, Loss: 0.126980215311.\n",
      "Iteration: 2654/8000, Loss: 0.126980185509.\n",
      "Iteration: 2655/8000, Loss: 0.126980111003.\n",
      "Iteration: 2656/8000, Loss: 0.126980081201.\n",
      "Iteration: 2657/8000, Loss: 0.126980021596.\n",
      "Iteration: 2658/8000, Loss: 0.126979976892.\n",
      "Iteration: 2659/8000, Loss: 0.12697994709.\n",
      "Iteration: 2660/8000, Loss: 0.126979872584.\n",
      "Iteration: 2661/8000, Loss: 0.126979827881.\n",
      "Iteration: 2662/8000, Loss: 0.126979783177.\n",
      "Iteration: 2663/8000, Loss: 0.126979738474.\n",
      "Iteration: 2664/8000, Loss: 0.12697969377.\n",
      "Iteration: 2665/8000, Loss: 0.126979649067.\n",
      "Iteration: 2666/8000, Loss: 0.126979619265.\n",
      "Iteration: 2667/8000, Loss: 0.126979544759.\n",
      "Iteration: 2668/8000, Loss: 0.126979514956.\n",
      "Iteration: 2669/8000, Loss: 0.126979470253.\n",
      "Iteration: 2670/8000, Loss: 0.12697942555.\n",
      "Iteration: 2671/8000, Loss: 0.126979365945.\n",
      "Iteration: 2672/8000, Loss: 0.126979321241.\n",
      "Iteration: 2673/8000, Loss: 0.126979276538.\n",
      "Iteration: 2674/8000, Loss: 0.126979231834.\n",
      "Iteration: 2675/8000, Loss: 0.12697917223.\n",
      "Iteration: 2676/8000, Loss: 0.126979142427.\n",
      "Iteration: 2677/8000, Loss: 0.126979112625.\n",
      "Iteration: 2678/8000, Loss: 0.12697905302.\n",
      "Iteration: 2679/8000, Loss: 0.126979008317.\n",
      "Iteration: 2680/8000, Loss: 0.126978948712.\n",
      "Iteration: 2681/8000, Loss: 0.12697891891.\n",
      "Iteration: 2682/8000, Loss: 0.126978874207.\n",
      "Iteration: 2683/8000, Loss: 0.126978814602.\n",
      "Iteration: 2684/8000, Loss: 0.1269787848.\n",
      "Iteration: 2685/8000, Loss: 0.126978725195.\n",
      "Iteration: 2686/8000, Loss: 0.126978680491.\n",
      "Iteration: 2687/8000, Loss: 0.126978650689.\n",
      "Iteration: 2688/8000, Loss: 0.126978605986.\n",
      "Iteration: 2689/8000, Loss: 0.126978546381.\n",
      "Iteration: 2690/8000, Loss: 0.126978501678.\n",
      "Iteration: 2691/8000, Loss: 0.126978456974.\n",
      "Iteration: 2692/8000, Loss: 0.126978412271.\n",
      "Iteration: 2693/8000, Loss: 0.126978382468.\n",
      "Iteration: 2694/8000, Loss: 0.126978322864.\n",
      "Iteration: 2695/8000, Loss: 0.12697827816.\n",
      "Iteration: 2696/8000, Loss: 0.126978233457.\n",
      "Iteration: 2697/8000, Loss: 0.126978188753.\n",
      "Iteration: 2698/8000, Loss: 0.12697814405.\n",
      "Iteration: 2699/8000, Loss: 0.126978099346.\n",
      "Iteration: 2700/8000, Loss: 0.126978054643.\n",
      "Iteration: 2701/8000, Loss: 0.126978009939.\n",
      "Iteration: 2702/8000, Loss: 0.126977965236.\n",
      "Iteration: 2703/8000, Loss: 0.126977920532.\n",
      "Iteration: 2704/8000, Loss: 0.126977875829.\n",
      "Iteration: 2705/8000, Loss: 0.126977816224.\n",
      "Iteration: 2706/8000, Loss: 0.126977801323.\n",
      "Iteration: 2707/8000, Loss: 0.126977741718.\n",
      "Iteration: 2708/8000, Loss: 0.126977697015.\n",
      "Iteration: 2709/8000, Loss: 0.126977652311.\n",
      "Iteration: 2710/8000, Loss: 0.126977607608.\n",
      "Iteration: 2711/8000, Loss: 0.126977577806.\n",
      "Iteration: 2712/8000, Loss: 0.126977533102.\n",
      "Iteration: 2713/8000, Loss: 0.126977488399.\n",
      "Iteration: 2714/8000, Loss: 0.126977428794.\n",
      "Iteration: 2715/8000, Loss: 0.126977398992.\n",
      "Iteration: 2716/8000, Loss: 0.126977354288.\n",
      "Iteration: 2717/8000, Loss: 0.126977294683.\n",
      "Iteration: 2718/8000, Loss: 0.126977264881.\n",
      "Iteration: 2719/8000, Loss: 0.126977220178.\n",
      "Iteration: 2720/8000, Loss: 0.126977175474.\n",
      "Iteration: 2721/8000, Loss: 0.126977130771.\n",
      "Iteration: 2722/8000, Loss: 0.126977086067.\n",
      "Iteration: 2723/8000, Loss: 0.126977041364.\n",
      "Iteration: 2724/8000, Loss: 0.12697699666.\n",
      "Iteration: 2725/8000, Loss: 0.126976951957.\n",
      "Iteration: 2726/8000, Loss: 0.126976922154.\n",
      "Iteration: 2727/8000, Loss: 0.126976877451.\n",
      "Iteration: 2728/8000, Loss: 0.126976832747.\n",
      "Iteration: 2729/8000, Loss: 0.126976788044.\n",
      "Iteration: 2730/8000, Loss: 0.12697674334.\n",
      "Iteration: 2731/8000, Loss: 0.126976698637.\n",
      "Iteration: 2732/8000, Loss: 0.126976653934.\n",
      "Iteration: 2733/8000, Loss: 0.12697660923.\n",
      "Iteration: 2734/8000, Loss: 0.126976579428.\n",
      "Iteration: 2735/8000, Loss: 0.126976534724.\n",
      "Iteration: 2736/8000, Loss: 0.126976490021.\n",
      "Iteration: 2737/8000, Loss: 0.126976445317.\n",
      "Iteration: 2738/8000, Loss: 0.126976385713.\n",
      "Iteration: 2739/8000, Loss: 0.126976341009.\n",
      "Iteration: 2740/8000, Loss: 0.126976311207.\n",
      "Iteration: 2741/8000, Loss: 0.126976281404.\n",
      "Iteration: 2742/8000, Loss: 0.1269762218.\n",
      "Iteration: 2743/8000, Loss: 0.126976191998.\n",
      "Iteration: 2744/8000, Loss: 0.126976132393.\n",
      "Iteration: 2745/8000, Loss: 0.126976102591.\n",
      "Iteration: 2746/8000, Loss: 0.126976072788.\n",
      "Iteration: 2747/8000, Loss: 0.126976028085.\n",
      "Iteration: 2748/8000, Loss: 0.12697596848.\n",
      "Iteration: 2749/8000, Loss: 0.126975938678.\n",
      "Iteration: 2750/8000, Loss: 0.126975879073.\n",
      "Iteration: 2751/8000, Loss: 0.126975849271.\n",
      "Iteration: 2752/8000, Loss: 0.126975804567.\n",
      "Iteration: 2753/8000, Loss: 0.126975759864.\n",
      "Iteration: 2754/8000, Loss: 0.12697571516.\n",
      "Iteration: 2755/8000, Loss: 0.126975685358.\n",
      "Iteration: 2756/8000, Loss: 0.126975625753.\n",
      "Iteration: 2757/8000, Loss: 0.126975595951.\n",
      "Iteration: 2758/8000, Loss: 0.126975551248.\n",
      "Iteration: 2759/8000, Loss: 0.126975506544.\n",
      "Iteration: 2760/8000, Loss: 0.126975476742.\n",
      "Iteration: 2761/8000, Loss: 0.126975432038.\n",
      "Iteration: 2762/8000, Loss: 0.126975387335.\n",
      "Iteration: 2763/8000, Loss: 0.126975357533.\n",
      "Iteration: 2764/8000, Loss: 0.126975312829.\n",
      "Iteration: 2765/8000, Loss: 0.126975268126.\n",
      "Iteration: 2766/8000, Loss: 0.126975223422.\n",
      "Iteration: 2767/8000, Loss: 0.126975178719.\n",
      "Iteration: 2768/8000, Loss: 0.126975148916.\n",
      "Iteration: 2769/8000, Loss: 0.126975089312.\n",
      "Iteration: 2770/8000, Loss: 0.126975059509.\n",
      "Iteration: 2771/8000, Loss: 0.126975014806.\n",
      "Iteration: 2772/8000, Loss: 0.126974970102.\n",
      "Iteration: 2773/8000, Loss: 0.1269749403.\n",
      "Iteration: 2774/8000, Loss: 0.126974895597.\n",
      "Iteration: 2775/8000, Loss: 0.126974850893.\n",
      "Iteration: 2776/8000, Loss: 0.12697480619.\n",
      "Iteration: 2777/8000, Loss: 0.126974776387.\n",
      "Iteration: 2778/8000, Loss: 0.126974731684.\n",
      "Iteration: 2779/8000, Loss: 0.12697468698.\n",
      "Iteration: 2780/8000, Loss: 0.126974642277.\n",
      "Iteration: 2781/8000, Loss: 0.126974612474.\n",
      "Iteration: 2782/8000, Loss: 0.126974567771.\n",
      "Iteration: 2783/8000, Loss: 0.126974523067.\n",
      "Iteration: 2784/8000, Loss: 0.126974478364.\n",
      "Iteration: 2785/8000, Loss: 0.126974448562.\n",
      "Iteration: 2786/8000, Loss: 0.126974403858.\n",
      "Iteration: 2787/8000, Loss: 0.126974374056.\n",
      "Iteration: 2788/8000, Loss: 0.126974314451.\n",
      "Iteration: 2789/8000, Loss: 0.126974284649.\n",
      "Iteration: 2790/8000, Loss: 0.126974254847.\n",
      "Iteration: 2791/8000, Loss: 0.126974195242.\n",
      "Iteration: 2792/8000, Loss: 0.12697416544.\n",
      "Iteration: 2793/8000, Loss: 0.126974105835.\n",
      "Iteration: 2794/8000, Loss: 0.126974076033.\n",
      "Iteration: 2795/8000, Loss: 0.12697404623.\n",
      "Iteration: 2796/8000, Loss: 0.126973986626.\n",
      "Iteration: 2797/8000, Loss: 0.126973956823.\n",
      "Iteration: 2798/8000, Loss: 0.12697391212.\n",
      "Iteration: 2799/8000, Loss: 0.126973882318.\n",
      "Iteration: 2800/8000, Loss: 0.126973837614.\n",
      "Iteration: 2801/8000, Loss: 0.126973792911.\n",
      "Iteration: 2802/8000, Loss: 0.126973763108.\n",
      "Iteration: 2803/8000, Loss: 0.126973718405.\n",
      "Iteration: 2804/8000, Loss: 0.126973673701.\n",
      "Iteration: 2805/8000, Loss: 0.126973628998.\n",
      "Iteration: 2806/8000, Loss: 0.126973599195.\n",
      "Iteration: 2807/8000, Loss: 0.126973569393.\n",
      "Iteration: 2808/8000, Loss: 0.126973509789.\n",
      "Iteration: 2809/8000, Loss: 0.126973479986.\n",
      "Iteration: 2810/8000, Loss: 0.126973450184.\n",
      "Iteration: 2811/8000, Loss: 0.12697340548.\n",
      "Iteration: 2812/8000, Loss: 0.126973375678.\n",
      "Iteration: 2813/8000, Loss: 0.126973330975.\n",
      "Iteration: 2814/8000, Loss: 0.126973286271.\n",
      "Iteration: 2815/8000, Loss: 0.126973256469.\n",
      "Iteration: 2816/8000, Loss: 0.126973211765.\n",
      "Iteration: 2817/8000, Loss: 0.126973167062.\n",
      "Iteration: 2818/8000, Loss: 0.126973122358.\n",
      "Iteration: 2819/8000, Loss: 0.126973092556.\n",
      "Iteration: 2820/8000, Loss: 0.126973032951.\n",
      "Iteration: 2821/8000, Loss: 0.12697301805.\n",
      "Iteration: 2822/8000, Loss: 0.126972973347.\n",
      "Iteration: 2823/8000, Loss: 0.126972928643.\n",
      "Iteration: 2824/8000, Loss: 0.12697288394.\n",
      "Iteration: 2825/8000, Loss: 0.126972869039.\n",
      "Iteration: 2826/8000, Loss: 0.126972794533.\n",
      "Iteration: 2827/8000, Loss: 0.126972779632.\n",
      "Iteration: 2828/8000, Loss: 0.126972749829.\n",
      "Iteration: 2829/8000, Loss: 0.126972690225.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2830/8000, Loss: 0.126972660422.\n",
      "Iteration: 2831/8000, Loss: 0.126972615719.\n",
      "Iteration: 2832/8000, Loss: 0.126972600818.\n",
      "Iteration: 2833/8000, Loss: 0.126972556114.\n",
      "Iteration: 2834/8000, Loss: 0.126972511411.\n",
      "Iteration: 2835/8000, Loss: 0.126972481608.\n",
      "Iteration: 2836/8000, Loss: 0.126972422004.\n",
      "Iteration: 2837/8000, Loss: 0.126972392201.\n",
      "Iteration: 2838/8000, Loss: 0.126972362399.\n",
      "Iteration: 2839/8000, Loss: 0.126972317696.\n",
      "Iteration: 2840/8000, Loss: 0.126972287893.\n",
      "Iteration: 2841/8000, Loss: 0.126972258091.\n",
      "Iteration: 2842/8000, Loss: 0.126972198486.\n",
      "Iteration: 2843/8000, Loss: 0.126972168684.\n",
      "Iteration: 2844/8000, Loss: 0.126972109079.\n",
      "Iteration: 2845/8000, Loss: 0.126972079277.\n",
      "Iteration: 2846/8000, Loss: 0.126972064376.\n",
      "Iteration: 2847/8000, Loss: 0.126972004771.\n",
      "Iteration: 2848/8000, Loss: 0.126971974969.\n",
      "Iteration: 2849/8000, Loss: 0.126971930265.\n",
      "Iteration: 2850/8000, Loss: 0.126971900463.\n",
      "Iteration: 2851/8000, Loss: 0.126971870661.\n",
      "Iteration: 2852/8000, Loss: 0.126971825957.\n",
      "Iteration: 2853/8000, Loss: 0.126971781254.\n",
      "Iteration: 2854/8000, Loss: 0.126971751451.\n",
      "Iteration: 2855/8000, Loss: 0.126971706748.\n",
      "Iteration: 2856/8000, Loss: 0.126971676946.\n",
      "Iteration: 2857/8000, Loss: 0.126971632242.\n",
      "Iteration: 2858/8000, Loss: 0.126971587539.\n",
      "Iteration: 2859/8000, Loss: 0.126971557736.\n",
      "Iteration: 2860/8000, Loss: 0.126971513033.\n",
      "Iteration: 2861/8000, Loss: 0.126971483231.\n",
      "Iteration: 2862/8000, Loss: 0.126971453428.\n",
      "Iteration: 2863/8000, Loss: 0.126971408725.\n",
      "Iteration: 2864/8000, Loss: 0.126971378922.\n",
      "Iteration: 2865/8000, Loss: 0.126971334219.\n",
      "Iteration: 2866/8000, Loss: 0.126971304417.\n",
      "Iteration: 2867/8000, Loss: 0.126971259713.\n",
      "Iteration: 2868/8000, Loss: 0.126971229911.\n",
      "Iteration: 2869/8000, Loss: 0.126971185207.\n",
      "Iteration: 2870/8000, Loss: 0.126971155405.\n",
      "Iteration: 2871/8000, Loss: 0.126971125603.\n",
      "Iteration: 2872/8000, Loss: 0.126971080899.\n",
      "Iteration: 2873/8000, Loss: 0.126971051097.\n",
      "Iteration: 2874/8000, Loss: 0.126971006393.\n",
      "Iteration: 2875/8000, Loss: 0.12697096169.\n",
      "Iteration: 2876/8000, Loss: 0.126970931888.\n",
      "Iteration: 2877/8000, Loss: 0.126970887184.\n",
      "Iteration: 2878/8000, Loss: 0.126970857382.\n",
      "Iteration: 2879/8000, Loss: 0.126970827579.\n",
      "Iteration: 2880/8000, Loss: 0.126970782876.\n",
      "Iteration: 2881/8000, Loss: 0.126970753074.\n",
      "Iteration: 2882/8000, Loss: 0.12697070837.\n",
      "Iteration: 2883/8000, Loss: 0.126970678568.\n",
      "Iteration: 2884/8000, Loss: 0.126970633864.\n",
      "Iteration: 2885/8000, Loss: 0.126970589161.\n",
      "Iteration: 2886/8000, Loss: 0.12697057426.\n",
      "Iteration: 2887/8000, Loss: 0.126970544457.\n",
      "Iteration: 2888/8000, Loss: 0.126970499754.\n",
      "Iteration: 2889/8000, Loss: 0.12697045505.\n",
      "Iteration: 2890/8000, Loss: 0.126970440149.\n",
      "Iteration: 2891/8000, Loss: 0.126970395446.\n",
      "Iteration: 2892/8000, Loss: 0.126970350742.\n",
      "Iteration: 2893/8000, Loss: 0.126970306039.\n",
      "Iteration: 2894/8000, Loss: 0.126970276237.\n",
      "Iteration: 2895/8000, Loss: 0.126970231533.\n",
      "Iteration: 2896/8000, Loss: 0.126970201731.\n",
      "Iteration: 2897/8000, Loss: 0.126970171928.\n",
      "Iteration: 2898/8000, Loss: 0.126970127225.\n",
      "Iteration: 2899/8000, Loss: 0.126970082521.\n",
      "Iteration: 2900/8000, Loss: 0.126970052719.\n",
      "Iteration: 2901/8000, Loss: 0.126970037818.\n",
      "Iteration: 2902/8000, Loss: 0.126969993114.\n",
      "Iteration: 2903/8000, Loss: 0.126969963312.\n",
      "Iteration: 2904/8000, Loss: 0.126969918609.\n",
      "Iteration: 2905/8000, Loss: 0.126969888806.\n",
      "Iteration: 2906/8000, Loss: 0.126969844103.\n",
      "Iteration: 2907/8000, Loss: 0.126969799399.\n",
      "Iteration: 2908/8000, Loss: 0.126969784498.\n",
      "Iteration: 2909/8000, Loss: 0.126969724894.\n",
      "Iteration: 2910/8000, Loss: 0.126969695091.\n",
      "Iteration: 2911/8000, Loss: 0.126969665289.\n",
      "Iteration: 2912/8000, Loss: 0.126969635487.\n",
      "Iteration: 2913/8000, Loss: 0.126969590783.\n",
      "Iteration: 2914/8000, Loss: 0.126969575882.\n",
      "Iteration: 2915/8000, Loss: 0.126969516277.\n",
      "Iteration: 2916/8000, Loss: 0.126969501376.\n",
      "Iteration: 2917/8000, Loss: 0.126969456673.\n",
      "Iteration: 2918/8000, Loss: 0.12696942687.\n",
      "Iteration: 2919/8000, Loss: 0.126969382167.\n",
      "Iteration: 2920/8000, Loss: 0.126969352365.\n",
      "Iteration: 2921/8000, Loss: 0.126969322562.\n",
      "Iteration: 2922/8000, Loss: 0.12696929276.\n",
      "Iteration: 2923/8000, Loss: 0.126969248056.\n",
      "Iteration: 2924/8000, Loss: 0.126969203353.\n",
      "Iteration: 2925/8000, Loss: 0.126969173551.\n",
      "Iteration: 2926/8000, Loss: 0.126969143748.\n",
      "Iteration: 2927/8000, Loss: 0.126969099045.\n",
      "Iteration: 2928/8000, Loss: 0.126969069242.\n",
      "Iteration: 2929/8000, Loss: 0.12696903944.\n",
      "Iteration: 2930/8000, Loss: 0.126969009638.\n",
      "Iteration: 2931/8000, Loss: 0.126968979836.\n",
      "Iteration: 2932/8000, Loss: 0.126968920231.\n",
      "Iteration: 2933/8000, Loss: 0.12696890533.\n",
      "Iteration: 2934/8000, Loss: 0.126968875527.\n",
      "Iteration: 2935/8000, Loss: 0.126968830824.\n",
      "Iteration: 2936/8000, Loss: 0.126968801022.\n",
      "Iteration: 2937/8000, Loss: 0.126968771219.\n",
      "Iteration: 2938/8000, Loss: 0.126968726516.\n",
      "Iteration: 2939/8000, Loss: 0.126968696713.\n",
      "Iteration: 2940/8000, Loss: 0.126968666911.\n",
      "Iteration: 2941/8000, Loss: 0.126968622208.\n",
      "Iteration: 2942/8000, Loss: 0.126968592405.\n",
      "Iteration: 2943/8000, Loss: 0.126968562603.\n",
      "Iteration: 2944/8000, Loss: 0.1269685179.\n",
      "Iteration: 2945/8000, Loss: 0.126968488097.\n",
      "Iteration: 2946/8000, Loss: 0.126968458295.\n",
      "Iteration: 2947/8000, Loss: 0.126968413591.\n",
      "Iteration: 2948/8000, Loss: 0.126968383789.\n",
      "Iteration: 2949/8000, Loss: 0.126968353987.\n",
      "Iteration: 2950/8000, Loss: 0.126968309283.\n",
      "Iteration: 2951/8000, Loss: 0.126968279481.\n",
      "Iteration: 2952/8000, Loss: 0.126968249679.\n",
      "Iteration: 2953/8000, Loss: 0.126968204975.\n",
      "Iteration: 2954/8000, Loss: 0.126968175173.\n",
      "Iteration: 2955/8000, Loss: 0.12696814537.\n",
      "Iteration: 2956/8000, Loss: 0.126968115568.\n",
      "Iteration: 2957/8000, Loss: 0.126968085766.\n",
      "Iteration: 2958/8000, Loss: 0.126968055964.\n",
      "Iteration: 2959/8000, Loss: 0.12696801126.\n",
      "Iteration: 2960/8000, Loss: 0.126967981458.\n",
      "Iteration: 2961/8000, Loss: 0.126967936754.\n",
      "Iteration: 2962/8000, Loss: 0.126967906952.\n",
      "Iteration: 2963/8000, Loss: 0.12696787715.\n",
      "Iteration: 2964/8000, Loss: 0.126967847347.\n",
      "Iteration: 2965/8000, Loss: 0.126967817545.\n",
      "Iteration: 2966/8000, Loss: 0.126967772841.\n",
      "Iteration: 2967/8000, Loss: 0.126967743039.\n",
      "Iteration: 2968/8000, Loss: 0.126967698336.\n",
      "Iteration: 2969/8000, Loss: 0.126967668533.\n",
      "Iteration: 2970/8000, Loss: 0.126967653632.\n",
      "Iteration: 2971/8000, Loss: 0.126967608929.\n",
      "Iteration: 2972/8000, Loss: 0.126967579126.\n",
      "Iteration: 2973/8000, Loss: 0.126967549324.\n",
      "Iteration: 2974/8000, Loss: 0.126967519522.\n",
      "Iteration: 2975/8000, Loss: 0.126967474818.\n",
      "Iteration: 2976/8000, Loss: 0.126967430115.\n",
      "Iteration: 2977/8000, Loss: 0.126967415214.\n",
      "Iteration: 2978/8000, Loss: 0.12696737051.\n",
      "Iteration: 2979/8000, Loss: 0.126967340708.\n",
      "Iteration: 2980/8000, Loss: 0.126967310905.\n",
      "Iteration: 2981/8000, Loss: 0.126967281103.\n",
      "Iteration: 2982/8000, Loss: 0.126967251301.\n",
      "Iteration: 2983/8000, Loss: 0.126967221498.\n",
      "Iteration: 2984/8000, Loss: 0.126967191696.\n",
      "Iteration: 2985/8000, Loss: 0.126967146993.\n",
      "Iteration: 2986/8000, Loss: 0.12696711719.\n",
      "Iteration: 2987/8000, Loss: 0.126967087388.\n",
      "Iteration: 2988/8000, Loss: 0.126967057586.\n",
      "Iteration: 2989/8000, Loss: 0.126967012882.\n",
      "Iteration: 2990/8000, Loss: 0.12696698308.\n",
      "Iteration: 2991/8000, Loss: 0.126966953278.\n",
      "Iteration: 2992/8000, Loss: 0.126966908574.\n",
      "Iteration: 2993/8000, Loss: 0.126966893673.\n",
      "Iteration: 2994/8000, Loss: 0.126966863871.\n",
      "Iteration: 2995/8000, Loss: 0.126966819167.\n",
      "Iteration: 2996/8000, Loss: 0.126966789365.\n",
      "Iteration: 2997/8000, Loss: 0.126966774464.\n",
      "Iteration: 2998/8000, Loss: 0.12696672976.\n",
      "Iteration: 2999/8000, Loss: 0.126966685057.\n",
      "Iteration: 3000/8000, Loss: 0.126966655254.\n",
      "Iteration: 3001/8000, Loss: 0.126966625452.\n",
      "Iteration: 3002/8000, Loss: 0.12696659565.\n",
      "Iteration: 3003/8000, Loss: 0.126966565847.\n",
      "Iteration: 3004/8000, Loss: 0.126966536045.\n",
      "Iteration: 3005/8000, Loss: 0.126966506243.\n",
      "Iteration: 3006/8000, Loss: 0.12696647644.\n",
      "Iteration: 3007/8000, Loss: 0.126966431737.\n",
      "Iteration: 3008/8000, Loss: 0.126966401935.\n",
      "Iteration: 3009/8000, Loss: 0.126966372132.\n",
      "Iteration: 3010/8000, Loss: 0.12696634233.\n",
      "Iteration: 3011/8000, Loss: 0.126966312528.\n",
      "Iteration: 3012/8000, Loss: 0.126966282725.\n",
      "Iteration: 3013/8000, Loss: 0.126966238022.\n",
      "Iteration: 3014/8000, Loss: 0.12696620822.\n",
      "Iteration: 3015/8000, Loss: 0.126966178417.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3016/8000, Loss: 0.126966148615.\n",
      "Iteration: 3017/8000, Loss: 0.126966103911.\n",
      "Iteration: 3018/8000, Loss: 0.12696608901.\n",
      "Iteration: 3019/8000, Loss: 0.126966044307.\n",
      "Iteration: 3020/8000, Loss: 0.126966014504.\n",
      "Iteration: 3021/8000, Loss: 0.126965984702.\n",
      "Iteration: 3022/8000, Loss: 0.1269659549.\n",
      "Iteration: 3023/8000, Loss: 0.126965925097.\n",
      "Iteration: 3024/8000, Loss: 0.126965895295.\n",
      "Iteration: 3025/8000, Loss: 0.126965865493.\n",
      "Iteration: 3026/8000, Loss: 0.12696583569.\n",
      "Iteration: 3027/8000, Loss: 0.126965805888.\n",
      "Iteration: 3028/8000, Loss: 0.126965776086.\n",
      "Iteration: 3029/8000, Loss: 0.126965731382.\n",
      "Iteration: 3030/8000, Loss: 0.126965716481.\n",
      "Iteration: 3031/8000, Loss: 0.126965671778.\n",
      "Iteration: 3032/8000, Loss: 0.126965641975.\n",
      "Iteration: 3033/8000, Loss: 0.126965612173.\n",
      "Iteration: 3034/8000, Loss: 0.126965582371.\n",
      "Iteration: 3035/8000, Loss: 0.126965552568.\n",
      "Iteration: 3036/8000, Loss: 0.126965522766.\n",
      "Iteration: 3037/8000, Loss: 0.126965492964.\n",
      "Iteration: 3038/8000, Loss: 0.12696544826.\n",
      "Iteration: 3039/8000, Loss: 0.126965433359.\n",
      "Iteration: 3040/8000, Loss: 0.126965403557.\n",
      "Iteration: 3041/8000, Loss: 0.126965358853.\n",
      "Iteration: 3042/8000, Loss: 0.126965329051.\n",
      "Iteration: 3043/8000, Loss: 0.12696531415.\n",
      "Iteration: 3044/8000, Loss: 0.126965269446.\n",
      "Iteration: 3045/8000, Loss: 0.126965239644.\n",
      "Iteration: 3046/8000, Loss: 0.126965209842.\n",
      "Iteration: 3047/8000, Loss: 0.126965194941.\n",
      "Iteration: 3048/8000, Loss: 0.126965135336.\n",
      "Iteration: 3049/8000, Loss: 0.126965120435.\n",
      "Iteration: 3050/8000, Loss: 0.126965090632.\n",
      "Iteration: 3051/8000, Loss: 0.12696506083.\n",
      "Iteration: 3052/8000, Loss: 0.126965031028.\n",
      "Iteration: 3053/8000, Loss: 0.126964986324.\n",
      "Iteration: 3054/8000, Loss: 0.126964986324.\n",
      "Iteration: 3055/8000, Loss: 0.12696492672.\n",
      "Iteration: 3056/8000, Loss: 0.126964896917.\n",
      "Iteration: 3057/8000, Loss: 0.126964867115.\n",
      "Iteration: 3058/8000, Loss: 0.126964837313.\n",
      "Iteration: 3059/8000, Loss: 0.12696480751.\n",
      "Iteration: 3060/8000, Loss: 0.126964777708.\n",
      "Iteration: 3061/8000, Loss: 0.126964747906.\n",
      "Iteration: 3062/8000, Loss: 0.126964718103.\n",
      "Iteration: 3063/8000, Loss: 0.126964688301.\n",
      "Iteration: 3064/8000, Loss: 0.126964658499.\n",
      "Iteration: 3065/8000, Loss: 0.126964628696.\n",
      "Iteration: 3066/8000, Loss: 0.126964598894.\n",
      "Iteration: 3067/8000, Loss: 0.126964569092.\n",
      "Iteration: 3068/8000, Loss: 0.126964539289.\n",
      "Iteration: 3069/8000, Loss: 0.126964509487.\n",
      "Iteration: 3070/8000, Loss: 0.126964479685.\n",
      "Iteration: 3071/8000, Loss: 0.126964449883.\n",
      "Iteration: 3072/8000, Loss: 0.12696442008.\n",
      "Iteration: 3073/8000, Loss: 0.126964390278.\n",
      "Iteration: 3074/8000, Loss: 0.126964345574.\n",
      "Iteration: 3075/8000, Loss: 0.126964330673.\n",
      "Iteration: 3076/8000, Loss: 0.126964300871.\n",
      "Iteration: 3077/8000, Loss: 0.126964271069.\n",
      "Iteration: 3078/8000, Loss: 0.126964241266.\n",
      "Iteration: 3079/8000, Loss: 0.126964226365.\n",
      "Iteration: 3080/8000, Loss: 0.12696416676.\n",
      "Iteration: 3081/8000, Loss: 0.126964151859.\n",
      "Iteration: 3082/8000, Loss: 0.126964122057.\n",
      "Iteration: 3083/8000, Loss: 0.126964092255.\n",
      "Iteration: 3084/8000, Loss: 0.126964062452.\n",
      "Iteration: 3085/8000, Loss: 0.12696403265.\n",
      "Iteration: 3086/8000, Loss: 0.126964002848.\n",
      "Iteration: 3087/8000, Loss: 0.126963973045.\n",
      "Iteration: 3088/8000, Loss: 0.126963943243.\n",
      "Iteration: 3089/8000, Loss: 0.126963913441.\n",
      "Iteration: 3090/8000, Loss: 0.126963883638.\n",
      "Iteration: 3091/8000, Loss: 0.126963853836.\n",
      "Iteration: 3092/8000, Loss: 0.126963838935.\n",
      "Iteration: 3093/8000, Loss: 0.126963794231.\n",
      "Iteration: 3094/8000, Loss: 0.126963764429.\n",
      "Iteration: 3095/8000, Loss: 0.126963734627.\n",
      "Iteration: 3096/8000, Loss: 0.126963704824.\n",
      "Iteration: 3097/8000, Loss: 0.126963675022.\n",
      "Iteration: 3098/8000, Loss: 0.126963660121.\n",
      "Iteration: 3099/8000, Loss: 0.126963615417.\n",
      "Iteration: 3100/8000, Loss: 0.126963585615.\n",
      "Iteration: 3101/8000, Loss: 0.126963555813.\n",
      "Iteration: 3102/8000, Loss: 0.126963540912.\n",
      "Iteration: 3103/8000, Loss: 0.126963511109.\n",
      "Iteration: 3104/8000, Loss: 0.126963481307.\n",
      "Iteration: 3105/8000, Loss: 0.126963451505.\n",
      "Iteration: 3106/8000, Loss: 0.126963421702.\n",
      "Iteration: 3107/8000, Loss: 0.126963376999.\n",
      "Iteration: 3108/8000, Loss: 0.126963362098.\n",
      "Iteration: 3109/8000, Loss: 0.126963332295.\n",
      "Iteration: 3110/8000, Loss: 0.126963302493.\n",
      "Iteration: 3111/8000, Loss: 0.126963272691.\n",
      "Iteration: 3112/8000, Loss: 0.126963242888.\n",
      "Iteration: 3113/8000, Loss: 0.126963213086.\n",
      "Iteration: 3114/8000, Loss: 0.126963183284.\n",
      "Iteration: 3115/8000, Loss: 0.126963153481.\n",
      "Iteration: 3116/8000, Loss: 0.126963123679.\n",
      "Iteration: 3117/8000, Loss: 0.126963108778.\n",
      "Iteration: 3118/8000, Loss: 0.126963078976.\n",
      "Iteration: 3119/8000, Loss: 0.126963049173.\n",
      "Iteration: 3120/8000, Loss: 0.126963019371.\n",
      "Iteration: 3121/8000, Loss: 0.126962989569.\n",
      "Iteration: 3122/8000, Loss: 0.126962959766.\n",
      "Iteration: 3123/8000, Loss: 0.126962929964.\n",
      "Iteration: 3124/8000, Loss: 0.126962900162.\n",
      "Iteration: 3125/8000, Loss: 0.126962870359.\n",
      "Iteration: 3126/8000, Loss: 0.126962840557.\n",
      "Iteration: 3127/8000, Loss: 0.126962810755.\n",
      "Iteration: 3128/8000, Loss: 0.126962780952.\n",
      "Iteration: 3129/8000, Loss: 0.126962766051.\n",
      "Iteration: 3130/8000, Loss: 0.126962721348.\n",
      "Iteration: 3131/8000, Loss: 0.126962691545.\n",
      "Iteration: 3132/8000, Loss: 0.126962676644.\n",
      "Iteration: 3133/8000, Loss: 0.126962646842.\n",
      "Iteration: 3134/8000, Loss: 0.12696261704.\n",
      "Iteration: 3135/8000, Loss: 0.126962587237.\n",
      "Iteration: 3136/8000, Loss: 0.126962557435.\n",
      "Iteration: 3137/8000, Loss: 0.126962527633.\n",
      "Iteration: 3138/8000, Loss: 0.126962512732.\n",
      "Iteration: 3139/8000, Loss: 0.126962482929.\n",
      "Iteration: 3140/8000, Loss: 0.126962453127.\n",
      "Iteration: 3141/8000, Loss: 0.126962423325.\n",
      "Iteration: 3142/8000, Loss: 0.126962393522.\n",
      "Iteration: 3143/8000, Loss: 0.126962348819.\n",
      "Iteration: 3144/8000, Loss: 0.126962333918.\n",
      "Iteration: 3145/8000, Loss: 0.126962319016.\n",
      "Iteration: 3146/8000, Loss: 0.126962274313.\n",
      "Iteration: 3147/8000, Loss: 0.126962244511.\n",
      "Iteration: 3148/8000, Loss: 0.126962214708.\n",
      "Iteration: 3149/8000, Loss: 0.126962184906.\n",
      "Iteration: 3150/8000, Loss: 0.126962170005.\n",
      "Iteration: 3151/8000, Loss: 0.126962155104.\n",
      "Iteration: 3152/8000, Loss: 0.1269621104.\n",
      "Iteration: 3153/8000, Loss: 0.126962080598.\n",
      "Iteration: 3154/8000, Loss: 0.126962065697.\n",
      "Iteration: 3155/8000, Loss: 0.126962020993.\n",
      "Iteration: 3156/8000, Loss: 0.126962006092.\n",
      "Iteration: 3157/8000, Loss: 0.12696197629.\n",
      "Iteration: 3158/8000, Loss: 0.126961946487.\n",
      "Iteration: 3159/8000, Loss: 0.126961916685.\n",
      "Iteration: 3160/8000, Loss: 0.126961901784.\n",
      "Iteration: 3161/8000, Loss: 0.12696185708.\n",
      "Iteration: 3162/8000, Loss: 0.126961842179.\n",
      "Iteration: 3163/8000, Loss: 0.126961812377.\n",
      "Iteration: 3164/8000, Loss: 0.126961782575.\n",
      "Iteration: 3165/8000, Loss: 0.126961767673.\n",
      "Iteration: 3166/8000, Loss: 0.12696172297.\n",
      "Iteration: 3167/8000, Loss: 0.126961708069.\n",
      "Iteration: 3168/8000, Loss: 0.126961678267.\n",
      "Iteration: 3169/8000, Loss: 0.126961648464.\n",
      "Iteration: 3170/8000, Loss: 0.126961618662.\n",
      "Iteration: 3171/8000, Loss: 0.12696158886.\n",
      "Iteration: 3172/8000, Loss: 0.126961573958.\n",
      "Iteration: 3173/8000, Loss: 0.126961529255.\n",
      "Iteration: 3174/8000, Loss: 0.126961514354.\n",
      "Iteration: 3175/8000, Loss: 0.126961484551.\n",
      "Iteration: 3176/8000, Loss: 0.126961454749.\n",
      "Iteration: 3177/8000, Loss: 0.126961439848.\n",
      "Iteration: 3178/8000, Loss: 0.126961410046.\n",
      "Iteration: 3179/8000, Loss: 0.126961380243.\n",
      "Iteration: 3180/8000, Loss: 0.126961350441.\n",
      "Iteration: 3181/8000, Loss: 0.126961320639.\n",
      "Iteration: 3182/8000, Loss: 0.126961290836.\n",
      "Iteration: 3183/8000, Loss: 0.126961261034.\n",
      "Iteration: 3184/8000, Loss: 0.126961246133.\n",
      "Iteration: 3185/8000, Loss: 0.126961216331.\n",
      "Iteration: 3186/8000, Loss: 0.126961186528.\n",
      "Iteration: 3187/8000, Loss: 0.126961171627.\n",
      "Iteration: 3188/8000, Loss: 0.126961126924.\n",
      "Iteration: 3189/8000, Loss: 0.126961112022.\n",
      "Iteration: 3190/8000, Loss: 0.12696108222.\n",
      "Iteration: 3191/8000, Loss: 0.126961052418.\n",
      "Iteration: 3192/8000, Loss: 0.126961022615.\n",
      "Iteration: 3193/8000, Loss: 0.126960992813.\n",
      "Iteration: 3194/8000, Loss: 0.126960977912.\n",
      "Iteration: 3195/8000, Loss: 0.12696094811.\n",
      "Iteration: 3196/8000, Loss: 0.126960918307.\n",
      "Iteration: 3197/8000, Loss: 0.126960888505.\n",
      "Iteration: 3198/8000, Loss: 0.126960858703.\n",
      "Iteration: 3199/8000, Loss: 0.126960843801.\n",
      "Iteration: 3200/8000, Loss: 0.126960813999.\n",
      "Iteration: 3201/8000, Loss: 0.126960784197.\n",
      "Iteration: 3202/8000, Loss: 0.126960754395.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3203/8000, Loss: 0.126960739493.\n",
      "Iteration: 3204/8000, Loss: 0.126960709691.\n",
      "Iteration: 3205/8000, Loss: 0.126960664988.\n",
      "Iteration: 3206/8000, Loss: 0.126960650086.\n",
      "Iteration: 3207/8000, Loss: 0.126960635185.\n",
      "Iteration: 3208/8000, Loss: 0.126960590482.\n",
      "Iteration: 3209/8000, Loss: 0.126960575581.\n",
      "Iteration: 3210/8000, Loss: 0.126960545778.\n",
      "Iteration: 3211/8000, Loss: 0.126960515976.\n",
      "Iteration: 3212/8000, Loss: 0.126960486174.\n",
      "Iteration: 3213/8000, Loss: 0.126960486174.\n",
      "Iteration: 3214/8000, Loss: 0.12696044147.\n",
      "Iteration: 3215/8000, Loss: 0.126960411668.\n",
      "Iteration: 3216/8000, Loss: 0.126960396767.\n",
      "Iteration: 3217/8000, Loss: 0.126960366964.\n",
      "Iteration: 3218/8000, Loss: 0.126960337162.\n",
      "Iteration: 3219/8000, Loss: 0.12696030736.\n",
      "Iteration: 3220/8000, Loss: 0.126960277557.\n",
      "Iteration: 3221/8000, Loss: 0.126960262656.\n",
      "Iteration: 3222/8000, Loss: 0.126960247755.\n",
      "Iteration: 3223/8000, Loss: 0.126960217953.\n",
      "Iteration: 3224/8000, Loss: 0.12696018815.\n",
      "Iteration: 3225/8000, Loss: 0.126960158348.\n",
      "Iteration: 3226/8000, Loss: 0.126960128546.\n",
      "Iteration: 3227/8000, Loss: 0.126960113645.\n",
      "Iteration: 3228/8000, Loss: 0.126960083842.\n",
      "Iteration: 3229/8000, Loss: 0.12696005404.\n",
      "Iteration: 3230/8000, Loss: 0.126960024238.\n",
      "Iteration: 3231/8000, Loss: 0.126959994435.\n",
      "Iteration: 3232/8000, Loss: 0.126959979534.\n",
      "Iteration: 3233/8000, Loss: 0.126959949732.\n",
      "Iteration: 3234/8000, Loss: 0.12695991993.\n",
      "Iteration: 3235/8000, Loss: 0.126959905028.\n",
      "Iteration: 3236/8000, Loss: 0.126959875226.\n",
      "Iteration: 3237/8000, Loss: 0.126959860325.\n",
      "Iteration: 3238/8000, Loss: 0.126959815621.\n",
      "Iteration: 3239/8000, Loss: 0.12695980072.\n",
      "Iteration: 3240/8000, Loss: 0.126959770918.\n",
      "Iteration: 3241/8000, Loss: 0.126959756017.\n",
      "Iteration: 3242/8000, Loss: 0.126959726214.\n",
      "Iteration: 3243/8000, Loss: 0.126959696412.\n",
      "Iteration: 3244/8000, Loss: 0.12695966661.\n",
      "Iteration: 3245/8000, Loss: 0.126959651709.\n",
      "Iteration: 3246/8000, Loss: 0.126959621906.\n",
      "Iteration: 3247/8000, Loss: 0.126959592104.\n",
      "Iteration: 3248/8000, Loss: 0.126959562302.\n",
      "Iteration: 3249/8000, Loss: 0.1269595474.\n",
      "Iteration: 3250/8000, Loss: 0.126959517598.\n",
      "Iteration: 3251/8000, Loss: 0.126959502697.\n",
      "Iteration: 3252/8000, Loss: 0.126959472895.\n",
      "Iteration: 3253/8000, Loss: 0.126959443092.\n",
      "Iteration: 3254/8000, Loss: 0.12695941329.\n",
      "Iteration: 3255/8000, Loss: 0.126959383488.\n",
      "Iteration: 3256/8000, Loss: 0.126959368587.\n",
      "Iteration: 3257/8000, Loss: 0.126959338784.\n",
      "Iteration: 3258/8000, Loss: 0.126959308982.\n",
      "Iteration: 3259/8000, Loss: 0.126959294081.\n",
      "Iteration: 3260/8000, Loss: 0.12695927918.\n",
      "Iteration: 3261/8000, Loss: 0.126959234476.\n",
      "Iteration: 3262/8000, Loss: 0.126959219575.\n",
      "Iteration: 3263/8000, Loss: 0.126959189773.\n",
      "Iteration: 3264/8000, Loss: 0.126959174871.\n",
      "Iteration: 3265/8000, Loss: 0.126959145069.\n",
      "Iteration: 3266/8000, Loss: 0.126959130168.\n",
      "Iteration: 3267/8000, Loss: 0.126959085464.\n",
      "Iteration: 3268/8000, Loss: 0.126959070563.\n",
      "Iteration: 3269/8000, Loss: 0.126959040761.\n",
      "Iteration: 3270/8000, Loss: 0.12695902586.\n",
      "Iteration: 3271/8000, Loss: 0.126958996058.\n",
      "Iteration: 3272/8000, Loss: 0.126958981156.\n",
      "Iteration: 3273/8000, Loss: 0.126958936453.\n",
      "Iteration: 3274/8000, Loss: 0.126958906651.\n",
      "Iteration: 3275/8000, Loss: 0.126958891749.\n",
      "Iteration: 3276/8000, Loss: 0.126958876848.\n",
      "Iteration: 3277/8000, Loss: 0.126958847046.\n",
      "Iteration: 3278/8000, Loss: 0.126958832145.\n",
      "Iteration: 3279/8000, Loss: 0.126958802342.\n",
      "Iteration: 3280/8000, Loss: 0.126958787441.\n",
      "Iteration: 3281/8000, Loss: 0.126958757639.\n",
      "Iteration: 3282/8000, Loss: 0.126958712935.\n",
      "Iteration: 3283/8000, Loss: 0.126958698034.\n",
      "Iteration: 3284/8000, Loss: 0.126958683133.\n",
      "Iteration: 3285/8000, Loss: 0.12695863843.\n",
      "Iteration: 3286/8000, Loss: 0.126958623528.\n",
      "Iteration: 3287/8000, Loss: 0.126958608627.\n",
      "Iteration: 3288/8000, Loss: 0.126958578825.\n",
      "Iteration: 3289/8000, Loss: 0.126958549023.\n",
      "Iteration: 3290/8000, Loss: 0.12695851922.\n",
      "Iteration: 3291/8000, Loss: 0.12695851922.\n",
      "Iteration: 3292/8000, Loss: 0.126958489418.\n",
      "Iteration: 3293/8000, Loss: 0.126958444715.\n",
      "Iteration: 3294/8000, Loss: 0.126958429813.\n",
      "Iteration: 3295/8000, Loss: 0.126958414912.\n",
      "Iteration: 3296/8000, Loss: 0.12695838511.\n",
      "Iteration: 3297/8000, Loss: 0.126958355308.\n",
      "Iteration: 3298/8000, Loss: 0.126958340406.\n",
      "Iteration: 3299/8000, Loss: 0.126958310604.\n",
      "Iteration: 3300/8000, Loss: 0.126958280802.\n",
      "Iteration: 3301/8000, Loss: 0.126958265901.\n",
      "Iteration: 3302/8000, Loss: 0.126958236098.\n",
      "Iteration: 3303/8000, Loss: 0.126958221197.\n",
      "Iteration: 3304/8000, Loss: 0.126958191395.\n",
      "Iteration: 3305/8000, Loss: 0.126958161592.\n",
      "Iteration: 3306/8000, Loss: 0.126958146691.\n",
      "Iteration: 3307/8000, Loss: 0.126958116889.\n",
      "Iteration: 3308/8000, Loss: 0.126958101988.\n",
      "Iteration: 3309/8000, Loss: 0.126958072186.\n",
      "Iteration: 3310/8000, Loss: 0.126958042383.\n",
      "Iteration: 3311/8000, Loss: 0.126958027482.\n",
      "Iteration: 3312/8000, Loss: 0.126958012581.\n",
      "Iteration: 3313/8000, Loss: 0.126957982779.\n",
      "Iteration: 3314/8000, Loss: 0.126957952976.\n",
      "Iteration: 3315/8000, Loss: 0.126957938075.\n",
      "Iteration: 3316/8000, Loss: 0.126957908273.\n",
      "Iteration: 3317/8000, Loss: 0.12695787847.\n",
      "Iteration: 3318/8000, Loss: 0.126957863569.\n",
      "Iteration: 3319/8000, Loss: 0.126957848668.\n",
      "Iteration: 3320/8000, Loss: 0.126957803965.\n",
      "Iteration: 3321/8000, Loss: 0.126957789063.\n",
      "Iteration: 3322/8000, Loss: 0.126957759261.\n",
      "Iteration: 3323/8000, Loss: 0.12695774436.\n",
      "Iteration: 3324/8000, Loss: 0.126957714558.\n",
      "Iteration: 3325/8000, Loss: 0.126957684755.\n",
      "Iteration: 3326/8000, Loss: 0.126957669854.\n",
      "Iteration: 3327/8000, Loss: 0.126957640052.\n",
      "Iteration: 3328/8000, Loss: 0.126957625151.\n",
      "Iteration: 3329/8000, Loss: 0.126957595348.\n",
      "Iteration: 3330/8000, Loss: 0.126957565546.\n",
      "Iteration: 3331/8000, Loss: 0.126957565546.\n",
      "Iteration: 3332/8000, Loss: 0.126957535744.\n",
      "Iteration: 3333/8000, Loss: 0.126957505941.\n",
      "Iteration: 3334/8000, Loss: 0.12695749104.\n",
      "Iteration: 3335/8000, Loss: 0.126957461238.\n",
      "Iteration: 3336/8000, Loss: 0.126957431436.\n",
      "Iteration: 3337/8000, Loss: 0.126957401633.\n",
      "Iteration: 3338/8000, Loss: 0.126957386732.\n",
      "Iteration: 3339/8000, Loss: 0.12695735693.\n",
      "Iteration: 3340/8000, Loss: 0.126957342029.\n",
      "Iteration: 3341/8000, Loss: 0.126957312226.\n",
      "Iteration: 3342/8000, Loss: 0.126957297325.\n",
      "Iteration: 3343/8000, Loss: 0.126957267523.\n",
      "Iteration: 3344/8000, Loss: 0.12695723772.\n",
      "Iteration: 3345/8000, Loss: 0.12695723772.\n",
      "Iteration: 3346/8000, Loss: 0.126957207918.\n",
      "Iteration: 3347/8000, Loss: 0.126957178116.\n",
      "Iteration: 3348/8000, Loss: 0.126957148314.\n",
      "Iteration: 3349/8000, Loss: 0.126957133412.\n",
      "Iteration: 3350/8000, Loss: 0.126957118511.\n",
      "Iteration: 3351/8000, Loss: 0.126957073808.\n",
      "Iteration: 3352/8000, Loss: 0.126957058907.\n",
      "Iteration: 3353/8000, Loss: 0.126957029104.\n",
      "Iteration: 3354/8000, Loss: 0.126957029104.\n",
      "Iteration: 3355/8000, Loss: 0.126956999302.\n",
      "Iteration: 3356/8000, Loss: 0.1269569695.\n",
      "Iteration: 3357/8000, Loss: 0.126956939697.\n",
      "Iteration: 3358/8000, Loss: 0.126956924796.\n",
      "Iteration: 3359/8000, Loss: 0.126956909895.\n",
      "Iteration: 3360/8000, Loss: 0.126956880093.\n",
      "Iteration: 3361/8000, Loss: 0.12695685029.\n",
      "Iteration: 3362/8000, Loss: 0.126956835389.\n",
      "Iteration: 3363/8000, Loss: 0.126956805587.\n",
      "Iteration: 3364/8000, Loss: 0.126956790686.\n",
      "Iteration: 3365/8000, Loss: 0.126956760883.\n",
      "Iteration: 3366/8000, Loss: 0.126956731081.\n",
      "Iteration: 3367/8000, Loss: 0.12695671618.\n",
      "Iteration: 3368/8000, Loss: 0.126956701279.\n",
      "Iteration: 3369/8000, Loss: 0.126956686378.\n",
      "Iteration: 3370/8000, Loss: 0.126956641674.\n",
      "Iteration: 3371/8000, Loss: 0.126956641674.\n",
      "Iteration: 3372/8000, Loss: 0.126956611872.\n",
      "Iteration: 3373/8000, Loss: 0.126956596971.\n",
      "Iteration: 3374/8000, Loss: 0.126956567168.\n",
      "Iteration: 3375/8000, Loss: 0.126956537366.\n",
      "Iteration: 3376/8000, Loss: 0.126956522465.\n",
      "Iteration: 3377/8000, Loss: 0.126956492662.\n",
      "Iteration: 3378/8000, Loss: 0.126956477761.\n",
      "Iteration: 3379/8000, Loss: 0.126956433058.\n",
      "Iteration: 3380/8000, Loss: 0.126956433058.\n",
      "Iteration: 3381/8000, Loss: 0.126956403255.\n",
      "Iteration: 3382/8000, Loss: 0.126956388354.\n",
      "Iteration: 3383/8000, Loss: 0.126956373453.\n",
      "Iteration: 3384/8000, Loss: 0.126956343651.\n",
      "Iteration: 3385/8000, Loss: 0.126956313848.\n",
      "Iteration: 3386/8000, Loss: 0.126956284046.\n",
      "Iteration: 3387/8000, Loss: 0.126956269145.\n",
      "Iteration: 3388/8000, Loss: 0.126956254244.\n",
      "Iteration: 3389/8000, Loss: 0.126956239343.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3390/8000, Loss: 0.126956224442.\n",
      "Iteration: 3391/8000, Loss: 0.126956179738.\n",
      "Iteration: 3392/8000, Loss: 0.126956164837.\n",
      "Iteration: 3393/8000, Loss: 0.126956135035.\n",
      "Iteration: 3394/8000, Loss: 0.126956120133.\n",
      "Iteration: 3395/8000, Loss: 0.126956090331.\n",
      "Iteration: 3396/8000, Loss: 0.12695607543.\n",
      "Iteration: 3397/8000, Loss: 0.126956060529.\n",
      "Iteration: 3398/8000, Loss: 0.126956030726.\n",
      "Iteration: 3399/8000, Loss: 0.126956000924.\n",
      "Iteration: 3400/8000, Loss: 0.126956000924.\n",
      "Iteration: 3401/8000, Loss: 0.126955956221.\n",
      "Iteration: 3402/8000, Loss: 0.126955941319.\n",
      "Iteration: 3403/8000, Loss: 0.126955926418.\n",
      "Iteration: 3404/8000, Loss: 0.126955896616.\n",
      "Iteration: 3405/8000, Loss: 0.126955881715.\n",
      "Iteration: 3406/8000, Loss: 0.126955866814.\n",
      "Iteration: 3407/8000, Loss: 0.126955837011.\n",
      "Iteration: 3408/8000, Loss: 0.12695582211.\n",
      "Iteration: 3409/8000, Loss: 0.126955777407.\n",
      "Iteration: 3410/8000, Loss: 0.126955762506.\n",
      "Iteration: 3411/8000, Loss: 0.126955732703.\n",
      "Iteration: 3412/8000, Loss: 0.126955717802.\n",
      "Iteration: 3413/8000, Loss: 0.126955688.\n",
      "Iteration: 3414/8000, Loss: 0.126955673099.\n",
      "Iteration: 3415/8000, Loss: 0.126955658197.\n",
      "Iteration: 3416/8000, Loss: 0.126955628395.\n",
      "Iteration: 3417/8000, Loss: 0.126955613494.\n",
      "Iteration: 3418/8000, Loss: 0.126955598593.\n",
      "Iteration: 3419/8000, Loss: 0.12695556879.\n",
      "Iteration: 3420/8000, Loss: 0.126955553889.\n",
      "Iteration: 3421/8000, Loss: 0.126955538988.\n",
      "Iteration: 3422/8000, Loss: 0.126955509186.\n",
      "Iteration: 3423/8000, Loss: 0.126955494285.\n",
      "Iteration: 3424/8000, Loss: 0.126955464482.\n",
      "Iteration: 3425/8000, Loss: 0.126955449581.\n",
      "Iteration: 3426/8000, Loss: 0.126955419779.\n",
      "Iteration: 3427/8000, Loss: 0.126955404878.\n",
      "Iteration: 3428/8000, Loss: 0.126955375075.\n",
      "Iteration: 3429/8000, Loss: 0.126955360174.\n",
      "Iteration: 3430/8000, Loss: 0.126955330372.\n",
      "Iteration: 3431/8000, Loss: 0.126955315471.\n",
      "Iteration: 3432/8000, Loss: 0.126955285668.\n",
      "Iteration: 3433/8000, Loss: 0.126955285668.\n",
      "Iteration: 3434/8000, Loss: 0.126955240965.\n",
      "Iteration: 3435/8000, Loss: 0.126955240965.\n",
      "Iteration: 3436/8000, Loss: 0.126955211163.\n",
      "Iteration: 3437/8000, Loss: 0.126955196261.\n",
      "Iteration: 3438/8000, Loss: 0.126955151558.\n",
      "Iteration: 3439/8000, Loss: 0.126955151558.\n",
      "Iteration: 3440/8000, Loss: 0.126955121756.\n",
      "Iteration: 3441/8000, Loss: 0.126955106854.\n",
      "Iteration: 3442/8000, Loss: 0.126955091953.\n",
      "Iteration: 3443/8000, Loss: 0.126955062151.\n",
      "Iteration: 3444/8000, Loss: 0.126955032349.\n",
      "Iteration: 3445/8000, Loss: 0.126955032349.\n",
      "Iteration: 3446/8000, Loss: 0.126955002546.\n",
      "Iteration: 3447/8000, Loss: 0.126954972744.\n",
      "Iteration: 3448/8000, Loss: 0.126954957843.\n",
      "Iteration: 3449/8000, Loss: 0.126954928041.\n",
      "Iteration: 3450/8000, Loss: 0.126954928041.\n",
      "Iteration: 3451/8000, Loss: 0.126954883337.\n",
      "Iteration: 3452/8000, Loss: 0.126954868436.\n",
      "Iteration: 3453/8000, Loss: 0.126954853535.\n",
      "Iteration: 3454/8000, Loss: 0.126954838634.\n",
      "Iteration: 3455/8000, Loss: 0.126954808831.\n",
      "Iteration: 3456/8000, Loss: 0.12695479393.\n",
      "Iteration: 3457/8000, Loss: 0.126954764128.\n",
      "Iteration: 3458/8000, Loss: 0.126954749227.\n",
      "Iteration: 3459/8000, Loss: 0.126954734325.\n",
      "Iteration: 3460/8000, Loss: 0.126954704523.\n",
      "Iteration: 3461/8000, Loss: 0.126954689622.\n",
      "Iteration: 3462/8000, Loss: 0.126954674721.\n",
      "Iteration: 3463/8000, Loss: 0.126954644918.\n",
      "Iteration: 3464/8000, Loss: 0.126954630017.\n",
      "Iteration: 3465/8000, Loss: 0.126954600215.\n",
      "Iteration: 3466/8000, Loss: 0.126954585314.\n",
      "Iteration: 3467/8000, Loss: 0.126954555511.\n",
      "Iteration: 3468/8000, Loss: 0.12695454061.\n",
      "Iteration: 3469/8000, Loss: 0.126954510808.\n",
      "Iteration: 3470/8000, Loss: 0.126954495907.\n",
      "Iteration: 3471/8000, Loss: 0.126954481006.\n",
      "Iteration: 3472/8000, Loss: 0.126954466105.\n",
      "Iteration: 3473/8000, Loss: 0.126954436302.\n",
      "Iteration: 3474/8000, Loss: 0.126954421401.\n",
      "Iteration: 3475/8000, Loss: 0.1269544065.\n",
      "Iteration: 3476/8000, Loss: 0.126954376698.\n",
      "Iteration: 3477/8000, Loss: 0.126954346895.\n",
      "Iteration: 3478/8000, Loss: 0.126954331994.\n",
      "Iteration: 3479/8000, Loss: 0.126954302192.\n",
      "Iteration: 3480/8000, Loss: 0.126954287291.\n",
      "Iteration: 3481/8000, Loss: 0.126954272389.\n",
      "Iteration: 3482/8000, Loss: 0.126954242587.\n",
      "Iteration: 3483/8000, Loss: 0.126954227686.\n",
      "Iteration: 3484/8000, Loss: 0.126954227686.\n",
      "Iteration: 3485/8000, Loss: 0.126954182982.\n",
      "Iteration: 3486/8000, Loss: 0.126954182982.\n",
      "Iteration: 3487/8000, Loss: 0.126954138279.\n",
      "Iteration: 3488/8000, Loss: 0.126954138279.\n",
      "Iteration: 3489/8000, Loss: 0.126954108477.\n",
      "Iteration: 3490/8000, Loss: 0.126954093575.\n",
      "Iteration: 3491/8000, Loss: 0.126954078674.\n",
      "Iteration: 3492/8000, Loss: 0.126954048872.\n",
      "Iteration: 3493/8000, Loss: 0.12695401907.\n",
      "Iteration: 3494/8000, Loss: 0.126954004169.\n",
      "Iteration: 3495/8000, Loss: 0.126953989267.\n",
      "Iteration: 3496/8000, Loss: 0.126953959465.\n",
      "Iteration: 3497/8000, Loss: 0.126953944564.\n",
      "Iteration: 3498/8000, Loss: 0.126953929663.\n",
      "Iteration: 3499/8000, Loss: 0.126953914762.\n",
      "Iteration: 3500/8000, Loss: 0.126953884959.\n",
      "Iteration: 3501/8000, Loss: 0.126953870058.\n",
      "Iteration: 3502/8000, Loss: 0.126953840256.\n",
      "Iteration: 3503/8000, Loss: 0.126953840256.\n",
      "Iteration: 3504/8000, Loss: 0.126953810453.\n",
      "Iteration: 3505/8000, Loss: 0.126953795552.\n",
      "Iteration: 3506/8000, Loss: 0.126953780651.\n",
      "Iteration: 3507/8000, Loss: 0.126953750849.\n",
      "Iteration: 3508/8000, Loss: 0.126953735948.\n",
      "Iteration: 3509/8000, Loss: 0.126953721046.\n",
      "Iteration: 3510/8000, Loss: 0.126953691244.\n",
      "Iteration: 3511/8000, Loss: 0.126953661442.\n",
      "Iteration: 3512/8000, Loss: 0.126953646541.\n",
      "Iteration: 3513/8000, Loss: 0.126953616738.\n",
      "Iteration: 3514/8000, Loss: 0.126953616738.\n",
      "Iteration: 3515/8000, Loss: 0.126953586936.\n",
      "Iteration: 3516/8000, Loss: 0.126953572035.\n",
      "Iteration: 3517/8000, Loss: 0.126953542233.\n",
      "Iteration: 3518/8000, Loss: 0.126953527331.\n",
      "Iteration: 3519/8000, Loss: 0.12695351243.\n",
      "Iteration: 3520/8000, Loss: 0.126953482628.\n",
      "Iteration: 3521/8000, Loss: 0.126953467727.\n",
      "Iteration: 3522/8000, Loss: 0.126953452826.\n",
      "Iteration: 3523/8000, Loss: 0.126953423023.\n",
      "Iteration: 3524/8000, Loss: 0.126953408122.\n",
      "Iteration: 3525/8000, Loss: 0.126953393221.\n",
      "Iteration: 3526/8000, Loss: 0.126953363419.\n",
      "Iteration: 3527/8000, Loss: 0.126953348517.\n",
      "Iteration: 3528/8000, Loss: 0.126953333616.\n",
      "Iteration: 3529/8000, Loss: 0.126953318715.\n",
      "Iteration: 3530/8000, Loss: 0.126953288913.\n",
      "Iteration: 3531/8000, Loss: 0.126953274012.\n",
      "Iteration: 3532/8000, Loss: 0.126953244209.\n",
      "Iteration: 3533/8000, Loss: 0.126953244209.\n",
      "Iteration: 3534/8000, Loss: 0.126953214407.\n",
      "Iteration: 3535/8000, Loss: 0.126953184605.\n",
      "Iteration: 3536/8000, Loss: 0.126953169703.\n",
      "Iteration: 3537/8000, Loss: 0.126953139901.\n",
      "Iteration: 3538/8000, Loss: 0.126953125.\n",
      "Iteration: 3539/8000, Loss: 0.126953110099.\n",
      "Iteration: 3540/8000, Loss: 0.126953095198.\n",
      "Iteration: 3541/8000, Loss: 0.126953080297.\n",
      "Iteration: 3542/8000, Loss: 0.126953050494.\n",
      "Iteration: 3543/8000, Loss: 0.126953035593.\n",
      "Iteration: 3544/8000, Loss: 0.126953020692.\n",
      "Iteration: 3545/8000, Loss: 0.126953005791.\n",
      "Iteration: 3546/8000, Loss: 0.126952975988.\n",
      "Iteration: 3547/8000, Loss: 0.126952961087.\n",
      "Iteration: 3548/8000, Loss: 0.126952931285.\n",
      "Iteration: 3549/8000, Loss: 0.126952916384.\n",
      "Iteration: 3550/8000, Loss: 0.126952916384.\n",
      "Iteration: 3551/8000, Loss: 0.126952886581.\n",
      "Iteration: 3552/8000, Loss: 0.126952856779.\n",
      "Iteration: 3553/8000, Loss: 0.126952841878.\n",
      "Iteration: 3554/8000, Loss: 0.126952826977.\n",
      "Iteration: 3555/8000, Loss: 0.126952797174.\n",
      "Iteration: 3556/8000, Loss: 0.126952797174.\n",
      "Iteration: 3557/8000, Loss: 0.126952767372.\n",
      "Iteration: 3558/8000, Loss: 0.12695273757.\n",
      "Iteration: 3559/8000, Loss: 0.12695273757.\n",
      "Iteration: 3560/8000, Loss: 0.126952707767.\n",
      "Iteration: 3561/8000, Loss: 0.126952692866.\n",
      "Iteration: 3562/8000, Loss: 0.126952663064.\n",
      "Iteration: 3563/8000, Loss: 0.126952648163.\n",
      "Iteration: 3564/8000, Loss: 0.126952633262.\n",
      "Iteration: 3565/8000, Loss: 0.126952618361.\n",
      "Iteration: 3566/8000, Loss: 0.126952603459.\n",
      "Iteration: 3567/8000, Loss: 0.126952573657.\n",
      "Iteration: 3568/8000, Loss: 0.126952573657.\n",
      "Iteration: 3569/8000, Loss: 0.126952528954.\n",
      "Iteration: 3570/8000, Loss: 0.126952528954.\n",
      "Iteration: 3571/8000, Loss: 0.126952499151.\n",
      "Iteration: 3572/8000, Loss: 0.12695248425.\n",
      "Iteration: 3573/8000, Loss: 0.126952469349.\n",
      "Iteration: 3574/8000, Loss: 0.126952439547.\n",
      "Iteration: 3575/8000, Loss: 0.126952424645.\n",
      "Iteration: 3576/8000, Loss: 0.126952394843.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3577/8000, Loss: 0.126952394843.\n",
      "Iteration: 3578/8000, Loss: 0.126952365041.\n",
      "Iteration: 3579/8000, Loss: 0.12695235014.\n",
      "Iteration: 3580/8000, Loss: 0.126952335238.\n",
      "Iteration: 3581/8000, Loss: 0.126952320337.\n",
      "Iteration: 3582/8000, Loss: 0.126952305436.\n",
      "Iteration: 3583/8000, Loss: 0.126952275634.\n",
      "Iteration: 3584/8000, Loss: 0.126952260733.\n",
      "Iteration: 3585/8000, Loss: 0.12695223093.\n",
      "Iteration: 3586/8000, Loss: 0.126952216029.\n",
      "Iteration: 3587/8000, Loss: 0.126952201128.\n",
      "Iteration: 3588/8000, Loss: 0.126952186227.\n",
      "Iteration: 3589/8000, Loss: 0.126952156425.\n",
      "Iteration: 3590/8000, Loss: 0.126952156425.\n",
      "Iteration: 3591/8000, Loss: 0.126952126622.\n",
      "Iteration: 3592/8000, Loss: 0.126952111721.\n",
      "Iteration: 3593/8000, Loss: 0.12695209682.\n",
      "Iteration: 3594/8000, Loss: 0.126952067018.\n",
      "Iteration: 3595/8000, Loss: 0.126952052116.\n",
      "Iteration: 3596/8000, Loss: 0.126952022314.\n",
      "Iteration: 3597/8000, Loss: 0.126952022314.\n",
      "Iteration: 3598/8000, Loss: 0.126951992512.\n",
      "Iteration: 3599/8000, Loss: 0.126951977611.\n",
      "Iteration: 3600/8000, Loss: 0.126951962709.\n",
      "Iteration: 3601/8000, Loss: 0.126951947808.\n",
      "Iteration: 3602/8000, Loss: 0.126951932907.\n",
      "Iteration: 3603/8000, Loss: 0.126951918006.\n",
      "Iteration: 3604/8000, Loss: 0.126951903105.\n",
      "Iteration: 3605/8000, Loss: 0.126951873302.\n",
      "Iteration: 3606/8000, Loss: 0.1269518435.\n",
      "Iteration: 3607/8000, Loss: 0.126951828599.\n",
      "Iteration: 3608/8000, Loss: 0.126951813698.\n",
      "Iteration: 3609/8000, Loss: 0.126951798797.\n",
      "Iteration: 3610/8000, Loss: 0.126951783895.\n",
      "Iteration: 3611/8000, Loss: 0.126951754093.\n",
      "Iteration: 3612/8000, Loss: 0.126951754093.\n",
      "Iteration: 3613/8000, Loss: 0.126951724291.\n",
      "Iteration: 3614/8000, Loss: 0.12695170939.\n",
      "Iteration: 3615/8000, Loss: 0.126951679587.\n",
      "Iteration: 3616/8000, Loss: 0.126951664686.\n",
      "Iteration: 3617/8000, Loss: 0.126951649785.\n",
      "Iteration: 3618/8000, Loss: 0.126951619983.\n",
      "Iteration: 3619/8000, Loss: 0.126951619983.\n",
      "Iteration: 3620/8000, Loss: 0.12695159018.\n",
      "Iteration: 3621/8000, Loss: 0.126951575279.\n",
      "Iteration: 3622/8000, Loss: 0.126951560378.\n",
      "Iteration: 3623/8000, Loss: 0.126951545477.\n",
      "Iteration: 3624/8000, Loss: 0.126951515675.\n",
      "Iteration: 3625/8000, Loss: 0.126951500773.\n",
      "Iteration: 3626/8000, Loss: 0.126951485872.\n",
      "Iteration: 3627/8000, Loss: 0.12695145607.\n",
      "Iteration: 3628/8000, Loss: 0.12695145607.\n",
      "Iteration: 3629/8000, Loss: 0.126951441169.\n",
      "Iteration: 3630/8000, Loss: 0.126951426268.\n",
      "Iteration: 3631/8000, Loss: 0.126951396465.\n",
      "Iteration: 3632/8000, Loss: 0.126951381564.\n",
      "Iteration: 3633/8000, Loss: 0.126951366663.\n",
      "Iteration: 3634/8000, Loss: 0.126951351762.\n",
      "Iteration: 3635/8000, Loss: 0.126951336861.\n",
      "Iteration: 3636/8000, Loss: 0.126951307058.\n",
      "Iteration: 3637/8000, Loss: 0.126951277256.\n",
      "Iteration: 3638/8000, Loss: 0.126951277256.\n",
      "Iteration: 3639/8000, Loss: 0.126951262355.\n",
      "Iteration: 3640/8000, Loss: 0.126951247454.\n",
      "Iteration: 3641/8000, Loss: 0.126951232553.\n",
      "Iteration: 3642/8000, Loss: 0.126951217651.\n",
      "Iteration: 3643/8000, Loss: 0.126951187849.\n",
      "Iteration: 3644/8000, Loss: 0.126951158047.\n",
      "Iteration: 3645/8000, Loss: 0.126951158047.\n",
      "Iteration: 3646/8000, Loss: 0.126951128244.\n",
      "Iteration: 3647/8000, Loss: 0.126951113343.\n",
      "Iteration: 3648/8000, Loss: 0.126951098442.\n",
      "Iteration: 3649/8000, Loss: 0.126951083541.\n",
      "Iteration: 3650/8000, Loss: 0.12695106864.\n",
      "Iteration: 3651/8000, Loss: 0.126951053739.\n",
      "Iteration: 3652/8000, Loss: 0.126951009035.\n",
      "Iteration: 3653/8000, Loss: 0.126951009035.\n",
      "Iteration: 3654/8000, Loss: 0.126950994134.\n",
      "Iteration: 3655/8000, Loss: 0.126950979233.\n",
      "Iteration: 3656/8000, Loss: 0.126950964332.\n",
      "Iteration: 3657/8000, Loss: 0.126950934529.\n",
      "Iteration: 3658/8000, Loss: 0.126950919628.\n",
      "Iteration: 3659/8000, Loss: 0.126950904727.\n",
      "Iteration: 3660/8000, Loss: 0.126950889826.\n",
      "Iteration: 3661/8000, Loss: 0.126950860023.\n",
      "Iteration: 3662/8000, Loss: 0.126950845122.\n",
      "Iteration: 3663/8000, Loss: 0.126950830221.\n",
      "Iteration: 3664/8000, Loss: 0.12695081532.\n",
      "Iteration: 3665/8000, Loss: 0.126950800419.\n",
      "Iteration: 3666/8000, Loss: 0.126950770617.\n",
      "Iteration: 3667/8000, Loss: 0.126950755715.\n",
      "Iteration: 3668/8000, Loss: 0.126950740814.\n",
      "Iteration: 3669/8000, Loss: 0.126950725913.\n",
      "Iteration: 3670/8000, Loss: 0.126950725913.\n",
      "Iteration: 3671/8000, Loss: 0.126950696111.\n",
      "Iteration: 3672/8000, Loss: 0.12695068121.\n",
      "Iteration: 3673/8000, Loss: 0.126950651407.\n",
      "Iteration: 3674/8000, Loss: 0.126950636506.\n",
      "Iteration: 3675/8000, Loss: 0.126950621605.\n",
      "Iteration: 3676/8000, Loss: 0.126950591803.\n",
      "Iteration: 3677/8000, Loss: 0.126950591803.\n",
      "Iteration: 3678/8000, Loss: 0.126950576901.\n",
      "Iteration: 3679/8000, Loss: 0.126950562.\n",
      "Iteration: 3680/8000, Loss: 0.126950547099.\n",
      "Iteration: 3681/8000, Loss: 0.126950517297.\n",
      "Iteration: 3682/8000, Loss: 0.126950502396.\n",
      "Iteration: 3683/8000, Loss: 0.126950487494.\n",
      "Iteration: 3684/8000, Loss: 0.126950457692.\n",
      "Iteration: 3685/8000, Loss: 0.126950457692.\n",
      "Iteration: 3686/8000, Loss: 0.12695042789.\n",
      "Iteration: 3687/8000, Loss: 0.12695042789.\n",
      "Iteration: 3688/8000, Loss: 0.126950412989.\n",
      "Iteration: 3689/8000, Loss: 0.126950383186.\n",
      "Iteration: 3690/8000, Loss: 0.126950368285.\n",
      "Iteration: 3691/8000, Loss: 0.126950353384.\n",
      "Iteration: 3692/8000, Loss: 0.126950323582.\n",
      "Iteration: 3693/8000, Loss: 0.126950308681.\n",
      "Iteration: 3694/8000, Loss: 0.126950293779.\n",
      "Iteration: 3695/8000, Loss: 0.126950278878.\n",
      "Iteration: 3696/8000, Loss: 0.126950263977.\n",
      "Iteration: 3697/8000, Loss: 0.126950234175.\n",
      "Iteration: 3698/8000, Loss: 0.126950234175.\n",
      "Iteration: 3699/8000, Loss: 0.126950219274.\n",
      "Iteration: 3700/8000, Loss: 0.126950204372.\n",
      "Iteration: 3701/8000, Loss: 0.126950189471.\n",
      "Iteration: 3702/8000, Loss: 0.12695017457.\n",
      "Iteration: 3703/8000, Loss: 0.126950144768.\n",
      "Iteration: 3704/8000, Loss: 0.126950129867.\n",
      "Iteration: 3705/8000, Loss: 0.126950114965.\n",
      "Iteration: 3706/8000, Loss: 0.126950100064.\n",
      "Iteration: 3707/8000, Loss: 0.126950085163.\n",
      "Iteration: 3708/8000, Loss: 0.126950070262.\n",
      "Iteration: 3709/8000, Loss: 0.12695004046.\n",
      "Iteration: 3710/8000, Loss: 0.126950025558.\n",
      "Iteration: 3711/8000, Loss: 0.126950010657.\n",
      "Iteration: 3712/8000, Loss: 0.126949995756.\n",
      "Iteration: 3713/8000, Loss: 0.126949980855.\n",
      "Iteration: 3714/8000, Loss: 0.126949965954.\n",
      "Iteration: 3715/8000, Loss: 0.126949951053.\n",
      "Iteration: 3716/8000, Loss: 0.126949936152.\n",
      "Iteration: 3717/8000, Loss: 0.126949906349.\n",
      "Iteration: 3718/8000, Loss: 0.126949906349.\n",
      "Iteration: 3719/8000, Loss: 0.126949876547.\n",
      "Iteration: 3720/8000, Loss: 0.126949861646.\n",
      "Iteration: 3721/8000, Loss: 0.126949831843.\n",
      "Iteration: 3722/8000, Loss: 0.126949831843.\n",
      "Iteration: 3723/8000, Loss: 0.126949816942.\n",
      "Iteration: 3724/8000, Loss: 0.126949802041.\n",
      "Iteration: 3725/8000, Loss: 0.126949772239.\n",
      "Iteration: 3726/8000, Loss: 0.126949757338.\n",
      "Iteration: 3727/8000, Loss: 0.126949742436.\n",
      "Iteration: 3728/8000, Loss: 0.126949727535.\n",
      "Iteration: 3729/8000, Loss: 0.126949712634.\n",
      "Iteration: 3730/8000, Loss: 0.126949697733.\n",
      "Iteration: 3731/8000, Loss: 0.126949682832.\n",
      "Iteration: 3732/8000, Loss: 0.126949667931.\n",
      "Iteration: 3733/8000, Loss: 0.126949638128.\n",
      "Iteration: 3734/8000, Loss: 0.126949638128.\n",
      "Iteration: 3735/8000, Loss: 0.126949608326.\n",
      "Iteration: 3736/8000, Loss: 0.126949608326.\n",
      "Iteration: 3737/8000, Loss: 0.126949578524.\n",
      "Iteration: 3738/8000, Loss: 0.126949563622.\n",
      "Iteration: 3739/8000, Loss: 0.126949548721.\n",
      "Iteration: 3740/8000, Loss: 0.12694953382.\n",
      "Iteration: 3741/8000, Loss: 0.126949504018.\n",
      "Iteration: 3742/8000, Loss: 0.126949489117.\n",
      "Iteration: 3743/8000, Loss: 0.126949489117.\n",
      "Iteration: 3744/8000, Loss: 0.126949459314.\n",
      "Iteration: 3745/8000, Loss: 0.126949459314.\n",
      "Iteration: 3746/8000, Loss: 0.126949429512.\n",
      "Iteration: 3747/8000, Loss: 0.126949414611.\n",
      "Iteration: 3748/8000, Loss: 0.12694939971.\n",
      "Iteration: 3749/8000, Loss: 0.126949384809.\n",
      "Iteration: 3750/8000, Loss: 0.126949369907.\n",
      "Iteration: 3751/8000, Loss: 0.126949369907.\n",
      "Iteration: 3752/8000, Loss: 0.126949340105.\n",
      "Iteration: 3753/8000, Loss: 0.126949310303.\n",
      "Iteration: 3754/8000, Loss: 0.126949310303.\n",
      "Iteration: 3755/8000, Loss: 0.1269492805.\n",
      "Iteration: 3756/8000, Loss: 0.1269492805.\n",
      "Iteration: 3757/8000, Loss: 0.126949250698.\n",
      "Iteration: 3758/8000, Loss: 0.126949235797.\n",
      "Iteration: 3759/8000, Loss: 0.126949220896.\n",
      "Iteration: 3760/8000, Loss: 0.126949205995.\n",
      "Iteration: 3761/8000, Loss: 0.126949191093.\n",
      "Iteration: 3762/8000, Loss: 0.126949161291.\n",
      "Iteration: 3763/8000, Loss: 0.126949161291.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3764/8000, Loss: 0.12694914639.\n",
      "Iteration: 3765/8000, Loss: 0.126949116588.\n",
      "Iteration: 3766/8000, Loss: 0.126949101686.\n",
      "Iteration: 3767/8000, Loss: 0.126949086785.\n",
      "Iteration: 3768/8000, Loss: 0.126949086785.\n",
      "Iteration: 3769/8000, Loss: 0.126949056983.\n",
      "Iteration: 3770/8000, Loss: 0.126949042082.\n",
      "Iteration: 3771/8000, Loss: 0.126949027181.\n",
      "Iteration: 3772/8000, Loss: 0.12694901228.\n",
      "Iteration: 3773/8000, Loss: 0.126948997378.\n",
      "Iteration: 3774/8000, Loss: 0.126948967576.\n",
      "Iteration: 3775/8000, Loss: 0.126948967576.\n",
      "Iteration: 3776/8000, Loss: 0.126948952675.\n",
      "Iteration: 3777/8000, Loss: 0.126948937774.\n",
      "Iteration: 3778/8000, Loss: 0.126948922873.\n",
      "Iteration: 3779/8000, Loss: 0.126948907971.\n",
      "Iteration: 3780/8000, Loss: 0.12694889307.\n",
      "Iteration: 3781/8000, Loss: 0.126948863268.\n",
      "Iteration: 3782/8000, Loss: 0.126948848367.\n",
      "Iteration: 3783/8000, Loss: 0.126948833466.\n",
      "Iteration: 3784/8000, Loss: 0.126948818564.\n",
      "Iteration: 3785/8000, Loss: 0.126948818564.\n",
      "Iteration: 3786/8000, Loss: 0.126948788762.\n",
      "Iteration: 3787/8000, Loss: 0.126948773861.\n",
      "Iteration: 3788/8000, Loss: 0.12694875896.\n",
      "Iteration: 3789/8000, Loss: 0.126948744059.\n",
      "Iteration: 3790/8000, Loss: 0.126948744059.\n",
      "Iteration: 3791/8000, Loss: 0.126948714256.\n",
      "Iteration: 3792/8000, Loss: 0.126948699355.\n",
      "Iteration: 3793/8000, Loss: 0.126948684454.\n",
      "Iteration: 3794/8000, Loss: 0.126948669553.\n",
      "Iteration: 3795/8000, Loss: 0.126948654652.\n",
      "Iteration: 3796/8000, Loss: 0.12694863975.\n",
      "Iteration: 3797/8000, Loss: 0.126948609948.\n",
      "Iteration: 3798/8000, Loss: 0.126948609948.\n",
      "Iteration: 3799/8000, Loss: 0.126948595047.\n",
      "Iteration: 3800/8000, Loss: 0.126948565245.\n",
      "Iteration: 3801/8000, Loss: 0.126948565245.\n",
      "Iteration: 3802/8000, Loss: 0.126948550344.\n",
      "Iteration: 3803/8000, Loss: 0.126948535442.\n",
      "Iteration: 3804/8000, Loss: 0.126948520541.\n",
      "Iteration: 3805/8000, Loss: 0.126948490739.\n",
      "Iteration: 3806/8000, Loss: 0.126948475838.\n",
      "Iteration: 3807/8000, Loss: 0.126948475838.\n",
      "Iteration: 3808/8000, Loss: 0.126948446035.\n",
      "Iteration: 3809/8000, Loss: 0.126948431134.\n",
      "Iteration: 3810/8000, Loss: 0.126948416233.\n",
      "Iteration: 3811/8000, Loss: 0.126948401332.\n",
      "Iteration: 3812/8000, Loss: 0.126948386431.\n",
      "Iteration: 3813/8000, Loss: 0.126948386431.\n",
      "Iteration: 3814/8000, Loss: 0.126948356628.\n",
      "Iteration: 3815/8000, Loss: 0.126948341727.\n",
      "Iteration: 3816/8000, Loss: 0.126948326826.\n",
      "Iteration: 3817/8000, Loss: 0.126948311925.\n",
      "Iteration: 3818/8000, Loss: 0.126948297024.\n",
      "Iteration: 3819/8000, Loss: 0.126948282123.\n",
      "Iteration: 3820/8000, Loss: 0.126948267221.\n",
      "Iteration: 3821/8000, Loss: 0.12694825232.\n",
      "Iteration: 3822/8000, Loss: 0.126948237419.\n",
      "Iteration: 3823/8000, Loss: 0.126948207617.\n",
      "Iteration: 3824/8000, Loss: 0.126948207617.\n",
      "Iteration: 3825/8000, Loss: 0.126948177814.\n",
      "Iteration: 3826/8000, Loss: 0.126948177814.\n",
      "Iteration: 3827/8000, Loss: 0.126948162913.\n",
      "Iteration: 3828/8000, Loss: 0.126948148012.\n",
      "Iteration: 3829/8000, Loss: 0.126948133111.\n",
      "Iteration: 3830/8000, Loss: 0.12694811821.\n",
      "Iteration: 3831/8000, Loss: 0.126948103309.\n",
      "Iteration: 3832/8000, Loss: 0.126948088408.\n",
      "Iteration: 3833/8000, Loss: 0.126948073506.\n",
      "Iteration: 3834/8000, Loss: 0.126948058605.\n",
      "Iteration: 3835/8000, Loss: 0.126948043704.\n",
      "Iteration: 3836/8000, Loss: 0.126948028803.\n",
      "Iteration: 3837/8000, Loss: 0.126947999001.\n",
      "Iteration: 3838/8000, Loss: 0.126947999001.\n",
      "Iteration: 3839/8000, Loss: 0.126947984099.\n",
      "Iteration: 3840/8000, Loss: 0.126947954297.\n",
      "Iteration: 3841/8000, Loss: 0.126947954297.\n",
      "Iteration: 3842/8000, Loss: 0.126947939396.\n",
      "Iteration: 3843/8000, Loss: 0.126947909594.\n",
      "Iteration: 3844/8000, Loss: 0.126947894692.\n",
      "Iteration: 3845/8000, Loss: 0.126947879791.\n",
      "Iteration: 3846/8000, Loss: 0.12694786489.\n",
      "Iteration: 3847/8000, Loss: 0.126947849989.\n",
      "Iteration: 3848/8000, Loss: 0.126947849989.\n",
      "Iteration: 3849/8000, Loss: 0.126947820187.\n",
      "Iteration: 3850/8000, Loss: 0.126947805285.\n",
      "Iteration: 3851/8000, Loss: 0.126947790384.\n",
      "Iteration: 3852/8000, Loss: 0.126947775483.\n",
      "Iteration: 3853/8000, Loss: 0.126947760582.\n",
      "Iteration: 3854/8000, Loss: 0.126947745681.\n",
      "Iteration: 3855/8000, Loss: 0.12694773078.\n",
      "Iteration: 3856/8000, Loss: 0.126947715878.\n",
      "Iteration: 3857/8000, Loss: 0.126947700977.\n",
      "Iteration: 3858/8000, Loss: 0.126947700977.\n",
      "Iteration: 3859/8000, Loss: 0.126947671175.\n",
      "Iteration: 3860/8000, Loss: 0.126947671175.\n",
      "Iteration: 3861/8000, Loss: 0.126947641373.\n",
      "Iteration: 3862/8000, Loss: 0.126947641373.\n",
      "Iteration: 3863/8000, Loss: 0.126947626472.\n",
      "Iteration: 3864/8000, Loss: 0.126947596669.\n",
      "Iteration: 3865/8000, Loss: 0.126947581768.\n",
      "Iteration: 3866/8000, Loss: 0.126947581768.\n",
      "Iteration: 3867/8000, Loss: 0.126947566867.\n",
      "Iteration: 3868/8000, Loss: 0.126947551966.\n",
      "Iteration: 3869/8000, Loss: 0.126947537065.\n",
      "Iteration: 3870/8000, Loss: 0.126947522163.\n",
      "Iteration: 3871/8000, Loss: 0.126947492361.\n",
      "Iteration: 3872/8000, Loss: 0.126947492361.\n",
      "Iteration: 3873/8000, Loss: 0.126947462559.\n",
      "Iteration: 3874/8000, Loss: 0.126947447658.\n",
      "Iteration: 3875/8000, Loss: 0.126947447658.\n",
      "Iteration: 3876/8000, Loss: 0.126947432756.\n",
      "Iteration: 3877/8000, Loss: 0.126947402954.\n",
      "Iteration: 3878/8000, Loss: 0.126947402954.\n",
      "Iteration: 3879/8000, Loss: 0.126947388053.\n",
      "Iteration: 3880/8000, Loss: 0.126947373152.\n",
      "Iteration: 3881/8000, Loss: 0.126947358251.\n",
      "Iteration: 3882/8000, Loss: 0.126947343349.\n",
      "Iteration: 3883/8000, Loss: 0.126947328448.\n",
      "Iteration: 3884/8000, Loss: 0.126947313547.\n",
      "Iteration: 3885/8000, Loss: 0.126947298646.\n",
      "Iteration: 3886/8000, Loss: 0.126947268844.\n",
      "Iteration: 3887/8000, Loss: 0.126947253942.\n",
      "Iteration: 3888/8000, Loss: 0.126947253942.\n",
      "Iteration: 3889/8000, Loss: 0.126947239041.\n",
      "Iteration: 3890/8000, Loss: 0.12694722414.\n",
      "Iteration: 3891/8000, Loss: 0.126947209239.\n",
      "Iteration: 3892/8000, Loss: 0.126947194338.\n",
      "Iteration: 3893/8000, Loss: 0.126947179437.\n",
      "Iteration: 3894/8000, Loss: 0.126947179437.\n",
      "Iteration: 3895/8000, Loss: 0.126947164536.\n",
      "Iteration: 3896/8000, Loss: 0.126947149634.\n",
      "Iteration: 3897/8000, Loss: 0.126947104931.\n",
      "Iteration: 3898/8000, Loss: 0.126947104931.\n",
      "Iteration: 3899/8000, Loss: 0.12694709003.\n",
      "Iteration: 3900/8000, Loss: 0.126947075129.\n",
      "Iteration: 3901/8000, Loss: 0.126947075129.\n",
      "Iteration: 3902/8000, Loss: 0.126947045326.\n",
      "Iteration: 3903/8000, Loss: 0.126947045326.\n",
      "Iteration: 3904/8000, Loss: 0.126947030425.\n",
      "Iteration: 3905/8000, Loss: 0.126947015524.\n",
      "Iteration: 3906/8000, Loss: 0.126947000623.\n",
      "Iteration: 3907/8000, Loss: 0.126946985722.\n",
      "Iteration: 3908/8000, Loss: 0.126946955919.\n",
      "Iteration: 3909/8000, Loss: 0.126946941018.\n",
      "Iteration: 3910/8000, Loss: 0.126946941018.\n",
      "Iteration: 3911/8000, Loss: 0.126946926117.\n",
      "Iteration: 3912/8000, Loss: 0.126946911216.\n",
      "Iteration: 3913/8000, Loss: 0.126946911216.\n",
      "Iteration: 3914/8000, Loss: 0.126946866512.\n",
      "Iteration: 3915/8000, Loss: 0.126946866512.\n",
      "Iteration: 3916/8000, Loss: 0.126946851611.\n",
      "Iteration: 3917/8000, Loss: 0.12694683671.\n",
      "Iteration: 3918/8000, Loss: 0.126946821809.\n",
      "Iteration: 3919/8000, Loss: 0.126946806908.\n",
      "Iteration: 3920/8000, Loss: 0.126946806908.\n",
      "Iteration: 3921/8000, Loss: 0.126946777105.\n",
      "Iteration: 3922/8000, Loss: 0.126946762204.\n",
      "Iteration: 3923/8000, Loss: 0.126946747303.\n",
      "Iteration: 3924/8000, Loss: 0.126946747303.\n",
      "Iteration: 3925/8000, Loss: 0.126946732402.\n",
      "Iteration: 3926/8000, Loss: 0.126946717501.\n",
      "Iteration: 3927/8000, Loss: 0.1269467026.\n",
      "Iteration: 3928/8000, Loss: 0.126946687698.\n",
      "Iteration: 3929/8000, Loss: 0.126946672797.\n",
      "Iteration: 3930/8000, Loss: 0.126946657896.\n",
      "Iteration: 3931/8000, Loss: 0.126946657896.\n",
      "Iteration: 3932/8000, Loss: 0.126946642995.\n",
      "Iteration: 3933/8000, Loss: 0.126946628094.\n",
      "Iteration: 3934/8000, Loss: 0.126946613193.\n",
      "Iteration: 3935/8000, Loss: 0.12694658339.\n",
      "Iteration: 3936/8000, Loss: 0.126946568489.\n",
      "Iteration: 3937/8000, Loss: 0.126946568489.\n",
      "Iteration: 3938/8000, Loss: 0.126946553588.\n",
      "Iteration: 3939/8000, Loss: 0.126946538687.\n",
      "Iteration: 3940/8000, Loss: 0.126946508884.\n",
      "Iteration: 3941/8000, Loss: 0.126946493983.\n",
      "Iteration: 3942/8000, Loss: 0.126946493983.\n",
      "Iteration: 3943/8000, Loss: 0.126946479082.\n",
      "Iteration: 3944/8000, Loss: 0.126946464181.\n",
      "Iteration: 3945/8000, Loss: 0.12694644928.\n",
      "Iteration: 3946/8000, Loss: 0.12694644928.\n",
      "Iteration: 3947/8000, Loss: 0.126946419477.\n",
      "Iteration: 3948/8000, Loss: 0.126946404576.\n",
      "Iteration: 3949/8000, Loss: 0.126946404576.\n",
      "Iteration: 3950/8000, Loss: 0.126946389675.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3951/8000, Loss: 0.126946374774.\n",
      "Iteration: 3952/8000, Loss: 0.126946359873.\n",
      "Iteration: 3953/8000, Loss: 0.126946344972.\n",
      "Iteration: 3954/8000, Loss: 0.12694633007.\n",
      "Iteration: 3955/8000, Loss: 0.126946300268.\n",
      "Iteration: 3956/8000, Loss: 0.126946300268.\n",
      "Iteration: 3957/8000, Loss: 0.126946285367.\n",
      "Iteration: 3958/8000, Loss: 0.126946270466.\n",
      "Iteration: 3959/8000, Loss: 0.126946270466.\n",
      "Iteration: 3960/8000, Loss: 0.126946240664.\n",
      "Iteration: 3961/8000, Loss: 0.126946225762.\n",
      "Iteration: 3962/8000, Loss: 0.126946225762.\n",
      "Iteration: 3963/8000, Loss: 0.126946210861.\n",
      "Iteration: 3964/8000, Loss: 0.12694619596.\n",
      "Iteration: 3965/8000, Loss: 0.126946181059.\n",
      "Iteration: 3966/8000, Loss: 0.126946166158.\n",
      "Iteration: 3967/8000, Loss: 0.126946151257.\n",
      "Iteration: 3968/8000, Loss: 0.126946136355.\n",
      "Iteration: 3969/8000, Loss: 0.126946121454.\n",
      "Iteration: 3970/8000, Loss: 0.126946121454.\n",
      "Iteration: 3971/8000, Loss: 0.126946106553.\n",
      "Iteration: 3972/8000, Loss: 0.126946091652.\n",
      "Iteration: 3973/8000, Loss: 0.12694606185.\n",
      "Iteration: 3974/8000, Loss: 0.12694606185.\n",
      "Iteration: 3975/8000, Loss: 0.126946032047.\n",
      "Iteration: 3976/8000, Loss: 0.126946032047.\n",
      "Iteration: 3977/8000, Loss: 0.126946017146.\n",
      "Iteration: 3978/8000, Loss: 0.126946002245.\n",
      "Iteration: 3979/8000, Loss: 0.126946002245.\n",
      "Iteration: 3980/8000, Loss: 0.126945972443.\n",
      "Iteration: 3981/8000, Loss: 0.126945957541.\n",
      "Iteration: 3982/8000, Loss: 0.126945957541.\n",
      "Iteration: 3983/8000, Loss: 0.126945927739.\n",
      "Iteration: 3984/8000, Loss: 0.126945912838.\n",
      "Iteration: 3985/8000, Loss: 0.126945912838.\n",
      "Iteration: 3986/8000, Loss: 0.126945883036.\n",
      "Iteration: 3987/8000, Loss: 0.126945868134.\n",
      "Iteration: 3988/8000, Loss: 0.126945853233.\n",
      "Iteration: 3989/8000, Loss: 0.126945853233.\n",
      "Iteration: 3990/8000, Loss: 0.126945838332.\n",
      "Iteration: 3991/8000, Loss: 0.126945823431.\n",
      "Iteration: 3992/8000, Loss: 0.12694580853.\n",
      "Iteration: 3993/8000, Loss: 0.126945793629.\n",
      "Iteration: 3994/8000, Loss: 0.126945793629.\n",
      "Iteration: 3995/8000, Loss: 0.126945778728.\n",
      "Iteration: 3996/8000, Loss: 0.126945763826.\n",
      "Iteration: 3997/8000, Loss: 0.126945748925.\n",
      "Iteration: 3998/8000, Loss: 0.126945734024.\n",
      "Iteration: 3999/8000, Loss: 0.126945719123.\n",
      "Iteration: 4000/8000, Loss: 0.126945704222.\n",
      "Iteration: 4001/8000, Loss: 0.126945689321.\n",
      "Iteration: 4002/8000, Loss: 0.126945674419.\n",
      "Iteration: 4003/8000, Loss: 0.126945674419.\n",
      "Iteration: 4004/8000, Loss: 0.126945659518.\n",
      "Iteration: 4005/8000, Loss: 0.126945644617.\n",
      "Iteration: 4006/8000, Loss: 0.126945629716.\n",
      "Iteration: 4007/8000, Loss: 0.126945614815.\n",
      "Iteration: 4008/8000, Loss: 0.126945599914.\n",
      "Iteration: 4009/8000, Loss: 0.126945585012.\n",
      "Iteration: 4010/8000, Loss: 0.126945585012.\n",
      "Iteration: 4011/8000, Loss: 0.12694555521.\n",
      "Iteration: 4012/8000, Loss: 0.12694555521.\n",
      "Iteration: 4013/8000, Loss: 0.126945525408.\n",
      "Iteration: 4014/8000, Loss: 0.126945525408.\n",
      "Iteration: 4015/8000, Loss: 0.126945525408.\n",
      "Iteration: 4016/8000, Loss: 0.126945495605.\n",
      "Iteration: 4017/8000, Loss: 0.126945495605.\n",
      "Iteration: 4018/8000, Loss: 0.126945480704.\n",
      "Iteration: 4019/8000, Loss: 0.126945450902.\n",
      "Iteration: 4020/8000, Loss: 0.126945450902.\n",
      "Iteration: 4021/8000, Loss: 0.126945436001.\n",
      "Iteration: 4022/8000, Loss: 0.1269454211.\n",
      "Iteration: 4023/8000, Loss: 0.126945406199.\n",
      "Iteration: 4024/8000, Loss: 0.126945376396.\n",
      "Iteration: 4025/8000, Loss: 0.126945376396.\n",
      "Iteration: 4026/8000, Loss: 0.126945376396.\n",
      "Iteration: 4027/8000, Loss: 0.126945361495.\n",
      "Iteration: 4028/8000, Loss: 0.126945346594.\n",
      "Iteration: 4029/8000, Loss: 0.126945316792.\n",
      "Iteration: 4030/8000, Loss: 0.126945316792.\n",
      "Iteration: 4031/8000, Loss: 0.12694530189.\n",
      "Iteration: 4032/8000, Loss: 0.126945286989.\n",
      "Iteration: 4033/8000, Loss: 0.126945286989.\n",
      "Iteration: 4034/8000, Loss: 0.126945272088.\n",
      "Iteration: 4035/8000, Loss: 0.126945242286.\n",
      "Iteration: 4036/8000, Loss: 0.126945242286.\n",
      "Iteration: 4037/8000, Loss: 0.126945227385.\n",
      "Iteration: 4038/8000, Loss: 0.126945197582.\n",
      "Iteration: 4039/8000, Loss: 0.126945197582.\n",
      "Iteration: 4040/8000, Loss: 0.12694516778.\n",
      "Iteration: 4041/8000, Loss: 0.12694516778.\n",
      "Iteration: 4042/8000, Loss: 0.12694516778.\n",
      "Iteration: 4043/8000, Loss: 0.126945152879.\n",
      "Iteration: 4044/8000, Loss: 0.126945123076.\n",
      "Iteration: 4045/8000, Loss: 0.126945123076.\n",
      "Iteration: 4046/8000, Loss: 0.126945108175.\n",
      "Iteration: 4047/8000, Loss: 0.126945108175.\n",
      "Iteration: 4048/8000, Loss: 0.126945078373.\n",
      "Iteration: 4049/8000, Loss: 0.126945078373.\n",
      "Iteration: 4050/8000, Loss: 0.126945063472.\n",
      "Iteration: 4051/8000, Loss: 0.126945033669.\n",
      "Iteration: 4052/8000, Loss: 0.126945033669.\n",
      "Iteration: 4053/8000, Loss: 0.126945033669.\n",
      "Iteration: 4054/8000, Loss: 0.126945003867.\n",
      "Iteration: 4055/8000, Loss: 0.126945003867.\n",
      "Iteration: 4056/8000, Loss: 0.126944974065.\n",
      "Iteration: 4057/8000, Loss: 0.126944974065.\n",
      "Iteration: 4058/8000, Loss: 0.126944959164.\n",
      "Iteration: 4059/8000, Loss: 0.126944944263.\n",
      "Iteration: 4060/8000, Loss: 0.126944929361.\n",
      "Iteration: 4061/8000, Loss: 0.12694491446.\n",
      "Iteration: 4062/8000, Loss: 0.126944899559.\n",
      "Iteration: 4063/8000, Loss: 0.126944899559.\n",
      "Iteration: 4064/8000, Loss: 0.126944884658.\n",
      "Iteration: 4065/8000, Loss: 0.126944884658.\n",
      "Iteration: 4066/8000, Loss: 0.126944854856.\n",
      "Iteration: 4067/8000, Loss: 0.126944839954.\n",
      "Iteration: 4068/8000, Loss: 0.126944839954.\n",
      "Iteration: 4069/8000, Loss: 0.126944825053.\n",
      "Iteration: 4070/8000, Loss: 0.126944810152.\n",
      "Iteration: 4071/8000, Loss: 0.126944795251.\n",
      "Iteration: 4072/8000, Loss: 0.12694478035.\n",
      "Iteration: 4073/8000, Loss: 0.126944765449.\n",
      "Iteration: 4074/8000, Loss: 0.126944750547.\n",
      "Iteration: 4075/8000, Loss: 0.126944735646.\n",
      "Iteration: 4076/8000, Loss: 0.126944735646.\n",
      "Iteration: 4077/8000, Loss: 0.126944720745.\n",
      "Iteration: 4078/8000, Loss: 0.126944705844.\n",
      "Iteration: 4079/8000, Loss: 0.126944690943.\n",
      "Iteration: 4080/8000, Loss: 0.126944676042.\n",
      "Iteration: 4081/8000, Loss: 0.12694466114.\n",
      "Iteration: 4082/8000, Loss: 0.12694466114.\n",
      "Iteration: 4083/8000, Loss: 0.126944631338.\n",
      "Iteration: 4084/8000, Loss: 0.126944631338.\n",
      "Iteration: 4085/8000, Loss: 0.126944631338.\n",
      "Iteration: 4086/8000, Loss: 0.126944601536.\n",
      "Iteration: 4087/8000, Loss: 0.126944601536.\n",
      "Iteration: 4088/8000, Loss: 0.126944586635.\n",
      "Iteration: 4089/8000, Loss: 0.126944586635.\n",
      "Iteration: 4090/8000, Loss: 0.126944556832.\n",
      "Iteration: 4091/8000, Loss: 0.126944541931.\n",
      "Iteration: 4092/8000, Loss: 0.126944541931.\n",
      "Iteration: 4093/8000, Loss: 0.12694452703.\n",
      "Iteration: 4094/8000, Loss: 0.126944497228.\n",
      "Iteration: 4095/8000, Loss: 0.126944497228.\n",
      "Iteration: 4096/8000, Loss: 0.126944482327.\n",
      "Iteration: 4097/8000, Loss: 0.126944482327.\n",
      "Iteration: 4098/8000, Loss: 0.126944467425.\n",
      "Iteration: 4099/8000, Loss: 0.126944452524.\n",
      "Iteration: 4100/8000, Loss: 0.126944437623.\n",
      "Iteration: 4101/8000, Loss: 0.126944422722.\n",
      "Iteration: 4102/8000, Loss: 0.126944407821.\n",
      "Iteration: 4103/8000, Loss: 0.12694439292.\n",
      "Iteration: 4104/8000, Loss: 0.12694439292.\n",
      "Iteration: 4105/8000, Loss: 0.126944363117.\n",
      "Iteration: 4106/8000, Loss: 0.126944363117.\n",
      "Iteration: 4107/8000, Loss: 0.126944348216.\n",
      "Iteration: 4108/8000, Loss: 0.126944333315.\n",
      "Iteration: 4109/8000, Loss: 0.126944318414.\n",
      "Iteration: 4110/8000, Loss: 0.126944318414.\n",
      "Iteration: 4111/8000, Loss: 0.126944303513.\n",
      "Iteration: 4112/8000, Loss: 0.126944288611.\n",
      "Iteration: 4113/8000, Loss: 0.12694427371.\n",
      "Iteration: 4114/8000, Loss: 0.126944258809.\n",
      "Iteration: 4115/8000, Loss: 0.126944243908.\n",
      "Iteration: 4116/8000, Loss: 0.126944229007.\n",
      "Iteration: 4117/8000, Loss: 0.126944229007.\n",
      "Iteration: 4118/8000, Loss: 0.126944214106.\n",
      "Iteration: 4119/8000, Loss: 0.126944214106.\n",
      "Iteration: 4120/8000, Loss: 0.126944199204.\n",
      "Iteration: 4121/8000, Loss: 0.126944184303.\n",
      "Iteration: 4122/8000, Loss: 0.126944169402.\n",
      "Iteration: 4123/8000, Loss: 0.126944154501.\n",
      "Iteration: 4124/8000, Loss: 0.126944154501.\n",
      "Iteration: 4125/8000, Loss: 0.126944124699.\n",
      "Iteration: 4126/8000, Loss: 0.126944124699.\n",
      "Iteration: 4127/8000, Loss: 0.126944124699.\n",
      "Iteration: 4128/8000, Loss: 0.126944094896.\n",
      "Iteration: 4129/8000, Loss: 0.126944079995.\n",
      "Iteration: 4130/8000, Loss: 0.126944065094.\n",
      "Iteration: 4131/8000, Loss: 0.126944050193.\n",
      "Iteration: 4132/8000, Loss: 0.126944050193.\n",
      "Iteration: 4133/8000, Loss: 0.126944035292.\n",
      "Iteration: 4134/8000, Loss: 0.126944020391.\n",
      "Iteration: 4135/8000, Loss: 0.126944005489.\n",
      "Iteration: 4136/8000, Loss: 0.126944005489.\n",
      "Iteration: 4137/8000, Loss: 0.126943990588.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4138/8000, Loss: 0.126943975687.\n",
      "Iteration: 4139/8000, Loss: 0.126943975687.\n",
      "Iteration: 4140/8000, Loss: 0.126943960786.\n",
      "Iteration: 4141/8000, Loss: 0.126943945885.\n",
      "Iteration: 4142/8000, Loss: 0.126943930984.\n",
      "Iteration: 4143/8000, Loss: 0.126943916082.\n",
      "Iteration: 4144/8000, Loss: 0.126943916082.\n",
      "Iteration: 4145/8000, Loss: 0.12694388628.\n",
      "Iteration: 4146/8000, Loss: 0.12694388628.\n",
      "Iteration: 4147/8000, Loss: 0.126943871379.\n",
      "Iteration: 4148/8000, Loss: 0.126943856478.\n",
      "Iteration: 4149/8000, Loss: 0.126943856478.\n",
      "Iteration: 4150/8000, Loss: 0.126943841577.\n",
      "Iteration: 4151/8000, Loss: 0.126943826675.\n",
      "Iteration: 4152/8000, Loss: 0.126943811774.\n",
      "Iteration: 4153/8000, Loss: 0.126943796873.\n",
      "Iteration: 4154/8000, Loss: 0.126943796873.\n",
      "Iteration: 4155/8000, Loss: 0.126943781972.\n",
      "Iteration: 4156/8000, Loss: 0.126943767071.\n",
      "Iteration: 4157/8000, Loss: 0.126943767071.\n",
      "Iteration: 4158/8000, Loss: 0.12694375217.\n",
      "Iteration: 4159/8000, Loss: 0.126943722367.\n",
      "Iteration: 4160/8000, Loss: 0.126943722367.\n",
      "Iteration: 4161/8000, Loss: 0.126943722367.\n",
      "Iteration: 4162/8000, Loss: 0.126943692565.\n",
      "Iteration: 4163/8000, Loss: 0.126943677664.\n",
      "Iteration: 4164/8000, Loss: 0.126943692565.\n",
      "Iteration: 4165/8000, Loss: 0.126943662763.\n",
      "Iteration: 4166/8000, Loss: 0.126943647861.\n",
      "Iteration: 4167/8000, Loss: 0.12694363296.\n",
      "Iteration: 4168/8000, Loss: 0.126943618059.\n",
      "Iteration: 4169/8000, Loss: 0.126943618059.\n",
      "Iteration: 4170/8000, Loss: 0.126943603158.\n",
      "Iteration: 4171/8000, Loss: 0.126943588257.\n",
      "Iteration: 4172/8000, Loss: 0.126943588257.\n",
      "Iteration: 4173/8000, Loss: 0.126943573356.\n",
      "Iteration: 4174/8000, Loss: 0.126943558455.\n",
      "Iteration: 4175/8000, Loss: 0.126943543553.\n",
      "Iteration: 4176/8000, Loss: 0.126943543553.\n",
      "Iteration: 4177/8000, Loss: 0.126943528652.\n",
      "Iteration: 4178/8000, Loss: 0.126943513751.\n",
      "Iteration: 4179/8000, Loss: 0.126943513751.\n",
      "Iteration: 4180/8000, Loss: 0.12694349885.\n",
      "Iteration: 4181/8000, Loss: 0.126943469048.\n",
      "Iteration: 4182/8000, Loss: 0.126943469048.\n",
      "Iteration: 4183/8000, Loss: 0.126943454146.\n",
      "Iteration: 4184/8000, Loss: 0.126943454146.\n",
      "Iteration: 4185/8000, Loss: 0.126943439245.\n",
      "Iteration: 4186/8000, Loss: 0.126943409443.\n",
      "Iteration: 4187/8000, Loss: 0.126943409443.\n",
      "Iteration: 4188/8000, Loss: 0.126943394542.\n",
      "Iteration: 4189/8000, Loss: 0.126943379641.\n",
      "Iteration: 4190/8000, Loss: 0.126943364739.\n",
      "Iteration: 4191/8000, Loss: 0.126943364739.\n",
      "Iteration: 4192/8000, Loss: 0.126943349838.\n",
      "Iteration: 4193/8000, Loss: 0.126943349838.\n",
      "Iteration: 4194/8000, Loss: 0.126943320036.\n",
      "Iteration: 4195/8000, Loss: 0.126943320036.\n",
      "Iteration: 4196/8000, Loss: 0.126943305135.\n",
      "Iteration: 4197/8000, Loss: 0.126943290234.\n",
      "Iteration: 4198/8000, Loss: 0.126943275332.\n",
      "Iteration: 4199/8000, Loss: 0.126943275332.\n",
      "Iteration: 4200/8000, Loss: 0.126943260431.\n",
      "Iteration: 4201/8000, Loss: 0.126943260431.\n",
      "Iteration: 4202/8000, Loss: 0.126943230629.\n",
      "Iteration: 4203/8000, Loss: 0.126943230629.\n",
      "Iteration: 4204/8000, Loss: 0.126943215728.\n",
      "Iteration: 4205/8000, Loss: 0.126943200827.\n",
      "Iteration: 4206/8000, Loss: 0.126943200827.\n",
      "Iteration: 4207/8000, Loss: 0.126943185925.\n",
      "Iteration: 4208/8000, Loss: 0.126943171024.\n",
      "Iteration: 4209/8000, Loss: 0.126943171024.\n",
      "Iteration: 4210/8000, Loss: 0.126943156123.\n",
      "Iteration: 4211/8000, Loss: 0.126943141222.\n",
      "Iteration: 4212/8000, Loss: 0.126943126321.\n",
      "Iteration: 4213/8000, Loss: 0.12694311142.\n",
      "Iteration: 4214/8000, Loss: 0.126943096519.\n",
      "Iteration: 4215/8000, Loss: 0.126943096519.\n",
      "Iteration: 4216/8000, Loss: 0.126943081617.\n",
      "Iteration: 4217/8000, Loss: 0.126943081617.\n",
      "Iteration: 4218/8000, Loss: 0.126943051815.\n",
      "Iteration: 4219/8000, Loss: 0.126943051815.\n",
      "Iteration: 4220/8000, Loss: 0.126943036914.\n",
      "Iteration: 4221/8000, Loss: 0.126943022013.\n",
      "Iteration: 4222/8000, Loss: 0.126943022013.\n",
      "Iteration: 4223/8000, Loss: 0.126943007112.\n",
      "Iteration: 4224/8000, Loss: 0.126943007112.\n",
      "Iteration: 4225/8000, Loss: 0.12694299221.\n",
      "Iteration: 4226/8000, Loss: 0.126942962408.\n",
      "Iteration: 4227/8000, Loss: 0.126942962408.\n",
      "Iteration: 4228/8000, Loss: 0.126942962408.\n",
      "Iteration: 4229/8000, Loss: 0.126942932606.\n",
      "Iteration: 4230/8000, Loss: 0.126942932606.\n",
      "Iteration: 4231/8000, Loss: 0.126942932606.\n",
      "Iteration: 4232/8000, Loss: 0.126942917705.\n",
      "Iteration: 4233/8000, Loss: 0.126942902803.\n",
      "Iteration: 4234/8000, Loss: 0.126942887902.\n",
      "Iteration: 4235/8000, Loss: 0.126942873001.\n",
      "Iteration: 4236/8000, Loss: 0.126942873001.\n",
      "Iteration: 4237/8000, Loss: 0.1269428581.\n",
      "Iteration: 4238/8000, Loss: 0.126942843199.\n",
      "Iteration: 4239/8000, Loss: 0.126942828298.\n",
      "Iteration: 4240/8000, Loss: 0.126942828298.\n",
      "Iteration: 4241/8000, Loss: 0.126942813396.\n",
      "Iteration: 4242/8000, Loss: 0.126942813396.\n",
      "Iteration: 4243/8000, Loss: 0.126942783594.\n",
      "Iteration: 4244/8000, Loss: 0.126942783594.\n",
      "Iteration: 4245/8000, Loss: 0.126942753792.\n",
      "Iteration: 4246/8000, Loss: 0.126942753792.\n",
      "Iteration: 4247/8000, Loss: 0.126942738891.\n",
      "Iteration: 4248/8000, Loss: 0.126942738891.\n",
      "Iteration: 4249/8000, Loss: 0.126942723989.\n",
      "Iteration: 4250/8000, Loss: 0.126942723989.\n",
      "Iteration: 4251/8000, Loss: 0.126942694187.\n",
      "Iteration: 4252/8000, Loss: 0.126942694187.\n",
      "Iteration: 4253/8000, Loss: 0.126942679286.\n",
      "Iteration: 4254/8000, Loss: 0.126942664385.\n",
      "Iteration: 4255/8000, Loss: 0.126942664385.\n",
      "Iteration: 4256/8000, Loss: 0.126942649484.\n",
      "Iteration: 4257/8000, Loss: 0.126942634583.\n",
      "Iteration: 4258/8000, Loss: 0.126942619681.\n",
      "Iteration: 4259/8000, Loss: 0.12694260478.\n",
      "Iteration: 4260/8000, Loss: 0.12694260478.\n",
      "Iteration: 4261/8000, Loss: 0.126942589879.\n",
      "Iteration: 4262/8000, Loss: 0.126942589879.\n",
      "Iteration: 4263/8000, Loss: 0.126942574978.\n",
      "Iteration: 4264/8000, Loss: 0.126942560077.\n",
      "Iteration: 4265/8000, Loss: 0.126942545176.\n",
      "Iteration: 4266/8000, Loss: 0.126942545176.\n",
      "Iteration: 4267/8000, Loss: 0.126942515373.\n",
      "Iteration: 4268/8000, Loss: 0.126942515373.\n",
      "Iteration: 4269/8000, Loss: 0.126942515373.\n",
      "Iteration: 4270/8000, Loss: 0.126942500472.\n",
      "Iteration: 4271/8000, Loss: 0.126942485571.\n",
      "Iteration: 4272/8000, Loss: 0.126942485571.\n",
      "Iteration: 4273/8000, Loss: 0.12694247067.\n",
      "Iteration: 4274/8000, Loss: 0.126942455769.\n",
      "Iteration: 4275/8000, Loss: 0.126942440867.\n",
      "Iteration: 4276/8000, Loss: 0.126942425966.\n",
      "Iteration: 4277/8000, Loss: 0.126942411065.\n",
      "Iteration: 4278/8000, Loss: 0.126942411065.\n",
      "Iteration: 4279/8000, Loss: 0.126942396164.\n",
      "Iteration: 4280/8000, Loss: 0.126942396164.\n",
      "Iteration: 4281/8000, Loss: 0.126942381263.\n",
      "Iteration: 4282/8000, Loss: 0.126942366362.\n",
      "Iteration: 4283/8000, Loss: 0.126942366362.\n",
      "Iteration: 4284/8000, Loss: 0.12694235146.\n",
      "Iteration: 4285/8000, Loss: 0.126942336559.\n",
      "Iteration: 4286/8000, Loss: 0.126942336559.\n",
      "Iteration: 4287/8000, Loss: 0.126942321658.\n",
      "Iteration: 4288/8000, Loss: 0.126942306757.\n",
      "Iteration: 4289/8000, Loss: 0.126942291856.\n",
      "Iteration: 4290/8000, Loss: 0.126942291856.\n",
      "Iteration: 4291/8000, Loss: 0.126942276955.\n",
      "Iteration: 4292/8000, Loss: 0.126942247152.\n",
      "Iteration: 4293/8000, Loss: 0.126942247152.\n",
      "Iteration: 4294/8000, Loss: 0.126942247152.\n",
      "Iteration: 4295/8000, Loss: 0.126942232251.\n",
      "Iteration: 4296/8000, Loss: 0.12694221735.\n",
      "Iteration: 4297/8000, Loss: 0.12694221735.\n",
      "Iteration: 4298/8000, Loss: 0.126942202449.\n",
      "Iteration: 4299/8000, Loss: 0.126942187548.\n",
      "Iteration: 4300/8000, Loss: 0.126942187548.\n",
      "Iteration: 4301/8000, Loss: 0.126942172647.\n",
      "Iteration: 4302/8000, Loss: 0.126942157745.\n",
      "Iteration: 4303/8000, Loss: 0.126942142844.\n",
      "Iteration: 4304/8000, Loss: 0.126942127943.\n",
      "Iteration: 4305/8000, Loss: 0.126942113042.\n",
      "Iteration: 4306/8000, Loss: 0.126942113042.\n",
      "Iteration: 4307/8000, Loss: 0.126942113042.\n",
      "Iteration: 4308/8000, Loss: 0.126942098141.\n",
      "Iteration: 4309/8000, Loss: 0.126942098141.\n",
      "Iteration: 4310/8000, Loss: 0.126942068338.\n",
      "Iteration: 4311/8000, Loss: 0.126942068338.\n",
      "Iteration: 4312/8000, Loss: 0.126942053437.\n",
      "Iteration: 4313/8000, Loss: 0.126942053437.\n",
      "Iteration: 4314/8000, Loss: 0.126942038536.\n",
      "Iteration: 4315/8000, Loss: 0.126942038536.\n",
      "Iteration: 4316/8000, Loss: 0.126942008734.\n",
      "Iteration: 4317/8000, Loss: 0.126942008734.\n",
      "Iteration: 4318/8000, Loss: 0.126941978931.\n",
      "Iteration: 4319/8000, Loss: 0.126941978931.\n",
      "Iteration: 4320/8000, Loss: 0.12694196403.\n",
      "Iteration: 4321/8000, Loss: 0.12694196403.\n",
      "Iteration: 4322/8000, Loss: 0.126941949129.\n",
      "Iteration: 4323/8000, Loss: 0.126941934228.\n",
      "Iteration: 4324/8000, Loss: 0.126941934228.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4325/8000, Loss: 0.126941919327.\n",
      "Iteration: 4326/8000, Loss: 0.126941919327.\n",
      "Iteration: 4327/8000, Loss: 0.126941904426.\n",
      "Iteration: 4328/8000, Loss: 0.126941889524.\n",
      "Iteration: 4329/8000, Loss: 0.126941889524.\n",
      "Iteration: 4330/8000, Loss: 0.126941874623.\n",
      "Iteration: 4331/8000, Loss: 0.126941859722.\n",
      "Iteration: 4332/8000, Loss: 0.126941844821.\n",
      "Iteration: 4333/8000, Loss: 0.126941844821.\n",
      "Iteration: 4334/8000, Loss: 0.12694182992.\n",
      "Iteration: 4335/8000, Loss: 0.12694182992.\n",
      "Iteration: 4336/8000, Loss: 0.126941800117.\n",
      "Iteration: 4337/8000, Loss: 0.126941800117.\n",
      "Iteration: 4338/8000, Loss: 0.126941800117.\n",
      "Iteration: 4339/8000, Loss: 0.126941785216.\n",
      "Iteration: 4340/8000, Loss: 0.126941770315.\n",
      "Iteration: 4341/8000, Loss: 0.126941755414.\n",
      "Iteration: 4342/8000, Loss: 0.126941740513.\n",
      "Iteration: 4343/8000, Loss: 0.126941740513.\n",
      "Iteration: 4344/8000, Loss: 0.126941740513.\n",
      "Iteration: 4345/8000, Loss: 0.126941710711.\n",
      "Iteration: 4346/8000, Loss: 0.126941710711.\n",
      "Iteration: 4347/8000, Loss: 0.126941695809.\n",
      "Iteration: 4348/8000, Loss: 0.126941695809.\n",
      "Iteration: 4349/8000, Loss: 0.126941680908.\n",
      "Iteration: 4350/8000, Loss: 0.126941666007.\n",
      "Iteration: 4351/8000, Loss: 0.126941651106.\n",
      "Iteration: 4352/8000, Loss: 0.126941651106.\n",
      "Iteration: 4353/8000, Loss: 0.126941651106.\n",
      "Iteration: 4354/8000, Loss: 0.126941621304.\n",
      "Iteration: 4355/8000, Loss: 0.126941621304.\n",
      "Iteration: 4356/8000, Loss: 0.126941606402.\n",
      "Iteration: 4357/8000, Loss: 0.126941606402.\n",
      "Iteration: 4358/8000, Loss: 0.126941591501.\n",
      "Iteration: 4359/8000, Loss: 0.1269415766.\n",
      "Iteration: 4360/8000, Loss: 0.1269415766.\n",
      "Iteration: 4361/8000, Loss: 0.126941561699.\n",
      "Iteration: 4362/8000, Loss: 0.126941561699.\n",
      "Iteration: 4363/8000, Loss: 0.126941546798.\n",
      "Iteration: 4364/8000, Loss: 0.126941531897.\n",
      "Iteration: 4365/8000, Loss: 0.126941516995.\n",
      "Iteration: 4366/8000, Loss: 0.126941502094.\n",
      "Iteration: 4367/8000, Loss: 0.126941502094.\n",
      "Iteration: 4368/8000, Loss: 0.126941487193.\n",
      "Iteration: 4369/8000, Loss: 0.126941487193.\n",
      "Iteration: 4370/8000, Loss: 0.126941472292.\n",
      "Iteration: 4371/8000, Loss: 0.126941472292.\n",
      "Iteration: 4372/8000, Loss: 0.12694144249.\n",
      "Iteration: 4373/8000, Loss: 0.12694144249.\n",
      "Iteration: 4374/8000, Loss: 0.126941427588.\n",
      "Iteration: 4375/8000, Loss: 0.126941427588.\n",
      "Iteration: 4376/8000, Loss: 0.126941412687.\n",
      "Iteration: 4377/8000, Loss: 0.126941412687.\n",
      "Iteration: 4378/8000, Loss: 0.126941397786.\n",
      "Iteration: 4379/8000, Loss: 0.126941367984.\n",
      "Iteration: 4380/8000, Loss: 0.126941367984.\n",
      "Iteration: 4381/8000, Loss: 0.126941353083.\n",
      "Iteration: 4382/8000, Loss: 0.126941353083.\n",
      "Iteration: 4383/8000, Loss: 0.126941338181.\n",
      "Iteration: 4384/8000, Loss: 0.126941338181.\n",
      "Iteration: 4385/8000, Loss: 0.126941338181.\n",
      "Iteration: 4386/8000, Loss: 0.12694132328.\n",
      "Iteration: 4387/8000, Loss: 0.126941308379.\n",
      "Iteration: 4388/8000, Loss: 0.126941308379.\n",
      "Iteration: 4389/8000, Loss: 0.126941293478.\n",
      "Iteration: 4390/8000, Loss: 0.126941263676.\n",
      "Iteration: 4391/8000, Loss: 0.126941263676.\n",
      "Iteration: 4392/8000, Loss: 0.126941263676.\n",
      "Iteration: 4393/8000, Loss: 0.126941248775.\n",
      "Iteration: 4394/8000, Loss: 0.126941233873.\n",
      "Iteration: 4395/8000, Loss: 0.126941218972.\n",
      "Iteration: 4396/8000, Loss: 0.126941218972.\n",
      "Iteration: 4397/8000, Loss: 0.126941218972.\n",
      "Iteration: 4398/8000, Loss: 0.12694118917.\n",
      "Iteration: 4399/8000, Loss: 0.12694118917.\n",
      "Iteration: 4400/8000, Loss: 0.126941174269.\n",
      "Iteration: 4401/8000, Loss: 0.126941174269.\n",
      "Iteration: 4402/8000, Loss: 0.126941159368.\n",
      "Iteration: 4403/8000, Loss: 0.126941159368.\n",
      "Iteration: 4404/8000, Loss: 0.126941144466.\n",
      "Iteration: 4405/8000, Loss: 0.126941129565.\n",
      "Iteration: 4406/8000, Loss: 0.126941129565.\n",
      "Iteration: 4407/8000, Loss: 0.126941114664.\n",
      "Iteration: 4408/8000, Loss: 0.126941084862.\n",
      "Iteration: 4409/8000, Loss: 0.126941084862.\n",
      "Iteration: 4410/8000, Loss: 0.126941084862.\n",
      "Iteration: 4411/8000, Loss: 0.126941069961.\n",
      "Iteration: 4412/8000, Loss: 0.126941069961.\n",
      "Iteration: 4413/8000, Loss: 0.126941055059.\n",
      "Iteration: 4414/8000, Loss: 0.126941055059.\n",
      "Iteration: 4415/8000, Loss: 0.126941040158.\n",
      "Iteration: 4416/8000, Loss: 0.126941025257.\n",
      "Iteration: 4417/8000, Loss: 0.126941025257.\n",
      "Iteration: 4418/8000, Loss: 0.126941010356.\n",
      "Iteration: 4419/8000, Loss: 0.126940995455.\n",
      "Iteration: 4420/8000, Loss: 0.126940980554.\n",
      "Iteration: 4421/8000, Loss: 0.126940965652.\n",
      "Iteration: 4422/8000, Loss: 0.126940965652.\n",
      "Iteration: 4423/8000, Loss: 0.126940950751.\n",
      "Iteration: 4424/8000, Loss: 0.126940950751.\n",
      "Iteration: 4425/8000, Loss: 0.12694093585.\n",
      "Iteration: 4426/8000, Loss: 0.126940920949.\n",
      "Iteration: 4427/8000, Loss: 0.126940920949.\n",
      "Iteration: 4428/8000, Loss: 0.126940920949.\n",
      "Iteration: 4429/8000, Loss: 0.126940891147.\n",
      "Iteration: 4430/8000, Loss: 0.126940891147.\n",
      "Iteration: 4431/8000, Loss: 0.126940891147.\n",
      "Iteration: 4432/8000, Loss: 0.126940876245.\n",
      "Iteration: 4433/8000, Loss: 0.126940861344.\n",
      "Iteration: 4434/8000, Loss: 0.126940846443.\n",
      "Iteration: 4435/8000, Loss: 0.126940846443.\n",
      "Iteration: 4436/8000, Loss: 0.126940831542.\n",
      "Iteration: 4437/8000, Loss: 0.126940816641.\n",
      "Iteration: 4438/8000, Loss: 0.126940816641.\n",
      "Iteration: 4439/8000, Loss: 0.126940816641.\n",
      "Iteration: 4440/8000, Loss: 0.12694080174.\n",
      "Iteration: 4441/8000, Loss: 0.126940786839.\n",
      "Iteration: 4442/8000, Loss: 0.126940786839.\n",
      "Iteration: 4443/8000, Loss: 0.126940757036.\n",
      "Iteration: 4444/8000, Loss: 0.126940757036.\n",
      "Iteration: 4445/8000, Loss: 0.126940742135.\n",
      "Iteration: 4446/8000, Loss: 0.126940742135.\n",
      "Iteration: 4447/8000, Loss: 0.126940742135.\n",
      "Iteration: 4448/8000, Loss: 0.126940712333.\n",
      "Iteration: 4449/8000, Loss: 0.126940712333.\n",
      "Iteration: 4450/8000, Loss: 0.126940712333.\n",
      "Iteration: 4451/8000, Loss: 0.12694068253.\n",
      "Iteration: 4452/8000, Loss: 0.12694068253.\n",
      "Iteration: 4453/8000, Loss: 0.12694068253.\n",
      "Iteration: 4454/8000, Loss: 0.126940667629.\n",
      "Iteration: 4455/8000, Loss: 0.126940667629.\n",
      "Iteration: 4456/8000, Loss: 0.126940652728.\n",
      "Iteration: 4457/8000, Loss: 0.126940637827.\n",
      "Iteration: 4458/8000, Loss: 0.126940622926.\n",
      "Iteration: 4459/8000, Loss: 0.126940622926.\n",
      "Iteration: 4460/8000, Loss: 0.126940622926.\n",
      "Iteration: 4461/8000, Loss: 0.126940608025.\n",
      "Iteration: 4462/8000, Loss: 0.126940593123.\n",
      "Iteration: 4463/8000, Loss: 0.126940593123.\n",
      "Iteration: 4464/8000, Loss: 0.126940578222.\n",
      "Iteration: 4465/8000, Loss: 0.126940563321.\n",
      "Iteration: 4466/8000, Loss: 0.12694054842.\n",
      "Iteration: 4467/8000, Loss: 0.12694054842.\n",
      "Iteration: 4468/8000, Loss: 0.126940533519.\n",
      "Iteration: 4469/8000, Loss: 0.126940518618.\n",
      "Iteration: 4470/8000, Loss: 0.126940518618.\n",
      "Iteration: 4471/8000, Loss: 0.126940518618.\n",
      "Iteration: 4472/8000, Loss: 0.126940503716.\n",
      "Iteration: 4473/8000, Loss: 0.126940488815.\n",
      "Iteration: 4474/8000, Loss: 0.126940488815.\n",
      "Iteration: 4475/8000, Loss: 0.126940473914.\n",
      "Iteration: 4476/8000, Loss: 0.126940488815.\n",
      "Iteration: 4477/8000, Loss: 0.126940459013.\n",
      "Iteration: 4478/8000, Loss: 0.126940444112.\n",
      "Iteration: 4479/8000, Loss: 0.126940429211.\n",
      "Iteration: 4480/8000, Loss: 0.126940429211.\n",
      "Iteration: 4481/8000, Loss: 0.12694041431.\n",
      "Iteration: 4482/8000, Loss: 0.12694041431.\n",
      "Iteration: 4483/8000, Loss: 0.126940399408.\n",
      "Iteration: 4484/8000, Loss: 0.126940399408.\n",
      "Iteration: 4485/8000, Loss: 0.126940369606.\n",
      "Iteration: 4486/8000, Loss: 0.126940369606.\n",
      "Iteration: 4487/8000, Loss: 0.126940369606.\n",
      "Iteration: 4488/8000, Loss: 0.126940354705.\n",
      "Iteration: 4489/8000, Loss: 0.126940339804.\n",
      "Iteration: 4490/8000, Loss: 0.126940339804.\n",
      "Iteration: 4491/8000, Loss: 0.126940339804.\n",
      "Iteration: 4492/8000, Loss: 0.126940324903.\n",
      "Iteration: 4493/8000, Loss: 0.126940310001.\n",
      "Iteration: 4494/8000, Loss: 0.126940310001.\n",
      "Iteration: 4495/8000, Loss: 0.1269402951.\n",
      "Iteration: 4496/8000, Loss: 0.126940280199.\n",
      "Iteration: 4497/8000, Loss: 0.126940265298.\n",
      "Iteration: 4498/8000, Loss: 0.126940265298.\n",
      "Iteration: 4499/8000, Loss: 0.126940265298.\n",
      "Iteration: 4500/8000, Loss: 0.126940250397.\n",
      "Iteration: 4501/8000, Loss: 0.126940250397.\n",
      "Iteration: 4502/8000, Loss: 0.126940235496.\n",
      "Iteration: 4503/8000, Loss: 0.126940220594.\n",
      "Iteration: 4504/8000, Loss: 0.126940205693.\n",
      "Iteration: 4505/8000, Loss: 0.126940205693.\n",
      "Iteration: 4506/8000, Loss: 0.126940190792.\n",
      "Iteration: 4507/8000, Loss: 0.126940190792.\n",
      "Iteration: 4508/8000, Loss: 0.126940175891.\n",
      "Iteration: 4509/8000, Loss: 0.126940175891.\n",
      "Iteration: 4510/8000, Loss: 0.12694016099.\n",
      "Iteration: 4511/8000, Loss: 0.126940146089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4512/8000, Loss: 0.126940146089.\n",
      "Iteration: 4513/8000, Loss: 0.126940146089.\n",
      "Iteration: 4514/8000, Loss: 0.126940131187.\n",
      "Iteration: 4515/8000, Loss: 0.126940116286.\n",
      "Iteration: 4516/8000, Loss: 0.126940116286.\n",
      "Iteration: 4517/8000, Loss: 0.126940101385.\n",
      "Iteration: 4518/8000, Loss: 0.126940101385.\n",
      "Iteration: 4519/8000, Loss: 0.126940071583.\n",
      "Iteration: 4520/8000, Loss: 0.126940071583.\n",
      "Iteration: 4521/8000, Loss: 0.126940071583.\n",
      "Iteration: 4522/8000, Loss: 0.126940071583.\n",
      "Iteration: 4523/8000, Loss: 0.12694004178.\n",
      "Iteration: 4524/8000, Loss: 0.12694004178.\n",
      "Iteration: 4525/8000, Loss: 0.12694004178.\n",
      "Iteration: 4526/8000, Loss: 0.126940026879.\n",
      "Iteration: 4527/8000, Loss: 0.126940011978.\n",
      "Iteration: 4528/8000, Loss: 0.126939997077.\n",
      "Iteration: 4529/8000, Loss: 0.126939997077.\n",
      "Iteration: 4530/8000, Loss: 0.126939982176.\n",
      "Iteration: 4531/8000, Loss: 0.126939982176.\n",
      "Iteration: 4532/8000, Loss: 0.126939967275.\n",
      "Iteration: 4533/8000, Loss: 0.126939967275.\n",
      "Iteration: 4534/8000, Loss: 0.126939952374.\n",
      "Iteration: 4535/8000, Loss: 0.126939937472.\n",
      "Iteration: 4536/8000, Loss: 0.126939937472.\n",
      "Iteration: 4537/8000, Loss: 0.126939922571.\n",
      "Iteration: 4538/8000, Loss: 0.126939922571.\n",
      "Iteration: 4539/8000, Loss: 0.12693990767.\n",
      "Iteration: 4540/8000, Loss: 0.12693990767.\n",
      "Iteration: 4541/8000, Loss: 0.126939892769.\n",
      "Iteration: 4542/8000, Loss: 0.126939892769.\n",
      "Iteration: 4543/8000, Loss: 0.126939862967.\n",
      "Iteration: 4544/8000, Loss: 0.126939862967.\n",
      "Iteration: 4545/8000, Loss: 0.126939848065.\n",
      "Iteration: 4546/8000, Loss: 0.126939833164.\n",
      "Iteration: 4547/8000, Loss: 0.126939833164.\n",
      "Iteration: 4548/8000, Loss: 0.126939833164.\n",
      "Iteration: 4549/8000, Loss: 0.126939818263.\n",
      "Iteration: 4550/8000, Loss: 0.126939818263.\n",
      "Iteration: 4551/8000, Loss: 0.126939803362.\n",
      "Iteration: 4552/8000, Loss: 0.126939803362.\n",
      "Iteration: 4553/8000, Loss: 0.126939788461.\n",
      "Iteration: 4554/8000, Loss: 0.12693977356.\n",
      "Iteration: 4555/8000, Loss: 0.12693977356.\n",
      "Iteration: 4556/8000, Loss: 0.12693977356.\n",
      "Iteration: 4557/8000, Loss: 0.12693977356.\n",
      "Iteration: 4558/8000, Loss: 0.126939743757.\n",
      "Iteration: 4559/8000, Loss: 0.126939743757.\n",
      "Iteration: 4560/8000, Loss: 0.126939728856.\n",
      "Iteration: 4561/8000, Loss: 0.126939728856.\n",
      "Iteration: 4562/8000, Loss: 0.126939713955.\n",
      "Iteration: 4563/8000, Loss: 0.126939699054.\n",
      "Iteration: 4564/8000, Loss: 0.126939699054.\n",
      "Iteration: 4565/8000, Loss: 0.126939684153.\n",
      "Iteration: 4566/8000, Loss: 0.126939684153.\n",
      "Iteration: 4567/8000, Loss: 0.126939669251.\n",
      "Iteration: 4568/8000, Loss: 0.12693965435.\n",
      "Iteration: 4569/8000, Loss: 0.12693965435.\n",
      "Iteration: 4570/8000, Loss: 0.12693965435.\n",
      "Iteration: 4571/8000, Loss: 0.126939639449.\n",
      "Iteration: 4572/8000, Loss: 0.126939624548.\n",
      "Iteration: 4573/8000, Loss: 0.126939624548.\n",
      "Iteration: 4574/8000, Loss: 0.126939609647.\n",
      "Iteration: 4575/8000, Loss: 0.126939594746.\n",
      "Iteration: 4576/8000, Loss: 0.126939594746.\n",
      "Iteration: 4577/8000, Loss: 0.126939579844.\n",
      "Iteration: 4578/8000, Loss: 0.126939579844.\n",
      "Iteration: 4579/8000, Loss: 0.126939564943.\n",
      "Iteration: 4580/8000, Loss: 0.126939564943.\n",
      "Iteration: 4581/8000, Loss: 0.126939550042.\n",
      "Iteration: 4582/8000, Loss: 0.126939550042.\n",
      "Iteration: 4583/8000, Loss: 0.126939550042.\n",
      "Iteration: 4584/8000, Loss: 0.126939535141.\n",
      "Iteration: 4585/8000, Loss: 0.12693952024.\n",
      "Iteration: 4586/8000, Loss: 0.126939505339.\n",
      "Iteration: 4587/8000, Loss: 0.126939505339.\n",
      "Iteration: 4588/8000, Loss: 0.126939505339.\n",
      "Iteration: 4589/8000, Loss: 0.126939505339.\n",
      "Iteration: 4590/8000, Loss: 0.126939475536.\n",
      "Iteration: 4591/8000, Loss: 0.126939475536.\n",
      "Iteration: 4592/8000, Loss: 0.126939460635.\n",
      "Iteration: 4593/8000, Loss: 0.126939460635.\n",
      "Iteration: 4594/8000, Loss: 0.126939445734.\n",
      "Iteration: 4595/8000, Loss: 0.126939430833.\n",
      "Iteration: 4596/8000, Loss: 0.126939415932.\n",
      "Iteration: 4597/8000, Loss: 0.126939415932.\n",
      "Iteration: 4598/8000, Loss: 0.126939415932.\n",
      "Iteration: 4599/8000, Loss: 0.126939401031.\n",
      "Iteration: 4600/8000, Loss: 0.126939386129.\n",
      "Iteration: 4601/8000, Loss: 0.126939386129.\n",
      "Iteration: 4602/8000, Loss: 0.126939386129.\n",
      "Iteration: 4603/8000, Loss: 0.126939371228.\n",
      "Iteration: 4604/8000, Loss: 0.126939371228.\n",
      "Iteration: 4605/8000, Loss: 0.126939356327.\n",
      "Iteration: 4606/8000, Loss: 0.126939356327.\n",
      "Iteration: 4607/8000, Loss: 0.126939326525.\n",
      "Iteration: 4608/8000, Loss: 0.126939326525.\n",
      "Iteration: 4609/8000, Loss: 0.126939326525.\n",
      "Iteration: 4610/8000, Loss: 0.126939311624.\n",
      "Iteration: 4611/8000, Loss: 0.126939296722.\n",
      "Iteration: 4612/8000, Loss: 0.126939296722.\n",
      "Iteration: 4613/8000, Loss: 0.126939281821.\n",
      "Iteration: 4614/8000, Loss: 0.126939281821.\n",
      "Iteration: 4615/8000, Loss: 0.126939281821.\n",
      "Iteration: 4616/8000, Loss: 0.12693926692.\n",
      "Iteration: 4617/8000, Loss: 0.126939252019.\n",
      "Iteration: 4618/8000, Loss: 0.126939252019.\n",
      "Iteration: 4619/8000, Loss: 0.126939237118.\n",
      "Iteration: 4620/8000, Loss: 0.126939237118.\n",
      "Iteration: 4621/8000, Loss: 0.126939222217.\n",
      "Iteration: 4622/8000, Loss: 0.126939222217.\n",
      "Iteration: 4623/8000, Loss: 0.126939222217.\n",
      "Iteration: 4624/8000, Loss: 0.126939207315.\n",
      "Iteration: 4625/8000, Loss: 0.126939192414.\n",
      "Iteration: 4626/8000, Loss: 0.126939177513.\n",
      "Iteration: 4627/8000, Loss: 0.126939177513.\n",
      "Iteration: 4628/8000, Loss: 0.126939162612.\n",
      "Iteration: 4629/8000, Loss: 0.126939147711.\n",
      "Iteration: 4630/8000, Loss: 0.126939147711.\n",
      "Iteration: 4631/8000, Loss: 0.126939147711.\n",
      "Iteration: 4632/8000, Loss: 0.12693913281.\n",
      "Iteration: 4633/8000, Loss: 0.126939117908.\n",
      "Iteration: 4634/8000, Loss: 0.126939117908.\n",
      "Iteration: 4635/8000, Loss: 0.126939117908.\n",
      "Iteration: 4636/8000, Loss: 0.126939103007.\n",
      "Iteration: 4637/8000, Loss: 0.126939088106.\n",
      "Iteration: 4638/8000, Loss: 0.126939088106.\n",
      "Iteration: 4639/8000, Loss: 0.126939088106.\n",
      "Iteration: 4640/8000, Loss: 0.126939088106.\n",
      "Iteration: 4641/8000, Loss: 0.126939073205.\n",
      "Iteration: 4642/8000, Loss: 0.126939058304.\n",
      "Iteration: 4643/8000, Loss: 0.126939043403.\n",
      "Iteration: 4644/8000, Loss: 0.126939043403.\n",
      "Iteration: 4645/8000, Loss: 0.126939028502.\n",
      "Iteration: 4646/8000, Loss: 0.126939028502.\n",
      "Iteration: 4647/8000, Loss: 0.1269390136.\n",
      "Iteration: 4648/8000, Loss: 0.1269390136.\n",
      "Iteration: 4649/8000, Loss: 0.1269390136.\n",
      "Iteration: 4650/8000, Loss: 0.126938998699.\n",
      "Iteration: 4651/8000, Loss: 0.126938983798.\n",
      "Iteration: 4652/8000, Loss: 0.126938983798.\n",
      "Iteration: 4653/8000, Loss: 0.126938968897.\n",
      "Iteration: 4654/8000, Loss: 0.126938953996.\n",
      "Iteration: 4655/8000, Loss: 0.126938939095.\n",
      "Iteration: 4656/8000, Loss: 0.126938953996.\n",
      "Iteration: 4657/8000, Loss: 0.126938939095.\n",
      "Iteration: 4658/8000, Loss: 0.126938924193.\n",
      "Iteration: 4659/8000, Loss: 0.126938924193.\n",
      "Iteration: 4660/8000, Loss: 0.126938909292.\n",
      "Iteration: 4661/8000, Loss: 0.126938909292.\n",
      "Iteration: 4662/8000, Loss: 0.126938909292.\n",
      "Iteration: 4663/8000, Loss: 0.126938894391.\n",
      "Iteration: 4664/8000, Loss: 0.12693887949.\n",
      "Iteration: 4665/8000, Loss: 0.12693887949.\n",
      "Iteration: 4666/8000, Loss: 0.126938864589.\n",
      "Iteration: 4667/8000, Loss: 0.126938864589.\n",
      "Iteration: 4668/8000, Loss: 0.126938849688.\n",
      "Iteration: 4669/8000, Loss: 0.126938834786.\n",
      "Iteration: 4670/8000, Loss: 0.126938849688.\n",
      "Iteration: 4671/8000, Loss: 0.126938834786.\n",
      "Iteration: 4672/8000, Loss: 0.126938819885.\n",
      "Iteration: 4673/8000, Loss: 0.126938819885.\n",
      "Iteration: 4674/8000, Loss: 0.126938819885.\n",
      "Iteration: 4675/8000, Loss: 0.126938804984.\n",
      "Iteration: 4676/8000, Loss: 0.126938790083.\n",
      "Iteration: 4677/8000, Loss: 0.126938775182.\n",
      "Iteration: 4678/8000, Loss: 0.126938775182.\n",
      "Iteration: 4679/8000, Loss: 0.126938760281.\n",
      "Iteration: 4680/8000, Loss: 0.126938760281.\n",
      "Iteration: 4681/8000, Loss: 0.126938745379.\n",
      "Iteration: 4682/8000, Loss: 0.126938745379.\n",
      "Iteration: 4683/8000, Loss: 0.126938745379.\n",
      "Iteration: 4684/8000, Loss: 0.126938730478.\n",
      "Iteration: 4685/8000, Loss: 0.126938700676.\n",
      "Iteration: 4686/8000, Loss: 0.126938700676.\n",
      "Iteration: 4687/8000, Loss: 0.126938700676.\n",
      "Iteration: 4688/8000, Loss: 0.126938700676.\n",
      "Iteration: 4689/8000, Loss: 0.126938685775.\n",
      "Iteration: 4690/8000, Loss: 0.126938670874.\n",
      "Iteration: 4691/8000, Loss: 0.126938685775.\n",
      "Iteration: 4692/8000, Loss: 0.126938670874.\n",
      "Iteration: 4693/8000, Loss: 0.126938670874.\n",
      "Iteration: 4694/8000, Loss: 0.126938655972.\n",
      "Iteration: 4695/8000, Loss: 0.126938641071.\n",
      "Iteration: 4696/8000, Loss: 0.126938641071.\n",
      "Iteration: 4697/8000, Loss: 0.126938641071.\n",
      "Iteration: 4698/8000, Loss: 0.126938611269.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4699/8000, Loss: 0.126938611269.\n",
      "Iteration: 4700/8000, Loss: 0.126938596368.\n",
      "Iteration: 4701/8000, Loss: 0.126938596368.\n",
      "Iteration: 4702/8000, Loss: 0.126938581467.\n",
      "Iteration: 4703/8000, Loss: 0.126938581467.\n",
      "Iteration: 4704/8000, Loss: 0.126938581467.\n",
      "Iteration: 4705/8000, Loss: 0.126938566566.\n",
      "Iteration: 4706/8000, Loss: 0.126938566566.\n",
      "Iteration: 4707/8000, Loss: 0.126938551664.\n",
      "Iteration: 4708/8000, Loss: 0.126938536763.\n",
      "Iteration: 4709/8000, Loss: 0.126938536763.\n",
      "Iteration: 4710/8000, Loss: 0.126938521862.\n",
      "Iteration: 4711/8000, Loss: 0.126938521862.\n",
      "Iteration: 4712/8000, Loss: 0.126938506961.\n",
      "Iteration: 4713/8000, Loss: 0.126938506961.\n",
      "Iteration: 4714/8000, Loss: 0.12693849206.\n",
      "Iteration: 4715/8000, Loss: 0.12693849206.\n",
      "Iteration: 4716/8000, Loss: 0.12693849206.\n",
      "Iteration: 4717/8000, Loss: 0.126938477159.\n",
      "Iteration: 4718/8000, Loss: 0.126938477159.\n",
      "Iteration: 4719/8000, Loss: 0.126938462257.\n",
      "Iteration: 4720/8000, Loss: 0.126938462257.\n",
      "Iteration: 4721/8000, Loss: 0.126938447356.\n",
      "Iteration: 4722/8000, Loss: 0.126938447356.\n",
      "Iteration: 4723/8000, Loss: 0.126938417554.\n",
      "Iteration: 4724/8000, Loss: 0.126938432455.\n",
      "Iteration: 4725/8000, Loss: 0.126938417554.\n",
      "Iteration: 4726/8000, Loss: 0.126938402653.\n",
      "Iteration: 4727/8000, Loss: 0.126938402653.\n",
      "Iteration: 4728/8000, Loss: 0.126938402653.\n",
      "Iteration: 4729/8000, Loss: 0.126938387752.\n",
      "Iteration: 4730/8000, Loss: 0.126938387752.\n",
      "Iteration: 4731/8000, Loss: 0.12693837285.\n",
      "Iteration: 4732/8000, Loss: 0.12693837285.\n",
      "Iteration: 4733/8000, Loss: 0.126938343048.\n",
      "Iteration: 4734/8000, Loss: 0.126938343048.\n",
      "Iteration: 4735/8000, Loss: 0.126938343048.\n",
      "Iteration: 4736/8000, Loss: 0.126938343048.\n",
      "Iteration: 4737/8000, Loss: 0.126938328147.\n",
      "Iteration: 4738/8000, Loss: 0.126938328147.\n",
      "Iteration: 4739/8000, Loss: 0.126938313246.\n",
      "Iteration: 4740/8000, Loss: 0.126938298345.\n",
      "Iteration: 4741/8000, Loss: 0.126938298345.\n",
      "Iteration: 4742/8000, Loss: 0.126938298345.\n",
      "Iteration: 4743/8000, Loss: 0.126938283443.\n",
      "Iteration: 4744/8000, Loss: 0.126938268542.\n",
      "Iteration: 4745/8000, Loss: 0.126938268542.\n",
      "Iteration: 4746/8000, Loss: 0.126938268542.\n",
      "Iteration: 4747/8000, Loss: 0.126938253641.\n",
      "Iteration: 4748/8000, Loss: 0.126938253641.\n",
      "Iteration: 4749/8000, Loss: 0.12693823874.\n",
      "Iteration: 4750/8000, Loss: 0.126938223839.\n",
      "Iteration: 4751/8000, Loss: 0.126938223839.\n",
      "Iteration: 4752/8000, Loss: 0.126938223839.\n",
      "Iteration: 4753/8000, Loss: 0.126938208938.\n",
      "Iteration: 4754/8000, Loss: 0.126938194036.\n",
      "Iteration: 4755/8000, Loss: 0.126938194036.\n",
      "Iteration: 4756/8000, Loss: 0.126938194036.\n",
      "Iteration: 4757/8000, Loss: 0.126938179135.\n",
      "Iteration: 4758/8000, Loss: 0.126938164234.\n",
      "Iteration: 4759/8000, Loss: 0.126938164234.\n",
      "Iteration: 4760/8000, Loss: 0.126938149333.\n",
      "Iteration: 4761/8000, Loss: 0.126938149333.\n",
      "Iteration: 4762/8000, Loss: 0.126938149333.\n",
      "Iteration: 4763/8000, Loss: 0.126938134432.\n",
      "Iteration: 4764/8000, Loss: 0.126938134432.\n",
      "Iteration: 4765/8000, Loss: 0.126938134432.\n",
      "Iteration: 4766/8000, Loss: 0.126938119531.\n",
      "Iteration: 4767/8000, Loss: 0.12693810463.\n",
      "Iteration: 4768/8000, Loss: 0.12693810463.\n",
      "Iteration: 4769/8000, Loss: 0.12693810463.\n",
      "Iteration: 4770/8000, Loss: 0.126938089728.\n",
      "Iteration: 4771/8000, Loss: 0.126938074827.\n",
      "Iteration: 4772/8000, Loss: 0.126938074827.\n",
      "Iteration: 4773/8000, Loss: 0.126938074827.\n",
      "Iteration: 4774/8000, Loss: 0.126938059926.\n",
      "Iteration: 4775/8000, Loss: 0.126938045025.\n",
      "Iteration: 4776/8000, Loss: 0.126938045025.\n",
      "Iteration: 4777/8000, Loss: 0.126938030124.\n",
      "Iteration: 4778/8000, Loss: 0.126938015223.\n",
      "Iteration: 4779/8000, Loss: 0.126938015223.\n",
      "Iteration: 4780/8000, Loss: 0.126938015223.\n",
      "Iteration: 4781/8000, Loss: 0.126938015223.\n",
      "Iteration: 4782/8000, Loss: 0.126938000321.\n",
      "Iteration: 4783/8000, Loss: 0.126938000321.\n",
      "Iteration: 4784/8000, Loss: 0.12693798542.\n",
      "Iteration: 4785/8000, Loss: 0.12693798542.\n",
      "Iteration: 4786/8000, Loss: 0.126937970519.\n",
      "Iteration: 4787/8000, Loss: 0.126937955618.\n",
      "Iteration: 4788/8000, Loss: 0.126937955618.\n",
      "Iteration: 4789/8000, Loss: 0.126937955618.\n",
      "Iteration: 4790/8000, Loss: 0.126937940717.\n",
      "Iteration: 4791/8000, Loss: 0.126937940717.\n",
      "Iteration: 4792/8000, Loss: 0.126937940717.\n",
      "Iteration: 4793/8000, Loss: 0.126937925816.\n",
      "Iteration: 4794/8000, Loss: 0.126937925816.\n",
      "Iteration: 4795/8000, Loss: 0.126937925816.\n",
      "Iteration: 4796/8000, Loss: 0.126937896013.\n",
      "Iteration: 4797/8000, Loss: 0.126937881112.\n",
      "Iteration: 4798/8000, Loss: 0.126937881112.\n",
      "Iteration: 4799/8000, Loss: 0.126937881112.\n",
      "Iteration: 4800/8000, Loss: 0.126937881112.\n",
      "Iteration: 4801/8000, Loss: 0.126937866211.\n",
      "Iteration: 4802/8000, Loss: 0.126937866211.\n",
      "Iteration: 4803/8000, Loss: 0.126937866211.\n",
      "Iteration: 4804/8000, Loss: 0.12693785131.\n",
      "Iteration: 4805/8000, Loss: 0.126937836409.\n",
      "Iteration: 4806/8000, Loss: 0.126937836409.\n",
      "Iteration: 4807/8000, Loss: 0.126937836409.\n",
      "Iteration: 4808/8000, Loss: 0.126937806606.\n",
      "Iteration: 4809/8000, Loss: 0.126937821507.\n",
      "Iteration: 4810/8000, Loss: 0.126937806606.\n",
      "Iteration: 4811/8000, Loss: 0.126937791705.\n",
      "Iteration: 4812/8000, Loss: 0.126937776804.\n",
      "Iteration: 4813/8000, Loss: 0.126937776804.\n",
      "Iteration: 4814/8000, Loss: 0.126937776804.\n",
      "Iteration: 4815/8000, Loss: 0.126937776804.\n",
      "Iteration: 4816/8000, Loss: 0.126937761903.\n",
      "Iteration: 4817/8000, Loss: 0.126937761903.\n",
      "Iteration: 4818/8000, Loss: 0.126937747002.\n",
      "Iteration: 4819/8000, Loss: 0.1269377321.\n",
      "Iteration: 4820/8000, Loss: 0.126937747002.\n",
      "Iteration: 4821/8000, Loss: 0.126937717199.\n",
      "Iteration: 4822/8000, Loss: 0.126937717199.\n",
      "Iteration: 4823/8000, Loss: 0.126937717199.\n",
      "Iteration: 4824/8000, Loss: 0.126937702298.\n",
      "Iteration: 4825/8000, Loss: 0.126937702298.\n",
      "Iteration: 4826/8000, Loss: 0.126937687397.\n",
      "Iteration: 4827/8000, Loss: 0.126937687397.\n",
      "Iteration: 4828/8000, Loss: 0.126937687397.\n",
      "Iteration: 4829/8000, Loss: 0.126937672496.\n",
      "Iteration: 4830/8000, Loss: 0.126937672496.\n",
      "Iteration: 4831/8000, Loss: 0.126937657595.\n",
      "Iteration: 4832/8000, Loss: 0.126937657595.\n",
      "Iteration: 4833/8000, Loss: 0.126937642694.\n",
      "Iteration: 4834/8000, Loss: 0.126937642694.\n",
      "Iteration: 4835/8000, Loss: 0.126937627792.\n",
      "Iteration: 4836/8000, Loss: 0.126937627792.\n",
      "Iteration: 4837/8000, Loss: 0.126937612891.\n",
      "Iteration: 4838/8000, Loss: 0.126937612891.\n",
      "Iteration: 4839/8000, Loss: 0.12693759799.\n",
      "Iteration: 4840/8000, Loss: 0.12693759799.\n",
      "Iteration: 4841/8000, Loss: 0.12693759799.\n",
      "Iteration: 4842/8000, Loss: 0.126937583089.\n",
      "Iteration: 4843/8000, Loss: 0.126937583089.\n",
      "Iteration: 4844/8000, Loss: 0.126937568188.\n",
      "Iteration: 4845/8000, Loss: 0.126937568188.\n",
      "Iteration: 4846/8000, Loss: 0.126937553287.\n",
      "Iteration: 4847/8000, Loss: 0.126937538385.\n",
      "Iteration: 4848/8000, Loss: 0.126937553287.\n",
      "Iteration: 4849/8000, Loss: 0.126937538385.\n",
      "Iteration: 4850/8000, Loss: 0.126937523484.\n",
      "Iteration: 4851/8000, Loss: 0.126937523484.\n",
      "Iteration: 4852/8000, Loss: 0.126937523484.\n",
      "Iteration: 4853/8000, Loss: 0.126937523484.\n",
      "Iteration: 4854/8000, Loss: 0.126937508583.\n",
      "Iteration: 4855/8000, Loss: 0.126937493682.\n",
      "Iteration: 4856/8000, Loss: 0.126937478781.\n",
      "Iteration: 4857/8000, Loss: 0.126937478781.\n",
      "Iteration: 4858/8000, Loss: 0.126937478781.\n",
      "Iteration: 4859/8000, Loss: 0.12693746388.\n",
      "Iteration: 4860/8000, Loss: 0.12693746388.\n",
      "Iteration: 4861/8000, Loss: 0.126937448978.\n",
      "Iteration: 4862/8000, Loss: 0.126937448978.\n",
      "Iteration: 4863/8000, Loss: 0.126937448978.\n",
      "Iteration: 4864/8000, Loss: 0.126937448978.\n",
      "Iteration: 4865/8000, Loss: 0.126937434077.\n",
      "Iteration: 4866/8000, Loss: 0.126937419176.\n",
      "Iteration: 4867/8000, Loss: 0.126937419176.\n",
      "Iteration: 4868/8000, Loss: 0.126937419176.\n",
      "Iteration: 4869/8000, Loss: 0.126937389374.\n",
      "Iteration: 4870/8000, Loss: 0.126937389374.\n",
      "Iteration: 4871/8000, Loss: 0.126937389374.\n",
      "Iteration: 4872/8000, Loss: 0.126937374473.\n",
      "Iteration: 4873/8000, Loss: 0.126937374473.\n",
      "Iteration: 4874/8000, Loss: 0.126937359571.\n",
      "Iteration: 4875/8000, Loss: 0.126937359571.\n",
      "Iteration: 4876/8000, Loss: 0.126937359571.\n",
      "Iteration: 4877/8000, Loss: 0.12693734467.\n",
      "Iteration: 4878/8000, Loss: 0.12693734467.\n",
      "Iteration: 4879/8000, Loss: 0.126937329769.\n",
      "Iteration: 4880/8000, Loss: 0.126937329769.\n",
      "Iteration: 4881/8000, Loss: 0.126937329769.\n",
      "Iteration: 4882/8000, Loss: 0.126937329769.\n",
      "Iteration: 4883/8000, Loss: 0.126937314868.\n",
      "Iteration: 4884/8000, Loss: 0.126937299967.\n",
      "Iteration: 4885/8000, Loss: 0.126937299967.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4886/8000, Loss: 0.126937285066.\n",
      "Iteration: 4887/8000, Loss: 0.126937285066.\n",
      "Iteration: 4888/8000, Loss: 0.126937270164.\n",
      "Iteration: 4889/8000, Loss: 0.126937255263.\n",
      "Iteration: 4890/8000, Loss: 0.126937255263.\n",
      "Iteration: 4891/8000, Loss: 0.126937255263.\n",
      "Iteration: 4892/8000, Loss: 0.126937255263.\n",
      "Iteration: 4893/8000, Loss: 0.126937240362.\n",
      "Iteration: 4894/8000, Loss: 0.126937240362.\n",
      "Iteration: 4895/8000, Loss: 0.126937240362.\n",
      "Iteration: 4896/8000, Loss: 0.126937225461.\n",
      "Iteration: 4897/8000, Loss: 0.12693721056.\n",
      "Iteration: 4898/8000, Loss: 0.12693721056.\n",
      "Iteration: 4899/8000, Loss: 0.12693721056.\n",
      "Iteration: 4900/8000, Loss: 0.126937195659.\n",
      "Iteration: 4901/8000, Loss: 0.126937195659.\n",
      "Iteration: 4902/8000, Loss: 0.126937195659.\n",
      "Iteration: 4903/8000, Loss: 0.126937180758.\n",
      "Iteration: 4904/8000, Loss: 0.126937180758.\n",
      "Iteration: 4905/8000, Loss: 0.126937180758.\n",
      "Iteration: 4906/8000, Loss: 0.126937165856.\n",
      "Iteration: 4907/8000, Loss: 0.126937150955.\n",
      "Iteration: 4908/8000, Loss: 0.126937150955.\n",
      "Iteration: 4909/8000, Loss: 0.126937136054.\n",
      "Iteration: 4910/8000, Loss: 0.126937150955.\n",
      "Iteration: 4911/8000, Loss: 0.126937121153.\n",
      "Iteration: 4912/8000, Loss: 0.126937121153.\n",
      "Iteration: 4913/8000, Loss: 0.126937121153.\n",
      "Iteration: 4914/8000, Loss: 0.126937106252.\n",
      "Iteration: 4915/8000, Loss: 0.126937106252.\n",
      "Iteration: 4916/8000, Loss: 0.126937091351.\n",
      "Iteration: 4917/8000, Loss: 0.126937091351.\n",
      "Iteration: 4918/8000, Loss: 0.126937091351.\n",
      "Iteration: 4919/8000, Loss: 0.126937076449.\n",
      "Iteration: 4920/8000, Loss: 0.126937061548.\n",
      "Iteration: 4921/8000, Loss: 0.126937061548.\n",
      "Iteration: 4922/8000, Loss: 0.126937061548.\n",
      "Iteration: 4923/8000, Loss: 0.126937061548.\n",
      "Iteration: 4924/8000, Loss: 0.126937046647.\n",
      "Iteration: 4925/8000, Loss: 0.126937046647.\n",
      "Iteration: 4926/8000, Loss: 0.126937031746.\n",
      "Iteration: 4927/8000, Loss: 0.126937016845.\n",
      "Iteration: 4928/8000, Loss: 0.126937016845.\n",
      "Iteration: 4929/8000, Loss: 0.126937016845.\n",
      "Iteration: 4930/8000, Loss: 0.126937016845.\n",
      "Iteration: 4931/8000, Loss: 0.126937001944.\n",
      "Iteration: 4932/8000, Loss: 0.126936987042.\n",
      "Iteration: 4933/8000, Loss: 0.126936987042.\n",
      "Iteration: 4934/8000, Loss: 0.126936987042.\n",
      "Iteration: 4935/8000, Loss: 0.126936987042.\n",
      "Iteration: 4936/8000, Loss: 0.126936972141.\n",
      "Iteration: 4937/8000, Loss: 0.126936972141.\n",
      "Iteration: 4938/8000, Loss: 0.12693695724.\n",
      "Iteration: 4939/8000, Loss: 0.126936942339.\n",
      "Iteration: 4940/8000, Loss: 0.126936942339.\n",
      "Iteration: 4941/8000, Loss: 0.126936942339.\n",
      "Iteration: 4942/8000, Loss: 0.126936942339.\n",
      "Iteration: 4943/8000, Loss: 0.126936927438.\n",
      "Iteration: 4944/8000, Loss: 0.126936912537.\n",
      "Iteration: 4945/8000, Loss: 0.126936927438.\n",
      "Iteration: 4946/8000, Loss: 0.126936912537.\n",
      "Iteration: 4947/8000, Loss: 0.126936912537.\n",
      "Iteration: 4948/8000, Loss: 0.126936912537.\n",
      "Iteration: 4949/8000, Loss: 0.126936882734.\n",
      "Iteration: 4950/8000, Loss: 0.126936882734.\n",
      "Iteration: 4951/8000, Loss: 0.126936882734.\n",
      "Iteration: 4952/8000, Loss: 0.126936867833.\n",
      "Iteration: 4953/8000, Loss: 0.126936867833.\n",
      "Iteration: 4954/8000, Loss: 0.126936852932.\n",
      "Iteration: 4955/8000, Loss: 0.126936852932.\n",
      "Iteration: 4956/8000, Loss: 0.126936838031.\n",
      "Iteration: 4957/8000, Loss: 0.126936838031.\n",
      "Iteration: 4958/8000, Loss: 0.126936838031.\n",
      "Iteration: 4959/8000, Loss: 0.12693682313.\n",
      "Iteration: 4960/8000, Loss: 0.12693682313.\n",
      "Iteration: 4961/8000, Loss: 0.12693682313.\n",
      "Iteration: 4962/8000, Loss: 0.126936808228.\n",
      "Iteration: 4963/8000, Loss: 0.126936793327.\n",
      "Iteration: 4964/8000, Loss: 0.126936793327.\n",
      "Iteration: 4965/8000, Loss: 0.126936793327.\n",
      "Iteration: 4966/8000, Loss: 0.126936793327.\n",
      "Iteration: 4967/8000, Loss: 0.126936778426.\n",
      "Iteration: 4968/8000, Loss: 0.126936778426.\n",
      "Iteration: 4969/8000, Loss: 0.126936778426.\n",
      "Iteration: 4970/8000, Loss: 0.126936763525.\n",
      "Iteration: 4971/8000, Loss: 0.126936748624.\n",
      "Iteration: 4972/8000, Loss: 0.126936748624.\n",
      "Iteration: 4973/8000, Loss: 0.126936733723.\n",
      "Iteration: 4974/8000, Loss: 0.126936733723.\n",
      "Iteration: 4975/8000, Loss: 0.126936733723.\n",
      "Iteration: 4976/8000, Loss: 0.12693670392.\n",
      "Iteration: 4977/8000, Loss: 0.12693670392.\n",
      "Iteration: 4978/8000, Loss: 0.12693670392.\n",
      "Iteration: 4979/8000, Loss: 0.12693670392.\n",
      "Iteration: 4980/8000, Loss: 0.12693670392.\n",
      "Iteration: 4981/8000, Loss: 0.126936689019.\n",
      "Iteration: 4982/8000, Loss: 0.126936689019.\n",
      "Iteration: 4983/8000, Loss: 0.126936674118.\n",
      "Iteration: 4984/8000, Loss: 0.126936674118.\n",
      "Iteration: 4985/8000, Loss: 0.126936674118.\n",
      "Iteration: 4986/8000, Loss: 0.126936674118.\n",
      "Iteration: 4987/8000, Loss: 0.126936659217.\n",
      "Iteration: 4988/8000, Loss: 0.126936644316.\n",
      "Iteration: 4989/8000, Loss: 0.126936644316.\n",
      "Iteration: 4990/8000, Loss: 0.126936629415.\n",
      "Iteration: 4991/8000, Loss: 0.126936614513.\n",
      "Iteration: 4992/8000, Loss: 0.126936614513.\n",
      "Iteration: 4993/8000, Loss: 0.126936614513.\n",
      "Iteration: 4994/8000, Loss: 0.126936599612.\n",
      "Iteration: 4995/8000, Loss: 0.126936599612.\n",
      "Iteration: 4996/8000, Loss: 0.126936599612.\n",
      "Iteration: 4997/8000, Loss: 0.126936599612.\n",
      "Iteration: 4998/8000, Loss: 0.126936599612.\n",
      "Iteration: 4999/8000, Loss: 0.126936584711.\n",
      "Iteration: 5000/8000, Loss: 0.126936584711.\n",
      "Iteration: 5001/8000, Loss: 0.12693656981.\n",
      "Iteration: 5002/8000, Loss: 0.12693656981.\n",
      "Iteration: 5003/8000, Loss: 0.126936554909.\n",
      "Iteration: 5004/8000, Loss: 0.126936554909.\n",
      "Iteration: 5005/8000, Loss: 0.126936540008.\n",
      "Iteration: 5006/8000, Loss: 0.126936525106.\n",
      "Iteration: 5007/8000, Loss: 0.126936525106.\n",
      "Iteration: 5008/8000, Loss: 0.126936525106.\n",
      "Iteration: 5009/8000, Loss: 0.126936510205.\n",
      "Iteration: 5010/8000, Loss: 0.126936510205.\n",
      "Iteration: 5011/8000, Loss: 0.126936510205.\n",
      "Iteration: 5012/8000, Loss: 0.126936495304.\n",
      "Iteration: 5013/8000, Loss: 0.126936495304.\n",
      "Iteration: 5014/8000, Loss: 0.126936480403.\n",
      "Iteration: 5015/8000, Loss: 0.126936480403.\n",
      "Iteration: 5016/8000, Loss: 0.126936480403.\n",
      "Iteration: 5017/8000, Loss: 0.126936465502.\n",
      "Iteration: 5018/8000, Loss: 0.126936465502.\n",
      "Iteration: 5019/8000, Loss: 0.126936465502.\n",
      "Iteration: 5020/8000, Loss: 0.126936465502.\n",
      "Iteration: 5021/8000, Loss: 0.126936450601.\n",
      "Iteration: 5022/8000, Loss: 0.126936435699.\n",
      "Iteration: 5023/8000, Loss: 0.126936435699.\n",
      "Iteration: 5024/8000, Loss: 0.126936420798.\n",
      "Iteration: 5025/8000, Loss: 0.126936420798.\n",
      "Iteration: 5026/8000, Loss: 0.126936420798.\n",
      "Iteration: 5027/8000, Loss: 0.126936405897.\n",
      "Iteration: 5028/8000, Loss: 0.126936405897.\n",
      "Iteration: 5029/8000, Loss: 0.126936405897.\n",
      "Iteration: 5030/8000, Loss: 0.126936405897.\n",
      "Iteration: 5031/8000, Loss: 0.126936390996.\n",
      "Iteration: 5032/8000, Loss: 0.126936390996.\n",
      "Iteration: 5033/8000, Loss: 0.126936376095.\n",
      "Iteration: 5034/8000, Loss: 0.126936376095.\n",
      "Iteration: 5035/8000, Loss: 0.126936376095.\n",
      "Iteration: 5036/8000, Loss: 0.126936376095.\n",
      "Iteration: 5037/8000, Loss: 0.126936346292.\n",
      "Iteration: 5038/8000, Loss: 0.126936346292.\n",
      "Iteration: 5039/8000, Loss: 0.126936346292.\n",
      "Iteration: 5040/8000, Loss: 0.126936346292.\n",
      "Iteration: 5041/8000, Loss: 0.126936331391.\n",
      "Iteration: 5042/8000, Loss: 0.126936331391.\n",
      "Iteration: 5043/8000, Loss: 0.126936331391.\n",
      "Iteration: 5044/8000, Loss: 0.12693631649.\n",
      "Iteration: 5045/8000, Loss: 0.12693631649.\n",
      "Iteration: 5046/8000, Loss: 0.126936301589.\n",
      "Iteration: 5047/8000, Loss: 0.126936286688.\n",
      "Iteration: 5048/8000, Loss: 0.126936286688.\n",
      "Iteration: 5049/8000, Loss: 0.126936286688.\n",
      "Iteration: 5050/8000, Loss: 0.126936286688.\n",
      "Iteration: 5051/8000, Loss: 0.126936286688.\n",
      "Iteration: 5052/8000, Loss: 0.126936256886.\n",
      "Iteration: 5053/8000, Loss: 0.126936256886.\n",
      "Iteration: 5054/8000, Loss: 0.126936271787.\n",
      "Iteration: 5055/8000, Loss: 0.126936256886.\n",
      "Iteration: 5056/8000, Loss: 0.126936241984.\n",
      "Iteration: 5057/8000, Loss: 0.126936241984.\n",
      "Iteration: 5058/8000, Loss: 0.126936227083.\n",
      "Iteration: 5059/8000, Loss: 0.126936227083.\n",
      "Iteration: 5060/8000, Loss: 0.126936227083.\n",
      "Iteration: 5061/8000, Loss: 0.126936227083.\n",
      "Iteration: 5062/8000, Loss: 0.126936227083.\n",
      "Iteration: 5063/8000, Loss: 0.126936197281.\n",
      "Iteration: 5064/8000, Loss: 0.126936197281.\n",
      "Iteration: 5065/8000, Loss: 0.126936197281.\n",
      "Iteration: 5066/8000, Loss: 0.126936197281.\n",
      "Iteration: 5067/8000, Loss: 0.126936167479.\n",
      "Iteration: 5068/8000, Loss: 0.12693618238.\n",
      "Iteration: 5069/8000, Loss: 0.126936167479.\n",
      "Iteration: 5070/8000, Loss: 0.126936167479.\n",
      "Iteration: 5071/8000, Loss: 0.126936167479.\n",
      "Iteration: 5072/8000, Loss: 0.126936167479.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5073/8000, Loss: 0.126936152577.\n",
      "Iteration: 5074/8000, Loss: 0.126936137676.\n",
      "Iteration: 5075/8000, Loss: 0.126936137676.\n",
      "Iteration: 5076/8000, Loss: 0.126936137676.\n",
      "Iteration: 5077/8000, Loss: 0.126936137676.\n",
      "Iteration: 5078/8000, Loss: 0.126936122775.\n",
      "Iteration: 5079/8000, Loss: 0.126936107874.\n",
      "Iteration: 5080/8000, Loss: 0.126936107874.\n",
      "Iteration: 5081/8000, Loss: 0.126936107874.\n",
      "Iteration: 5082/8000, Loss: 0.126936092973.\n",
      "Iteration: 5083/8000, Loss: 0.126936092973.\n",
      "Iteration: 5084/8000, Loss: 0.126936078072.\n",
      "Iteration: 5085/8000, Loss: 0.126936078072.\n",
      "Iteration: 5086/8000, Loss: 0.126936078072.\n",
      "Iteration: 5087/8000, Loss: 0.12693606317.\n",
      "Iteration: 5088/8000, Loss: 0.12693606317.\n",
      "Iteration: 5089/8000, Loss: 0.126936048269.\n",
      "Iteration: 5090/8000, Loss: 0.126936048269.\n",
      "Iteration: 5091/8000, Loss: 0.126936048269.\n",
      "Iteration: 5092/8000, Loss: 0.126936048269.\n",
      "Iteration: 5093/8000, Loss: 0.126936033368.\n",
      "Iteration: 5094/8000, Loss: 0.126936033368.\n",
      "Iteration: 5095/8000, Loss: 0.126936018467.\n",
      "Iteration: 5096/8000, Loss: 0.126936018467.\n",
      "Iteration: 5097/8000, Loss: 0.126936018467.\n",
      "Iteration: 5098/8000, Loss: 0.126936018467.\n",
      "Iteration: 5099/8000, Loss: 0.126936003566.\n",
      "Iteration: 5100/8000, Loss: 0.126936003566.\n",
      "Iteration: 5101/8000, Loss: 0.126935988665.\n",
      "Iteration: 5102/8000, Loss: 0.126935988665.\n",
      "Iteration: 5103/8000, Loss: 0.126935988665.\n",
      "Iteration: 5104/8000, Loss: 0.126935973763.\n",
      "Iteration: 5105/8000, Loss: 0.126935958862.\n",
      "Iteration: 5106/8000, Loss: 0.126935958862.\n",
      "Iteration: 5107/8000, Loss: 0.126935958862.\n",
      "Iteration: 5108/8000, Loss: 0.126935958862.\n",
      "Iteration: 5109/8000, Loss: 0.126935958862.\n",
      "Iteration: 5110/8000, Loss: 0.126935943961.\n",
      "Iteration: 5111/8000, Loss: 0.12693592906.\n",
      "Iteration: 5112/8000, Loss: 0.12693592906.\n",
      "Iteration: 5113/8000, Loss: 0.12693592906.\n",
      "Iteration: 5114/8000, Loss: 0.12693592906.\n",
      "Iteration: 5115/8000, Loss: 0.126935914159.\n",
      "Iteration: 5116/8000, Loss: 0.12693592906.\n",
      "Iteration: 5117/8000, Loss: 0.126935914159.\n",
      "Iteration: 5118/8000, Loss: 0.126935899258.\n",
      "Iteration: 5119/8000, Loss: 0.126935884356.\n",
      "Iteration: 5120/8000, Loss: 0.126935899258.\n",
      "Iteration: 5121/8000, Loss: 0.126935884356.\n",
      "Iteration: 5122/8000, Loss: 0.126935884356.\n",
      "Iteration: 5123/8000, Loss: 0.126935869455.\n",
      "Iteration: 5124/8000, Loss: 0.126935869455.\n",
      "Iteration: 5125/8000, Loss: 0.126935869455.\n",
      "Iteration: 5126/8000, Loss: 0.126935854554.\n",
      "Iteration: 5127/8000, Loss: 0.126935854554.\n",
      "Iteration: 5128/8000, Loss: 0.126935839653.\n",
      "Iteration: 5129/8000, Loss: 0.126935839653.\n",
      "Iteration: 5130/8000, Loss: 0.126935824752.\n",
      "Iteration: 5131/8000, Loss: 0.126935824752.\n",
      "Iteration: 5132/8000, Loss: 0.126935824752.\n",
      "Iteration: 5133/8000, Loss: 0.126935809851.\n",
      "Iteration: 5134/8000, Loss: 0.126935809851.\n",
      "Iteration: 5135/8000, Loss: 0.126935809851.\n",
      "Iteration: 5136/8000, Loss: 0.12693579495.\n",
      "Iteration: 5137/8000, Loss: 0.12693579495.\n",
      "Iteration: 5138/8000, Loss: 0.12693579495.\n",
      "Iteration: 5139/8000, Loss: 0.12693579495.\n",
      "Iteration: 5140/8000, Loss: 0.12693579495.\n",
      "Iteration: 5141/8000, Loss: 0.12693579495.\n",
      "Iteration: 5142/8000, Loss: 0.126935780048.\n",
      "Iteration: 5143/8000, Loss: 0.126935780048.\n",
      "Iteration: 5144/8000, Loss: 0.126935750246.\n",
      "Iteration: 5145/8000, Loss: 0.126935750246.\n",
      "Iteration: 5146/8000, Loss: 0.126935750246.\n",
      "Iteration: 5147/8000, Loss: 0.126935750246.\n",
      "Iteration: 5148/8000, Loss: 0.126935720444.\n",
      "Iteration: 5149/8000, Loss: 0.126935720444.\n",
      "Iteration: 5150/8000, Loss: 0.126935720444.\n",
      "Iteration: 5151/8000, Loss: 0.126935720444.\n",
      "Iteration: 5152/8000, Loss: 0.126935720444.\n",
      "Iteration: 5153/8000, Loss: 0.126935720444.\n",
      "Iteration: 5154/8000, Loss: 0.126935705543.\n",
      "Iteration: 5155/8000, Loss: 0.126935690641.\n",
      "Iteration: 5156/8000, Loss: 0.126935690641.\n",
      "Iteration: 5157/8000, Loss: 0.126935690641.\n",
      "Iteration: 5158/8000, Loss: 0.126935690641.\n",
      "Iteration: 5159/8000, Loss: 0.126935690641.\n",
      "Iteration: 5160/8000, Loss: 0.126935690641.\n",
      "Iteration: 5161/8000, Loss: 0.126935660839.\n",
      "Iteration: 5162/8000, Loss: 0.12693567574.\n",
      "Iteration: 5163/8000, Loss: 0.126935660839.\n",
      "Iteration: 5164/8000, Loss: 0.126935645938.\n",
      "Iteration: 5165/8000, Loss: 0.126935645938.\n",
      "Iteration: 5166/8000, Loss: 0.126935645938.\n",
      "Iteration: 5167/8000, Loss: 0.126935631037.\n",
      "Iteration: 5168/8000, Loss: 0.126935631037.\n",
      "Iteration: 5169/8000, Loss: 0.126935616136.\n",
      "Iteration: 5170/8000, Loss: 0.126935616136.\n",
      "Iteration: 5171/8000, Loss: 0.126935616136.\n",
      "Iteration: 5172/8000, Loss: 0.126935616136.\n",
      "Iteration: 5173/8000, Loss: 0.126935616136.\n",
      "Iteration: 5174/8000, Loss: 0.126935601234.\n",
      "Iteration: 5175/8000, Loss: 0.126935601234.\n",
      "Iteration: 5176/8000, Loss: 0.126935601234.\n",
      "Iteration: 5177/8000, Loss: 0.126935586333.\n",
      "Iteration: 5178/8000, Loss: 0.126935571432.\n",
      "Iteration: 5179/8000, Loss: 0.126935586333.\n",
      "Iteration: 5180/8000, Loss: 0.126935571432.\n",
      "Iteration: 5181/8000, Loss: 0.126935556531.\n",
      "Iteration: 5182/8000, Loss: 0.126935556531.\n",
      "Iteration: 5183/8000, Loss: 0.126935556531.\n",
      "Iteration: 5184/8000, Loss: 0.126935556531.\n",
      "Iteration: 5185/8000, Loss: 0.126935556531.\n",
      "Iteration: 5186/8000, Loss: 0.12693554163.\n",
      "Iteration: 5187/8000, Loss: 0.12693554163.\n",
      "Iteration: 5188/8000, Loss: 0.12693554163.\n",
      "Iteration: 5189/8000, Loss: 0.126935526729.\n",
      "Iteration: 5190/8000, Loss: 0.126935526729.\n",
      "Iteration: 5191/8000, Loss: 0.126935511827.\n",
      "Iteration: 5192/8000, Loss: 0.126935496926.\n",
      "Iteration: 5193/8000, Loss: 0.126935496926.\n",
      "Iteration: 5194/8000, Loss: 0.126935496926.\n",
      "Iteration: 5195/8000, Loss: 0.126935482025.\n",
      "Iteration: 5196/8000, Loss: 0.126935482025.\n",
      "Iteration: 5197/8000, Loss: 0.126935482025.\n",
      "Iteration: 5198/8000, Loss: 0.126935467124.\n",
      "Iteration: 5199/8000, Loss: 0.126935467124.\n",
      "Iteration: 5200/8000, Loss: 0.126935467124.\n",
      "Iteration: 5201/8000, Loss: 0.126935467124.\n",
      "Iteration: 5202/8000, Loss: 0.126935452223.\n",
      "Iteration: 5203/8000, Loss: 0.126935452223.\n",
      "Iteration: 5204/8000, Loss: 0.126935452223.\n",
      "Iteration: 5205/8000, Loss: 0.126935452223.\n",
      "Iteration: 5206/8000, Loss: 0.126935437322.\n",
      "Iteration: 5207/8000, Loss: 0.126935422421.\n",
      "Iteration: 5208/8000, Loss: 0.126935422421.\n",
      "Iteration: 5209/8000, Loss: 0.126935422421.\n",
      "Iteration: 5210/8000, Loss: 0.126935422421.\n",
      "Iteration: 5211/8000, Loss: 0.126935422421.\n",
      "Iteration: 5212/8000, Loss: 0.126935407519.\n",
      "Iteration: 5213/8000, Loss: 0.126935407519.\n",
      "Iteration: 5214/8000, Loss: 0.126935407519.\n",
      "Iteration: 5215/8000, Loss: 0.126935392618.\n",
      "Iteration: 5216/8000, Loss: 0.126935377717.\n",
      "Iteration: 5217/8000, Loss: 0.126935377717.\n",
      "Iteration: 5218/8000, Loss: 0.126935377717.\n",
      "Iteration: 5219/8000, Loss: 0.126935362816.\n",
      "Iteration: 5220/8000, Loss: 0.126935362816.\n",
      "Iteration: 5221/8000, Loss: 0.126935362816.\n",
      "Iteration: 5222/8000, Loss: 0.126935362816.\n",
      "Iteration: 5223/8000, Loss: 0.126935347915.\n",
      "Iteration: 5224/8000, Loss: 0.126935347915.\n",
      "Iteration: 5225/8000, Loss: 0.126935347915.\n",
      "Iteration: 5226/8000, Loss: 0.126935333014.\n",
      "Iteration: 5227/8000, Loss: 0.126935333014.\n",
      "Iteration: 5228/8000, Loss: 0.126935318112.\n",
      "Iteration: 5229/8000, Loss: 0.126935318112.\n",
      "Iteration: 5230/8000, Loss: 0.126935303211.\n",
      "Iteration: 5231/8000, Loss: 0.126935303211.\n",
      "Iteration: 5232/8000, Loss: 0.126935303211.\n",
      "Iteration: 5233/8000, Loss: 0.126935303211.\n",
      "Iteration: 5234/8000, Loss: 0.12693528831.\n",
      "Iteration: 5235/8000, Loss: 0.12693528831.\n",
      "Iteration: 5236/8000, Loss: 0.12693528831.\n",
      "Iteration: 5237/8000, Loss: 0.126935273409.\n",
      "Iteration: 5238/8000, Loss: 0.126935273409.\n",
      "Iteration: 5239/8000, Loss: 0.126935273409.\n",
      "Iteration: 5240/8000, Loss: 0.126935258508.\n",
      "Iteration: 5241/8000, Loss: 0.126935273409.\n",
      "Iteration: 5242/8000, Loss: 0.126935243607.\n",
      "Iteration: 5243/8000, Loss: 0.126935258508.\n",
      "Iteration: 5244/8000, Loss: 0.126935243607.\n",
      "Iteration: 5245/8000, Loss: 0.126935243607.\n",
      "Iteration: 5246/8000, Loss: 0.126935228705.\n",
      "Iteration: 5247/8000, Loss: 0.126935243607.\n",
      "Iteration: 5248/8000, Loss: 0.126935228705.\n",
      "Iteration: 5249/8000, Loss: 0.126935228705.\n",
      "Iteration: 5250/8000, Loss: 0.126935213804.\n",
      "Iteration: 5251/8000, Loss: 0.126935213804.\n",
      "Iteration: 5252/8000, Loss: 0.126935213804.\n",
      "Iteration: 5253/8000, Loss: 0.126935213804.\n",
      "Iteration: 5254/8000, Loss: 0.126935184002.\n",
      "Iteration: 5255/8000, Loss: 0.126935184002.\n",
      "Iteration: 5256/8000, Loss: 0.126935184002.\n",
      "Iteration: 5257/8000, Loss: 0.126935184002.\n",
      "Iteration: 5258/8000, Loss: 0.126935184002.\n",
      "Iteration: 5259/8000, Loss: 0.126935184002.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5260/8000, Loss: 0.126935169101.\n",
      "Iteration: 5261/8000, Loss: 0.126935169101.\n",
      "Iteration: 5262/8000, Loss: 0.126935169101.\n",
      "Iteration: 5263/8000, Loss: 0.1269351542.\n",
      "Iteration: 5264/8000, Loss: 0.1269351542.\n",
      "Iteration: 5265/8000, Loss: 0.126935139298.\n",
      "Iteration: 5266/8000, Loss: 0.126935139298.\n",
      "Iteration: 5267/8000, Loss: 0.126935139298.\n",
      "Iteration: 5268/8000, Loss: 0.126935124397.\n",
      "Iteration: 5269/8000, Loss: 0.126935124397.\n",
      "Iteration: 5270/8000, Loss: 0.126935124397.\n",
      "Iteration: 5271/8000, Loss: 0.126935124397.\n",
      "Iteration: 5272/8000, Loss: 0.126935109496.\n",
      "Iteration: 5273/8000, Loss: 0.126935109496.\n",
      "Iteration: 5274/8000, Loss: 0.126935109496.\n",
      "Iteration: 5275/8000, Loss: 0.126935094595.\n",
      "Iteration: 5276/8000, Loss: 0.126935094595.\n",
      "Iteration: 5277/8000, Loss: 0.126935094595.\n",
      "Iteration: 5278/8000, Loss: 0.126935079694.\n",
      "Iteration: 5279/8000, Loss: 0.126935079694.\n",
      "Iteration: 5280/8000, Loss: 0.126935079694.\n",
      "Iteration: 5281/8000, Loss: 0.126935064793.\n",
      "Iteration: 5282/8000, Loss: 0.126935064793.\n",
      "Iteration: 5283/8000, Loss: 0.126935049891.\n",
      "Iteration: 5284/8000, Loss: 0.126935049891.\n",
      "Iteration: 5285/8000, Loss: 0.126935049891.\n",
      "Iteration: 5286/8000, Loss: 0.126935049891.\n",
      "Iteration: 5287/8000, Loss: 0.12693503499.\n",
      "Iteration: 5288/8000, Loss: 0.12693503499.\n",
      "Iteration: 5289/8000, Loss: 0.12693503499.\n",
      "Iteration: 5290/8000, Loss: 0.12693503499.\n",
      "Iteration: 5291/8000, Loss: 0.126935020089.\n",
      "Iteration: 5292/8000, Loss: 0.12693503499.\n",
      "Iteration: 5293/8000, Loss: 0.126935005188.\n",
      "Iteration: 5294/8000, Loss: 0.126935005188.\n",
      "Iteration: 5295/8000, Loss: 0.126935005188.\n",
      "Iteration: 5296/8000, Loss: 0.126934990287.\n",
      "Iteration: 5297/8000, Loss: 0.126934975386.\n",
      "Iteration: 5298/8000, Loss: 0.126934975386.\n",
      "Iteration: 5299/8000, Loss: 0.126934975386.\n",
      "Iteration: 5300/8000, Loss: 0.126934975386.\n",
      "Iteration: 5301/8000, Loss: 0.126934975386.\n",
      "Iteration: 5302/8000, Loss: 0.126934975386.\n",
      "Iteration: 5303/8000, Loss: 0.126934975386.\n",
      "Iteration: 5304/8000, Loss: 0.126934960485.\n",
      "Iteration: 5305/8000, Loss: 0.126934945583.\n",
      "Iteration: 5306/8000, Loss: 0.126934945583.\n",
      "Iteration: 5307/8000, Loss: 0.126934945583.\n",
      "Iteration: 5308/8000, Loss: 0.126934945583.\n",
      "Iteration: 5309/8000, Loss: 0.126934945583.\n",
      "Iteration: 5310/8000, Loss: 0.126934945583.\n",
      "Iteration: 5311/8000, Loss: 0.126934930682.\n",
      "Iteration: 5312/8000, Loss: 0.126934915781.\n",
      "Iteration: 5313/8000, Loss: 0.126934915781.\n",
      "Iteration: 5314/8000, Loss: 0.126934915781.\n",
      "Iteration: 5315/8000, Loss: 0.12693490088.\n",
      "Iteration: 5316/8000, Loss: 0.12693490088.\n",
      "Iteration: 5317/8000, Loss: 0.12693490088.\n",
      "Iteration: 5318/8000, Loss: 0.12693490088.\n",
      "Iteration: 5319/8000, Loss: 0.126934885979.\n",
      "Iteration: 5320/8000, Loss: 0.126934885979.\n",
      "Iteration: 5321/8000, Loss: 0.126934885979.\n",
      "Iteration: 5322/8000, Loss: 0.126934885979.\n",
      "Iteration: 5323/8000, Loss: 0.126934871078.\n",
      "Iteration: 5324/8000, Loss: 0.126934871078.\n",
      "Iteration: 5325/8000, Loss: 0.126934856176.\n",
      "Iteration: 5326/8000, Loss: 0.126934856176.\n",
      "Iteration: 5327/8000, Loss: 0.126934841275.\n",
      "Iteration: 5328/8000, Loss: 0.126934841275.\n",
      "Iteration: 5329/8000, Loss: 0.126934826374.\n",
      "Iteration: 5330/8000, Loss: 0.126934841275.\n",
      "Iteration: 5331/8000, Loss: 0.126934826374.\n",
      "Iteration: 5332/8000, Loss: 0.126934826374.\n",
      "Iteration: 5333/8000, Loss: 0.126934811473.\n",
      "Iteration: 5334/8000, Loss: 0.126934811473.\n",
      "Iteration: 5335/8000, Loss: 0.126934811473.\n",
      "Iteration: 5336/8000, Loss: 0.126934811473.\n",
      "Iteration: 5337/8000, Loss: 0.126934811473.\n",
      "Iteration: 5338/8000, Loss: 0.126934811473.\n",
      "Iteration: 5339/8000, Loss: 0.126934796572.\n",
      "Iteration: 5340/8000, Loss: 0.126934781671.\n",
      "Iteration: 5341/8000, Loss: 0.126934781671.\n",
      "Iteration: 5342/8000, Loss: 0.126934781671.\n",
      "Iteration: 5343/8000, Loss: 0.126934781671.\n",
      "Iteration: 5344/8000, Loss: 0.126934781671.\n",
      "Iteration: 5345/8000, Loss: 0.126934766769.\n",
      "Iteration: 5346/8000, Loss: 0.126934766769.\n",
      "Iteration: 5347/8000, Loss: 0.126934766769.\n",
      "Iteration: 5348/8000, Loss: 0.126934751868.\n",
      "Iteration: 5349/8000, Loss: 0.126934751868.\n",
      "Iteration: 5350/8000, Loss: 0.126934736967.\n",
      "Iteration: 5351/8000, Loss: 0.126934736967.\n",
      "Iteration: 5352/8000, Loss: 0.126934736967.\n",
      "Iteration: 5353/8000, Loss: 0.126934736967.\n",
      "Iteration: 5354/8000, Loss: 0.126934722066.\n",
      "Iteration: 5355/8000, Loss: 0.126934722066.\n",
      "Iteration: 5356/8000, Loss: 0.126934722066.\n",
      "Iteration: 5357/8000, Loss: 0.126934707165.\n",
      "Iteration: 5358/8000, Loss: 0.126934707165.\n",
      "Iteration: 5359/8000, Loss: 0.126934707165.\n",
      "Iteration: 5360/8000, Loss: 0.126934707165.\n",
      "Iteration: 5361/8000, Loss: 0.126934707165.\n",
      "Iteration: 5362/8000, Loss: 0.126934692264.\n",
      "Iteration: 5363/8000, Loss: 0.126934677362.\n",
      "Iteration: 5364/8000, Loss: 0.126934677362.\n",
      "Iteration: 5365/8000, Loss: 0.126934677362.\n",
      "Iteration: 5366/8000, Loss: 0.126934662461.\n",
      "Iteration: 5367/8000, Loss: 0.126934662461.\n",
      "Iteration: 5368/8000, Loss: 0.126934677362.\n",
      "Iteration: 5369/8000, Loss: 0.12693464756.\n",
      "Iteration: 5370/8000, Loss: 0.12693464756.\n",
      "Iteration: 5371/8000, Loss: 0.12693464756.\n",
      "Iteration: 5372/8000, Loss: 0.12693464756.\n",
      "Iteration: 5373/8000, Loss: 0.126934632659.\n",
      "Iteration: 5374/8000, Loss: 0.126934632659.\n",
      "Iteration: 5375/8000, Loss: 0.126934632659.\n",
      "Iteration: 5376/8000, Loss: 0.126934617758.\n",
      "Iteration: 5377/8000, Loss: 0.126934617758.\n",
      "Iteration: 5378/8000, Loss: 0.126934617758.\n",
      "Iteration: 5379/8000, Loss: 0.126934617758.\n",
      "Iteration: 5380/8000, Loss: 0.126934617758.\n",
      "Iteration: 5381/8000, Loss: 0.126934602857.\n",
      "Iteration: 5382/8000, Loss: 0.126934602857.\n",
      "Iteration: 5383/8000, Loss: 0.126934602857.\n",
      "Iteration: 5384/8000, Loss: 0.126934602857.\n",
      "Iteration: 5385/8000, Loss: 0.126934573054.\n",
      "Iteration: 5386/8000, Loss: 0.126934573054.\n",
      "Iteration: 5387/8000, Loss: 0.126934573054.\n",
      "Iteration: 5388/8000, Loss: 0.126934573054.\n",
      "Iteration: 5389/8000, Loss: 0.126934573054.\n",
      "Iteration: 5390/8000, Loss: 0.126934573054.\n",
      "Iteration: 5391/8000, Loss: 0.126934558153.\n",
      "Iteration: 5392/8000, Loss: 0.126934558153.\n",
      "Iteration: 5393/8000, Loss: 0.126934543252.\n",
      "Iteration: 5394/8000, Loss: 0.126934543252.\n",
      "Iteration: 5395/8000, Loss: 0.126934543252.\n",
      "Iteration: 5396/8000, Loss: 0.126934543252.\n",
      "Iteration: 5397/8000, Loss: 0.126934543252.\n",
      "Iteration: 5398/8000, Loss: 0.126934543252.\n",
      "Iteration: 5399/8000, Loss: 0.126934543252.\n",
      "Iteration: 5400/8000, Loss: 0.126934543252.\n",
      "Iteration: 5401/8000, Loss: 0.126934528351.\n",
      "Iteration: 5402/8000, Loss: 0.12693451345.\n",
      "Iteration: 5403/8000, Loss: 0.12693451345.\n",
      "Iteration: 5404/8000, Loss: 0.12693451345.\n",
      "Iteration: 5405/8000, Loss: 0.126934498549.\n",
      "Iteration: 5406/8000, Loss: 0.12693451345.\n",
      "Iteration: 5407/8000, Loss: 0.126934498549.\n",
      "Iteration: 5408/8000, Loss: 0.126934483647.\n",
      "Iteration: 5409/8000, Loss: 0.126934483647.\n",
      "Iteration: 5410/8000, Loss: 0.126934483647.\n",
      "Iteration: 5411/8000, Loss: 0.126934468746.\n",
      "Iteration: 5412/8000, Loss: 0.126934468746.\n",
      "Iteration: 5413/8000, Loss: 0.126934468746.\n",
      "Iteration: 5414/8000, Loss: 0.126934468746.\n",
      "Iteration: 5415/8000, Loss: 0.126934468746.\n",
      "Iteration: 5416/8000, Loss: 0.126934453845.\n",
      "Iteration: 5417/8000, Loss: 0.126934438944.\n",
      "Iteration: 5418/8000, Loss: 0.126934438944.\n",
      "Iteration: 5419/8000, Loss: 0.126934438944.\n",
      "Iteration: 5420/8000, Loss: 0.126934438944.\n",
      "Iteration: 5421/8000, Loss: 0.126934438944.\n",
      "Iteration: 5422/8000, Loss: 0.126934438944.\n",
      "Iteration: 5423/8000, Loss: 0.126934438944.\n",
      "Iteration: 5424/8000, Loss: 0.126934424043.\n",
      "Iteration: 5425/8000, Loss: 0.126934424043.\n",
      "Iteration: 5426/8000, Loss: 0.126934424043.\n",
      "Iteration: 5427/8000, Loss: 0.126934409142.\n",
      "Iteration: 5428/8000, Loss: 0.126934409142.\n",
      "Iteration: 5429/8000, Loss: 0.126934409142.\n",
      "Iteration: 5430/8000, Loss: 0.126934409142.\n",
      "Iteration: 5431/8000, Loss: 0.12693439424.\n",
      "Iteration: 5432/8000, Loss: 0.12693439424.\n",
      "Iteration: 5433/8000, Loss: 0.126934379339.\n",
      "Iteration: 5434/8000, Loss: 0.12693439424.\n",
      "Iteration: 5435/8000, Loss: 0.126934379339.\n",
      "Iteration: 5436/8000, Loss: 0.126934379339.\n",
      "Iteration: 5437/8000, Loss: 0.126934379339.\n",
      "Iteration: 5438/8000, Loss: 0.126934364438.\n",
      "Iteration: 5439/8000, Loss: 0.126934349537.\n",
      "Iteration: 5440/8000, Loss: 0.126934349537.\n",
      "Iteration: 5441/8000, Loss: 0.126934349537.\n",
      "Iteration: 5442/8000, Loss: 0.126934334636.\n",
      "Iteration: 5443/8000, Loss: 0.126934334636.\n",
      "Iteration: 5444/8000, Loss: 0.126934334636.\n",
      "Iteration: 5445/8000, Loss: 0.126934319735.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5446/8000, Loss: 0.126934334636.\n",
      "Iteration: 5447/8000, Loss: 0.126934319735.\n",
      "Iteration: 5448/8000, Loss: 0.126934319735.\n",
      "Iteration: 5449/8000, Loss: 0.126934304833.\n",
      "Iteration: 5450/8000, Loss: 0.126934319735.\n",
      "Iteration: 5451/8000, Loss: 0.126934304833.\n",
      "Iteration: 5452/8000, Loss: 0.126934289932.\n",
      "Iteration: 5453/8000, Loss: 0.126934289932.\n",
      "Iteration: 5454/8000, Loss: 0.126934289932.\n",
      "Iteration: 5455/8000, Loss: 0.126934289932.\n",
      "Iteration: 5456/8000, Loss: 0.126934289932.\n",
      "Iteration: 5457/8000, Loss: 0.126934275031.\n",
      "Iteration: 5458/8000, Loss: 0.126934275031.\n",
      "Iteration: 5459/8000, Loss: 0.126934275031.\n",
      "Iteration: 5460/8000, Loss: 0.12693426013.\n",
      "Iteration: 5461/8000, Loss: 0.12693426013.\n",
      "Iteration: 5462/8000, Loss: 0.12693426013.\n",
      "Iteration: 5463/8000, Loss: 0.12693426013.\n",
      "Iteration: 5464/8000, Loss: 0.12693426013.\n",
      "Iteration: 5465/8000, Loss: 0.126934245229.\n",
      "Iteration: 5466/8000, Loss: 0.126934245229.\n",
      "Iteration: 5467/8000, Loss: 0.126934230328.\n",
      "Iteration: 5468/8000, Loss: 0.126934230328.\n",
      "Iteration: 5469/8000, Loss: 0.126934230328.\n",
      "Iteration: 5470/8000, Loss: 0.126934230328.\n",
      "Iteration: 5471/8000, Loss: 0.126934230328.\n",
      "Iteration: 5472/8000, Loss: 0.126934230328.\n",
      "Iteration: 5473/8000, Loss: 0.126934215426.\n",
      "Iteration: 5474/8000, Loss: 0.126934215426.\n",
      "Iteration: 5475/8000, Loss: 0.126934200525.\n",
      "Iteration: 5476/8000, Loss: 0.126934200525.\n",
      "Iteration: 5477/8000, Loss: 0.126934200525.\n",
      "Iteration: 5478/8000, Loss: 0.126934200525.\n",
      "Iteration: 5479/8000, Loss: 0.126934185624.\n",
      "Iteration: 5480/8000, Loss: 0.126934185624.\n",
      "Iteration: 5481/8000, Loss: 0.126934170723.\n",
      "Iteration: 5482/8000, Loss: 0.126934185624.\n",
      "Iteration: 5483/8000, Loss: 0.126934170723.\n",
      "Iteration: 5484/8000, Loss: 0.126934170723.\n",
      "Iteration: 5485/8000, Loss: 0.126934170723.\n",
      "Iteration: 5486/8000, Loss: 0.126934170723.\n",
      "Iteration: 5487/8000, Loss: 0.126934155822.\n",
      "Iteration: 5488/8000, Loss: 0.126934140921.\n",
      "Iteration: 5489/8000, Loss: 0.126934140921.\n",
      "Iteration: 5490/8000, Loss: 0.126934140921.\n",
      "Iteration: 5491/8000, Loss: 0.126934140921.\n",
      "Iteration: 5492/8000, Loss: 0.126934140921.\n",
      "Iteration: 5493/8000, Loss: 0.126934140921.\n",
      "Iteration: 5494/8000, Loss: 0.126934126019.\n",
      "Iteration: 5495/8000, Loss: 0.126934111118.\n",
      "Iteration: 5496/8000, Loss: 0.126934126019.\n",
      "Iteration: 5497/8000, Loss: 0.126934111118.\n",
      "Iteration: 5498/8000, Loss: 0.126934111118.\n",
      "Iteration: 5499/8000, Loss: 0.126934111118.\n",
      "Iteration: 5500/8000, Loss: 0.126934096217.\n",
      "Iteration: 5501/8000, Loss: 0.126934096217.\n",
      "Iteration: 5502/8000, Loss: 0.126934096217.\n",
      "Iteration: 5503/8000, Loss: 0.126934096217.\n",
      "Iteration: 5504/8000, Loss: 0.126934096217.\n",
      "Iteration: 5505/8000, Loss: 0.126934096217.\n",
      "Iteration: 5506/8000, Loss: 0.126934096217.\n",
      "Iteration: 5507/8000, Loss: 0.126934081316.\n",
      "Iteration: 5508/8000, Loss: 0.126934081316.\n",
      "Iteration: 5509/8000, Loss: 0.126934066415.\n",
      "Iteration: 5510/8000, Loss: 0.126934066415.\n",
      "Iteration: 5511/8000, Loss: 0.126934066415.\n",
      "Iteration: 5512/8000, Loss: 0.126934066415.\n",
      "Iteration: 5513/8000, Loss: 0.126934051514.\n",
      "Iteration: 5514/8000, Loss: 0.126934051514.\n",
      "Iteration: 5515/8000, Loss: 0.126934051514.\n",
      "Iteration: 5516/8000, Loss: 0.126934036613.\n",
      "Iteration: 5517/8000, Loss: 0.126934051514.\n",
      "Iteration: 5518/8000, Loss: 0.126934036613.\n",
      "Iteration: 5519/8000, Loss: 0.126934021711.\n",
      "Iteration: 5520/8000, Loss: 0.126934021711.\n",
      "Iteration: 5521/8000, Loss: 0.126934021711.\n",
      "Iteration: 5522/8000, Loss: 0.126934021711.\n",
      "Iteration: 5523/8000, Loss: 0.12693400681.\n",
      "Iteration: 5524/8000, Loss: 0.12693400681.\n",
      "Iteration: 5525/8000, Loss: 0.12693400681.\n",
      "Iteration: 5526/8000, Loss: 0.126933991909.\n",
      "Iteration: 5527/8000, Loss: 0.126933991909.\n",
      "Iteration: 5528/8000, Loss: 0.126933991909.\n",
      "Iteration: 5529/8000, Loss: 0.126933991909.\n",
      "Iteration: 5530/8000, Loss: 0.126933991909.\n",
      "Iteration: 5531/8000, Loss: 0.126933977008.\n",
      "Iteration: 5532/8000, Loss: 0.126933977008.\n",
      "Iteration: 5533/8000, Loss: 0.126933962107.\n",
      "Iteration: 5534/8000, Loss: 0.126933962107.\n",
      "Iteration: 5535/8000, Loss: 0.126933962107.\n",
      "Iteration: 5536/8000, Loss: 0.126933962107.\n",
      "Iteration: 5537/8000, Loss: 0.126933962107.\n",
      "Iteration: 5538/8000, Loss: 0.126933962107.\n",
      "Iteration: 5539/8000, Loss: 0.126933947206.\n",
      "Iteration: 5540/8000, Loss: 0.126933947206.\n",
      "Iteration: 5541/8000, Loss: 0.126933932304.\n",
      "Iteration: 5542/8000, Loss: 0.126933932304.\n",
      "Iteration: 5543/8000, Loss: 0.126933932304.\n",
      "Iteration: 5544/8000, Loss: 0.126933932304.\n",
      "Iteration: 5545/8000, Loss: 0.126933932304.\n",
      "Iteration: 5546/8000, Loss: 0.126933917403.\n",
      "Iteration: 5547/8000, Loss: 0.126933917403.\n",
      "Iteration: 5548/8000, Loss: 0.126933917403.\n",
      "Iteration: 5549/8000, Loss: 0.126933902502.\n",
      "Iteration: 5550/8000, Loss: 0.126933902502.\n",
      "Iteration: 5551/8000, Loss: 0.126933887601.\n",
      "Iteration: 5552/8000, Loss: 0.126933902502.\n",
      "Iteration: 5553/8000, Loss: 0.126933887601.\n",
      "Iteration: 5554/8000, Loss: 0.126933887601.\n",
      "Iteration: 5555/8000, Loss: 0.1269338727.\n",
      "Iteration: 5556/8000, Loss: 0.1269338727.\n",
      "Iteration: 5557/8000, Loss: 0.1269338727.\n",
      "Iteration: 5558/8000, Loss: 0.1269338727.\n",
      "Iteration: 5559/8000, Loss: 0.1269338727.\n",
      "Iteration: 5560/8000, Loss: 0.126933857799.\n",
      "Iteration: 5561/8000, Loss: 0.126933857799.\n",
      "Iteration: 5562/8000, Loss: 0.126933857799.\n",
      "Iteration: 5563/8000, Loss: 0.126933857799.\n",
      "Iteration: 5564/8000, Loss: 0.126933842897.\n",
      "Iteration: 5565/8000, Loss: 0.126933842897.\n",
      "Iteration: 5566/8000, Loss: 0.126933842897.\n",
      "Iteration: 5567/8000, Loss: 0.126933842897.\n",
      "Iteration: 5568/8000, Loss: 0.126933842897.\n",
      "Iteration: 5569/8000, Loss: 0.126933842897.\n",
      "Iteration: 5570/8000, Loss: 0.126933827996.\n",
      "Iteration: 5571/8000, Loss: 0.126933827996.\n",
      "Iteration: 5572/8000, Loss: 0.126933827996.\n",
      "Iteration: 5573/8000, Loss: 0.126933813095.\n",
      "Iteration: 5574/8000, Loss: 0.126933827996.\n",
      "Iteration: 5575/8000, Loss: 0.126933813095.\n",
      "Iteration: 5576/8000, Loss: 0.126933798194.\n",
      "Iteration: 5577/8000, Loss: 0.126933798194.\n",
      "Iteration: 5578/8000, Loss: 0.126933798194.\n",
      "Iteration: 5579/8000, Loss: 0.126933783293.\n",
      "Iteration: 5580/8000, Loss: 0.126933783293.\n",
      "Iteration: 5581/8000, Loss: 0.126933783293.\n",
      "Iteration: 5582/8000, Loss: 0.126933783293.\n",
      "Iteration: 5583/8000, Loss: 0.126933783293.\n",
      "Iteration: 5584/8000, Loss: 0.126933783293.\n",
      "Iteration: 5585/8000, Loss: 0.126933768392.\n",
      "Iteration: 5586/8000, Loss: 0.126933768392.\n",
      "Iteration: 5587/8000, Loss: 0.12693375349.\n",
      "Iteration: 5588/8000, Loss: 0.12693375349.\n",
      "Iteration: 5589/8000, Loss: 0.12693375349.\n",
      "Iteration: 5590/8000, Loss: 0.12693375349.\n",
      "Iteration: 5591/8000, Loss: 0.12693375349.\n",
      "Iteration: 5592/8000, Loss: 0.12693375349.\n",
      "Iteration: 5593/8000, Loss: 0.12693375349.\n",
      "Iteration: 5594/8000, Loss: 0.12693375349.\n",
      "Iteration: 5595/8000, Loss: 0.126933738589.\n",
      "Iteration: 5596/8000, Loss: 0.126933738589.\n",
      "Iteration: 5597/8000, Loss: 0.126933723688.\n",
      "Iteration: 5598/8000, Loss: 0.126933723688.\n",
      "Iteration: 5599/8000, Loss: 0.126933723688.\n",
      "Iteration: 5600/8000, Loss: 0.126933723688.\n",
      "Iteration: 5601/8000, Loss: 0.126933723688.\n",
      "Iteration: 5602/8000, Loss: 0.126933723688.\n",
      "Iteration: 5603/8000, Loss: 0.126933693886.\n",
      "Iteration: 5604/8000, Loss: 0.126933693886.\n",
      "Iteration: 5605/8000, Loss: 0.126933693886.\n",
      "Iteration: 5606/8000, Loss: 0.126933693886.\n",
      "Iteration: 5607/8000, Loss: 0.126933693886.\n",
      "Iteration: 5608/8000, Loss: 0.126933693886.\n",
      "Iteration: 5609/8000, Loss: 0.126933678985.\n",
      "Iteration: 5610/8000, Loss: 0.126933693886.\n",
      "Iteration: 5611/8000, Loss: 0.126933664083.\n",
      "Iteration: 5612/8000, Loss: 0.126933664083.\n",
      "Iteration: 5613/8000, Loss: 0.126933664083.\n",
      "Iteration: 5614/8000, Loss: 0.126933664083.\n",
      "Iteration: 5615/8000, Loss: 0.126933664083.\n",
      "Iteration: 5616/8000, Loss: 0.126933664083.\n",
      "Iteration: 5617/8000, Loss: 0.126933664083.\n",
      "Iteration: 5618/8000, Loss: 0.126933664083.\n",
      "Iteration: 5619/8000, Loss: 0.126933649182.\n",
      "Iteration: 5620/8000, Loss: 0.126933634281.\n",
      "Iteration: 5621/8000, Loss: 0.126933649182.\n",
      "Iteration: 5622/8000, Loss: 0.126933634281.\n",
      "Iteration: 5623/8000, Loss: 0.126933634281.\n",
      "Iteration: 5624/8000, Loss: 0.126933634281.\n",
      "Iteration: 5625/8000, Loss: 0.126933634281.\n",
      "Iteration: 5626/8000, Loss: 0.126933634281.\n",
      "Iteration: 5627/8000, Loss: 0.12693361938.\n",
      "Iteration: 5628/8000, Loss: 0.12693361938.\n",
      "Iteration: 5629/8000, Loss: 0.126933604479.\n",
      "Iteration: 5630/8000, Loss: 0.126933604479.\n",
      "Iteration: 5631/8000, Loss: 0.126933604479.\n",
      "Iteration: 5632/8000, Loss: 0.126933604479.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5633/8000, Loss: 0.126933604479.\n",
      "Iteration: 5634/8000, Loss: 0.126933589578.\n",
      "Iteration: 5635/8000, Loss: 0.126933589578.\n",
      "Iteration: 5636/8000, Loss: 0.126933589578.\n",
      "Iteration: 5637/8000, Loss: 0.126933589578.\n",
      "Iteration: 5638/8000, Loss: 0.126933589578.\n",
      "Iteration: 5639/8000, Loss: 0.126933589578.\n",
      "Iteration: 5640/8000, Loss: 0.126933589578.\n",
      "Iteration: 5641/8000, Loss: 0.126933574677.\n",
      "Iteration: 5642/8000, Loss: 0.126933559775.\n",
      "Iteration: 5643/8000, Loss: 0.126933574677.\n",
      "Iteration: 5644/8000, Loss: 0.126933574677.\n",
      "Iteration: 5645/8000, Loss: 0.126933544874.\n",
      "Iteration: 5646/8000, Loss: 0.126933544874.\n",
      "Iteration: 5647/8000, Loss: 0.126933544874.\n",
      "Iteration: 5648/8000, Loss: 0.126933544874.\n",
      "Iteration: 5649/8000, Loss: 0.126933544874.\n",
      "Iteration: 5650/8000, Loss: 0.126933544874.\n",
      "Iteration: 5651/8000, Loss: 0.126933529973.\n",
      "Iteration: 5652/8000, Loss: 0.126933529973.\n",
      "Iteration: 5653/8000, Loss: 0.126933515072.\n",
      "Iteration: 5654/8000, Loss: 0.126933515072.\n",
      "Iteration: 5655/8000, Loss: 0.126933515072.\n",
      "Iteration: 5656/8000, Loss: 0.126933515072.\n",
      "Iteration: 5657/8000, Loss: 0.126933515072.\n",
      "Iteration: 5658/8000, Loss: 0.126933515072.\n",
      "Iteration: 5659/8000, Loss: 0.126933515072.\n",
      "Iteration: 5660/8000, Loss: 0.126933500171.\n",
      "Iteration: 5661/8000, Loss: 0.126933500171.\n",
      "Iteration: 5662/8000, Loss: 0.126933500171.\n",
      "Iteration: 5663/8000, Loss: 0.12693348527.\n",
      "Iteration: 5664/8000, Loss: 0.12693348527.\n",
      "Iteration: 5665/8000, Loss: 0.12693348527.\n",
      "Iteration: 5666/8000, Loss: 0.12693348527.\n",
      "Iteration: 5667/8000, Loss: 0.12693348527.\n",
      "Iteration: 5668/8000, Loss: 0.126933470368.\n",
      "Iteration: 5669/8000, Loss: 0.126933470368.\n",
      "Iteration: 5670/8000, Loss: 0.126933455467.\n",
      "Iteration: 5671/8000, Loss: 0.126933455467.\n",
      "Iteration: 5672/8000, Loss: 0.126933455467.\n",
      "Iteration: 5673/8000, Loss: 0.126933455467.\n",
      "Iteration: 5674/8000, Loss: 0.126933455467.\n",
      "Iteration: 5675/8000, Loss: 0.126933455467.\n",
      "Iteration: 5676/8000, Loss: 0.126933455467.\n",
      "Iteration: 5677/8000, Loss: 0.126933440566.\n",
      "Iteration: 5678/8000, Loss: 0.126933440566.\n",
      "Iteration: 5679/8000, Loss: 0.126933425665.\n",
      "Iteration: 5680/8000, Loss: 0.126933425665.\n",
      "Iteration: 5681/8000, Loss: 0.126933425665.\n",
      "Iteration: 5682/8000, Loss: 0.126933425665.\n",
      "Iteration: 5683/8000, Loss: 0.126933425665.\n",
      "Iteration: 5684/8000, Loss: 0.126933425665.\n",
      "Iteration: 5685/8000, Loss: 0.126933410764.\n",
      "Iteration: 5686/8000, Loss: 0.126933410764.\n",
      "Iteration: 5687/8000, Loss: 0.126933410764.\n",
      "Iteration: 5688/8000, Loss: 0.126933395863.\n",
      "Iteration: 5689/8000, Loss: 0.126933395863.\n",
      "Iteration: 5690/8000, Loss: 0.126933395863.\n",
      "Iteration: 5691/8000, Loss: 0.126933395863.\n",
      "Iteration: 5692/8000, Loss: 0.126933395863.\n",
      "Iteration: 5693/8000, Loss: 0.126933380961.\n",
      "Iteration: 5694/8000, Loss: 0.126933380961.\n",
      "Iteration: 5695/8000, Loss: 0.126933380961.\n",
      "Iteration: 5696/8000, Loss: 0.12693336606.\n",
      "Iteration: 5697/8000, Loss: 0.12693336606.\n",
      "Iteration: 5698/8000, Loss: 0.12693336606.\n",
      "Iteration: 5699/8000, Loss: 0.12693336606.\n",
      "Iteration: 5700/8000, Loss: 0.126933351159.\n",
      "Iteration: 5701/8000, Loss: 0.126933351159.\n",
      "Iteration: 5702/8000, Loss: 0.126933351159.\n",
      "Iteration: 5703/8000, Loss: 0.126933351159.\n",
      "Iteration: 5704/8000, Loss: 0.126933351159.\n",
      "Iteration: 5705/8000, Loss: 0.126933351159.\n",
      "Iteration: 5706/8000, Loss: 0.126933351159.\n",
      "Iteration: 5707/8000, Loss: 0.126933336258.\n",
      "Iteration: 5708/8000, Loss: 0.126933336258.\n",
      "Iteration: 5709/8000, Loss: 0.126933336258.\n",
      "Iteration: 5710/8000, Loss: 0.126933321357.\n",
      "Iteration: 5711/8000, Loss: 0.126933336258.\n",
      "Iteration: 5712/8000, Loss: 0.126933321357.\n",
      "Iteration: 5713/8000, Loss: 0.126933306456.\n",
      "Iteration: 5714/8000, Loss: 0.126933306456.\n",
      "Iteration: 5715/8000, Loss: 0.126933306456.\n",
      "Iteration: 5716/8000, Loss: 0.126933306456.\n",
      "Iteration: 5717/8000, Loss: 0.126933306456.\n",
      "Iteration: 5718/8000, Loss: 0.126933306456.\n",
      "Iteration: 5719/8000, Loss: 0.126933291554.\n",
      "Iteration: 5720/8000, Loss: 0.126933291554.\n",
      "Iteration: 5721/8000, Loss: 0.126933291554.\n",
      "Iteration: 5722/8000, Loss: 0.126933291554.\n",
      "Iteration: 5723/8000, Loss: 0.126933276653.\n",
      "Iteration: 5724/8000, Loss: 0.126933276653.\n",
      "Iteration: 5725/8000, Loss: 0.126933276653.\n",
      "Iteration: 5726/8000, Loss: 0.126933276653.\n",
      "Iteration: 5727/8000, Loss: 0.126933276653.\n",
      "Iteration: 5728/8000, Loss: 0.126933276653.\n",
      "Iteration: 5729/8000, Loss: 0.126933261752.\n",
      "Iteration: 5730/8000, Loss: 0.126933261752.\n",
      "Iteration: 5731/8000, Loss: 0.126933261752.\n",
      "Iteration: 5732/8000, Loss: 0.126933261752.\n",
      "Iteration: 5733/8000, Loss: 0.126933246851.\n",
      "Iteration: 5734/8000, Loss: 0.126933246851.\n",
      "Iteration: 5735/8000, Loss: 0.126933246851.\n",
      "Iteration: 5736/8000, Loss: 0.126933246851.\n",
      "Iteration: 5737/8000, Loss: 0.12693323195.\n",
      "Iteration: 5738/8000, Loss: 0.12693323195.\n",
      "Iteration: 5739/8000, Loss: 0.12693323195.\n",
      "Iteration: 5740/8000, Loss: 0.12693323195.\n",
      "Iteration: 5741/8000, Loss: 0.126933217049.\n",
      "Iteration: 5742/8000, Loss: 0.126933217049.\n",
      "Iteration: 5743/8000, Loss: 0.126933217049.\n",
      "Iteration: 5744/8000, Loss: 0.126933217049.\n",
      "Iteration: 5745/8000, Loss: 0.126933217049.\n",
      "Iteration: 5746/8000, Loss: 0.126933202147.\n",
      "Iteration: 5747/8000, Loss: 0.126933187246.\n",
      "Iteration: 5748/8000, Loss: 0.126933187246.\n",
      "Iteration: 5749/8000, Loss: 0.126933187246.\n",
      "Iteration: 5750/8000, Loss: 0.126933187246.\n",
      "Iteration: 5751/8000, Loss: 0.126933172345.\n",
      "Iteration: 5752/8000, Loss: 0.126933187246.\n",
      "Iteration: 5753/8000, Loss: 0.126933172345.\n",
      "Iteration: 5754/8000, Loss: 0.126933187246.\n",
      "Iteration: 5755/8000, Loss: 0.126933172345.\n",
      "Iteration: 5756/8000, Loss: 0.126933172345.\n",
      "Iteration: 5757/8000, Loss: 0.126933172345.\n",
      "Iteration: 5758/8000, Loss: 0.126933157444.\n",
      "Iteration: 5759/8000, Loss: 0.126933157444.\n",
      "Iteration: 5760/8000, Loss: 0.126933157444.\n",
      "Iteration: 5761/8000, Loss: 0.126933157444.\n",
      "Iteration: 5762/8000, Loss: 0.126933157444.\n",
      "Iteration: 5763/8000, Loss: 0.126933157444.\n",
      "Iteration: 5764/8000, Loss: 0.126933142543.\n",
      "Iteration: 5765/8000, Loss: 0.126933142543.\n",
      "Iteration: 5766/8000, Loss: 0.126933142543.\n",
      "Iteration: 5767/8000, Loss: 0.126933142543.\n",
      "Iteration: 5768/8000, Loss: 0.126933142543.\n",
      "Iteration: 5769/8000, Loss: 0.126933127642.\n",
      "Iteration: 5770/8000, Loss: 0.126933127642.\n",
      "Iteration: 5771/8000, Loss: 0.126933127642.\n",
      "Iteration: 5772/8000, Loss: 0.126933127642.\n",
      "Iteration: 5773/8000, Loss: 0.126933112741.\n",
      "Iteration: 5774/8000, Loss: 0.126933112741.\n",
      "Iteration: 5775/8000, Loss: 0.126933112741.\n",
      "Iteration: 5776/8000, Loss: 0.126933112741.\n",
      "Iteration: 5777/8000, Loss: 0.126933097839.\n",
      "Iteration: 5778/8000, Loss: 0.126933097839.\n",
      "Iteration: 5779/8000, Loss: 0.126933097839.\n",
      "Iteration: 5780/8000, Loss: 0.126933097839.\n",
      "Iteration: 5781/8000, Loss: 0.126933082938.\n",
      "Iteration: 5782/8000, Loss: 0.126933097839.\n",
      "Iteration: 5783/8000, Loss: 0.126933068037.\n",
      "Iteration: 5784/8000, Loss: 0.126933082938.\n",
      "Iteration: 5785/8000, Loss: 0.126933068037.\n",
      "Iteration: 5786/8000, Loss: 0.126933082938.\n",
      "Iteration: 5787/8000, Loss: 0.126933068037.\n",
      "Iteration: 5788/8000, Loss: 0.126933068037.\n",
      "Iteration: 5789/8000, Loss: 0.126933068037.\n",
      "Iteration: 5790/8000, Loss: 0.126933053136.\n",
      "Iteration: 5791/8000, Loss: 0.126933053136.\n",
      "Iteration: 5792/8000, Loss: 0.126933053136.\n",
      "Iteration: 5793/8000, Loss: 0.126933053136.\n",
      "Iteration: 5794/8000, Loss: 0.126933053136.\n",
      "Iteration: 5795/8000, Loss: 0.126933053136.\n",
      "Iteration: 5796/8000, Loss: 0.126933038235.\n",
      "Iteration: 5797/8000, Loss: 0.126933038235.\n",
      "Iteration: 5798/8000, Loss: 0.126933038235.\n",
      "Iteration: 5799/8000, Loss: 0.126933038235.\n",
      "Iteration: 5800/8000, Loss: 0.126933023334.\n",
      "Iteration: 5801/8000, Loss: 0.126933023334.\n",
      "Iteration: 5802/8000, Loss: 0.126933023334.\n",
      "Iteration: 5803/8000, Loss: 0.126933008432.\n",
      "Iteration: 5804/8000, Loss: 0.126933023334.\n",
      "Iteration: 5805/8000, Loss: 0.126933008432.\n",
      "Iteration: 5806/8000, Loss: 0.126933023334.\n",
      "Iteration: 5807/8000, Loss: 0.126933008432.\n",
      "Iteration: 5808/8000, Loss: 0.126933008432.\n",
      "Iteration: 5809/8000, Loss: 0.126933008432.\n",
      "Iteration: 5810/8000, Loss: 0.126933008432.\n",
      "Iteration: 5811/8000, Loss: 0.126932993531.\n",
      "Iteration: 5812/8000, Loss: 0.126933008432.\n",
      "Iteration: 5813/8000, Loss: 0.12693297863.\n",
      "Iteration: 5814/8000, Loss: 0.12693297863.\n",
      "Iteration: 5815/8000, Loss: 0.12693297863.\n",
      "Iteration: 5816/8000, Loss: 0.12693297863.\n",
      "Iteration: 5817/8000, Loss: 0.12693297863.\n",
      "Iteration: 5818/8000, Loss: 0.12693297863.\n",
      "Iteration: 5819/8000, Loss: 0.12693297863.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5820/8000, Loss: 0.126932963729.\n",
      "Iteration: 5821/8000, Loss: 0.126932963729.\n",
      "Iteration: 5822/8000, Loss: 0.126932963729.\n",
      "Iteration: 5823/8000, Loss: 0.126932948828.\n",
      "Iteration: 5824/8000, Loss: 0.126932948828.\n",
      "Iteration: 5825/8000, Loss: 0.126932948828.\n",
      "Iteration: 5826/8000, Loss: 0.126932948828.\n",
      "Iteration: 5827/8000, Loss: 0.126932948828.\n",
      "Iteration: 5828/8000, Loss: 0.126932933927.\n",
      "Iteration: 5829/8000, Loss: 0.126932933927.\n",
      "Iteration: 5830/8000, Loss: 0.126932919025.\n",
      "Iteration: 5831/8000, Loss: 0.126932919025.\n",
      "Iteration: 5832/8000, Loss: 0.126932919025.\n",
      "Iteration: 5833/8000, Loss: 0.126932919025.\n",
      "Iteration: 5834/8000, Loss: 0.126932919025.\n",
      "Iteration: 5835/8000, Loss: 0.126932919025.\n",
      "Iteration: 5836/8000, Loss: 0.126932919025.\n",
      "Iteration: 5837/8000, Loss: 0.126932904124.\n",
      "Iteration: 5838/8000, Loss: 0.126932904124.\n",
      "Iteration: 5839/8000, Loss: 0.126932889223.\n",
      "Iteration: 5840/8000, Loss: 0.126932904124.\n",
      "Iteration: 5841/8000, Loss: 0.126932889223.\n",
      "Iteration: 5842/8000, Loss: 0.126932889223.\n",
      "Iteration: 5843/8000, Loss: 0.126932889223.\n",
      "Iteration: 5844/8000, Loss: 0.126932889223.\n",
      "Iteration: 5845/8000, Loss: 0.126932889223.\n",
      "Iteration: 5846/8000, Loss: 0.126932889223.\n",
      "Iteration: 5847/8000, Loss: 0.126932889223.\n",
      "Iteration: 5848/8000, Loss: 0.126932889223.\n",
      "Iteration: 5849/8000, Loss: 0.126932874322.\n",
      "Iteration: 5850/8000, Loss: 0.126932874322.\n",
      "Iteration: 5851/8000, Loss: 0.126932874322.\n",
      "Iteration: 5852/8000, Loss: 0.126932859421.\n",
      "Iteration: 5853/8000, Loss: 0.126932859421.\n",
      "Iteration: 5854/8000, Loss: 0.126932859421.\n",
      "Iteration: 5855/8000, Loss: 0.126932859421.\n",
      "Iteration: 5856/8000, Loss: 0.12693284452.\n",
      "Iteration: 5857/8000, Loss: 0.126932859421.\n",
      "Iteration: 5858/8000, Loss: 0.126932859421.\n",
      "Iteration: 5859/8000, Loss: 0.12693284452.\n",
      "Iteration: 5860/8000, Loss: 0.12693284452.\n",
      "Iteration: 5861/8000, Loss: 0.12693284452.\n",
      "Iteration: 5862/8000, Loss: 0.126932829618.\n",
      "Iteration: 5863/8000, Loss: 0.126932829618.\n",
      "Iteration: 5864/8000, Loss: 0.126932829618.\n",
      "Iteration: 5865/8000, Loss: 0.126932829618.\n",
      "Iteration: 5866/8000, Loss: 0.126932814717.\n",
      "Iteration: 5867/8000, Loss: 0.126932814717.\n",
      "Iteration: 5868/8000, Loss: 0.126932814717.\n",
      "Iteration: 5869/8000, Loss: 0.126932814717.\n",
      "Iteration: 5870/8000, Loss: 0.126932814717.\n",
      "Iteration: 5871/8000, Loss: 0.126932814717.\n",
      "Iteration: 5872/8000, Loss: 0.126932799816.\n",
      "Iteration: 5873/8000, Loss: 0.126932799816.\n",
      "Iteration: 5874/8000, Loss: 0.126932799816.\n",
      "Iteration: 5875/8000, Loss: 0.126932799816.\n",
      "Iteration: 5876/8000, Loss: 0.126932799816.\n",
      "Iteration: 5877/8000, Loss: 0.126932799816.\n",
      "Iteration: 5878/8000, Loss: 0.126932799816.\n",
      "Iteration: 5879/8000, Loss: 0.126932784915.\n",
      "Iteration: 5880/8000, Loss: 0.126932770014.\n",
      "Iteration: 5881/8000, Loss: 0.126932770014.\n",
      "Iteration: 5882/8000, Loss: 0.126932770014.\n",
      "Iteration: 5883/8000, Loss: 0.126932770014.\n",
      "Iteration: 5884/8000, Loss: 0.126932770014.\n",
      "Iteration: 5885/8000, Loss: 0.126932770014.\n",
      "Iteration: 5886/8000, Loss: 0.126932770014.\n",
      "Iteration: 5887/8000, Loss: 0.126932770014.\n",
      "Iteration: 5888/8000, Loss: 0.126932770014.\n",
      "Iteration: 5889/8000, Loss: 0.126932755113.\n",
      "Iteration: 5890/8000, Loss: 0.126932740211.\n",
      "Iteration: 5891/8000, Loss: 0.126932740211.\n",
      "Iteration: 5892/8000, Loss: 0.126932755113.\n",
      "Iteration: 5893/8000, Loss: 0.126932740211.\n",
      "Iteration: 5894/8000, Loss: 0.126932740211.\n",
      "Iteration: 5895/8000, Loss: 0.12693272531.\n",
      "Iteration: 5896/8000, Loss: 0.12693272531.\n",
      "Iteration: 5897/8000, Loss: 0.12693272531.\n",
      "Iteration: 5898/8000, Loss: 0.12693272531.\n",
      "Iteration: 5899/8000, Loss: 0.12693272531.\n",
      "Iteration: 5900/8000, Loss: 0.12693272531.\n",
      "Iteration: 5901/8000, Loss: 0.12693272531.\n",
      "Iteration: 5902/8000, Loss: 0.126932710409.\n",
      "Iteration: 5903/8000, Loss: 0.126932710409.\n",
      "Iteration: 5904/8000, Loss: 0.126932710409.\n",
      "Iteration: 5905/8000, Loss: 0.126932710409.\n",
      "Iteration: 5906/8000, Loss: 0.126932710409.\n",
      "Iteration: 5907/8000, Loss: 0.126932710409.\n",
      "Iteration: 5908/8000, Loss: 0.126932710409.\n",
      "Iteration: 5909/8000, Loss: 0.126932710409.\n",
      "Iteration: 5910/8000, Loss: 0.126932695508.\n",
      "Iteration: 5911/8000, Loss: 0.126932680607.\n",
      "Iteration: 5912/8000, Loss: 0.126932680607.\n",
      "Iteration: 5913/8000, Loss: 0.126932680607.\n",
      "Iteration: 5914/8000, Loss: 0.126932680607.\n",
      "Iteration: 5915/8000, Loss: 0.126932680607.\n",
      "Iteration: 5916/8000, Loss: 0.126932680607.\n",
      "Iteration: 5917/8000, Loss: 0.126932680607.\n",
      "Iteration: 5918/8000, Loss: 0.126932680607.\n",
      "Iteration: 5919/8000, Loss: 0.126932665706.\n",
      "Iteration: 5920/8000, Loss: 0.126932665706.\n",
      "Iteration: 5921/8000, Loss: 0.126932665706.\n",
      "Iteration: 5922/8000, Loss: 0.126932665706.\n",
      "Iteration: 5923/8000, Loss: 0.126932650805.\n",
      "Iteration: 5924/8000, Loss: 0.126932650805.\n",
      "Iteration: 5925/8000, Loss: 0.126932650805.\n",
      "Iteration: 5926/8000, Loss: 0.126932650805.\n",
      "Iteration: 5927/8000, Loss: 0.126932635903.\n",
      "Iteration: 5928/8000, Loss: 0.126932635903.\n",
      "Iteration: 5929/8000, Loss: 0.126932635903.\n",
      "Iteration: 5930/8000, Loss: 0.126932635903.\n",
      "Iteration: 5931/8000, Loss: 0.126932635903.\n",
      "Iteration: 5932/8000, Loss: 0.126932635903.\n",
      "Iteration: 5933/8000, Loss: 0.126932635903.\n",
      "Iteration: 5934/8000, Loss: 0.126932635903.\n",
      "Iteration: 5935/8000, Loss: 0.126932635903.\n",
      "Iteration: 5936/8000, Loss: 0.126932621002.\n",
      "Iteration: 5937/8000, Loss: 0.126932621002.\n",
      "Iteration: 5938/8000, Loss: 0.126932621002.\n",
      "Iteration: 5939/8000, Loss: 0.126932621002.\n",
      "Iteration: 5940/8000, Loss: 0.126932606101.\n",
      "Iteration: 5941/8000, Loss: 0.1269325912.\n",
      "Iteration: 5942/8000, Loss: 0.126932606101.\n",
      "Iteration: 5943/8000, Loss: 0.1269325912.\n",
      "Iteration: 5944/8000, Loss: 0.1269325912.\n",
      "Iteration: 5945/8000, Loss: 0.1269325912.\n",
      "Iteration: 5946/8000, Loss: 0.1269325912.\n",
      "Iteration: 5947/8000, Loss: 0.126932576299.\n",
      "Iteration: 5948/8000, Loss: 0.126932576299.\n",
      "Iteration: 5949/8000, Loss: 0.126932576299.\n",
      "Iteration: 5950/8000, Loss: 0.126932576299.\n",
      "Iteration: 5951/8000, Loss: 0.126932576299.\n",
      "Iteration: 5952/8000, Loss: 0.126932576299.\n",
      "Iteration: 5953/8000, Loss: 0.126932576299.\n",
      "Iteration: 5954/8000, Loss: 0.126932576299.\n",
      "Iteration: 5955/8000, Loss: 0.126932561398.\n",
      "Iteration: 5956/8000, Loss: 0.126932561398.\n",
      "Iteration: 5957/8000, Loss: 0.126932546496.\n",
      "Iteration: 5958/8000, Loss: 0.126932546496.\n",
      "Iteration: 5959/8000, Loss: 0.126932546496.\n",
      "Iteration: 5960/8000, Loss: 0.126932561398.\n",
      "Iteration: 5961/8000, Loss: 0.126932546496.\n",
      "Iteration: 5962/8000, Loss: 0.126932531595.\n",
      "Iteration: 5963/8000, Loss: 0.126932531595.\n",
      "Iteration: 5964/8000, Loss: 0.126932546496.\n",
      "Iteration: 5965/8000, Loss: 0.126932531595.\n",
      "Iteration: 5966/8000, Loss: 0.126932531595.\n",
      "Iteration: 5967/8000, Loss: 0.126932531595.\n",
      "Iteration: 5968/8000, Loss: 0.126932531595.\n",
      "Iteration: 5969/8000, Loss: 0.126932531595.\n",
      "Iteration: 5970/8000, Loss: 0.126932531595.\n",
      "Iteration: 5971/8000, Loss: 0.126932516694.\n",
      "Iteration: 5972/8000, Loss: 0.126932516694.\n",
      "Iteration: 5973/8000, Loss: 0.126932516694.\n",
      "Iteration: 5974/8000, Loss: 0.126932516694.\n",
      "Iteration: 5975/8000, Loss: 0.126932516694.\n",
      "Iteration: 5976/8000, Loss: 0.126932516694.\n",
      "Iteration: 5977/8000, Loss: 0.126932501793.\n",
      "Iteration: 5978/8000, Loss: 0.126932501793.\n",
      "Iteration: 5979/8000, Loss: 0.126932501793.\n",
      "Iteration: 5980/8000, Loss: 0.126932501793.\n",
      "Iteration: 5981/8000, Loss: 0.126932486892.\n",
      "Iteration: 5982/8000, Loss: 0.126932501793.\n",
      "Iteration: 5983/8000, Loss: 0.126932486892.\n",
      "Iteration: 5984/8000, Loss: 0.126932486892.\n",
      "Iteration: 5985/8000, Loss: 0.126932471991.\n",
      "Iteration: 5986/8000, Loss: 0.126932471991.\n",
      "Iteration: 5987/8000, Loss: 0.126932471991.\n",
      "Iteration: 5988/8000, Loss: 0.126932471991.\n",
      "Iteration: 5989/8000, Loss: 0.126932471991.\n",
      "Iteration: 5990/8000, Loss: 0.126932471991.\n",
      "Iteration: 5991/8000, Loss: 0.126932457089.\n",
      "Iteration: 5992/8000, Loss: 0.126932457089.\n",
      "Iteration: 5993/8000, Loss: 0.126932457089.\n",
      "Iteration: 5994/8000, Loss: 0.126932457089.\n",
      "Iteration: 5995/8000, Loss: 0.126932442188.\n",
      "Iteration: 5996/8000, Loss: 0.126932457089.\n",
      "Iteration: 5997/8000, Loss: 0.126932457089.\n",
      "Iteration: 5998/8000, Loss: 0.126932457089.\n",
      "Iteration: 5999/8000, Loss: 0.126932442188.\n",
      "Iteration: 6000/8000, Loss: 0.126932442188.\n",
      "Iteration: 6001/8000, Loss: 0.126932442188.\n",
      "Iteration: 6002/8000, Loss: 0.126932442188.\n",
      "Iteration: 6003/8000, Loss: 0.126932442188.\n",
      "Iteration: 6004/8000, Loss: 0.126932442188.\n",
      "Iteration: 6005/8000, Loss: 0.126932427287.\n",
      "Iteration: 6006/8000, Loss: 0.126932427287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6007/8000, Loss: 0.126932427287.\n",
      "Iteration: 6008/8000, Loss: 0.126932427287.\n",
      "Iteration: 6009/8000, Loss: 0.126932427287.\n",
      "Iteration: 6010/8000, Loss: 0.126932412386.\n",
      "Iteration: 6011/8000, Loss: 0.126932412386.\n",
      "Iteration: 6012/8000, Loss: 0.126932397485.\n",
      "Iteration: 6013/8000, Loss: 0.126932397485.\n",
      "Iteration: 6014/8000, Loss: 0.126932397485.\n",
      "Iteration: 6015/8000, Loss: 0.126932397485.\n",
      "Iteration: 6016/8000, Loss: 0.126932397485.\n",
      "Iteration: 6017/8000, Loss: 0.126932382584.\n",
      "Iteration: 6018/8000, Loss: 0.126932382584.\n",
      "Iteration: 6019/8000, Loss: 0.126932382584.\n",
      "Iteration: 6020/8000, Loss: 0.126932382584.\n",
      "Iteration: 6021/8000, Loss: 0.126932382584.\n",
      "Iteration: 6022/8000, Loss: 0.126932382584.\n",
      "Iteration: 6023/8000, Loss: 0.126932382584.\n",
      "Iteration: 6024/8000, Loss: 0.126932382584.\n",
      "Iteration: 6025/8000, Loss: 0.126932382584.\n",
      "Iteration: 6026/8000, Loss: 0.126932367682.\n",
      "Iteration: 6027/8000, Loss: 0.126932352781.\n",
      "Iteration: 6028/8000, Loss: 0.126932352781.\n",
      "Iteration: 6029/8000, Loss: 0.126932352781.\n",
      "Iteration: 6030/8000, Loss: 0.126932352781.\n",
      "Iteration: 6031/8000, Loss: 0.126932352781.\n",
      "Iteration: 6032/8000, Loss: 0.126932352781.\n",
      "Iteration: 6033/8000, Loss: 0.126932352781.\n",
      "Iteration: 6034/8000, Loss: 0.126932352781.\n",
      "Iteration: 6035/8000, Loss: 0.126932352781.\n",
      "Iteration: 6036/8000, Loss: 0.126932352781.\n",
      "Iteration: 6037/8000, Loss: 0.12693233788.\n",
      "Iteration: 6038/8000, Loss: 0.126932352781.\n",
      "Iteration: 6039/8000, Loss: 0.12693233788.\n",
      "Iteration: 6040/8000, Loss: 0.12693233788.\n",
      "Iteration: 6041/8000, Loss: 0.12693233788.\n",
      "Iteration: 6042/8000, Loss: 0.12693233788.\n",
      "Iteration: 6043/8000, Loss: 0.12693233788.\n",
      "Iteration: 6044/8000, Loss: 0.126932322979.\n",
      "Iteration: 6045/8000, Loss: 0.126932322979.\n",
      "Iteration: 6046/8000, Loss: 0.126932322979.\n",
      "Iteration: 6047/8000, Loss: 0.126932322979.\n",
      "Iteration: 6048/8000, Loss: 0.126932322979.\n",
      "Iteration: 6049/8000, Loss: 0.126932293177.\n",
      "Iteration: 6050/8000, Loss: 0.126932293177.\n",
      "Iteration: 6051/8000, Loss: 0.126932293177.\n",
      "Iteration: 6052/8000, Loss: 0.126932293177.\n",
      "Iteration: 6053/8000, Loss: 0.126932293177.\n",
      "Iteration: 6054/8000, Loss: 0.126932293177.\n",
      "Iteration: 6055/8000, Loss: 0.126932278275.\n",
      "Iteration: 6056/8000, Loss: 0.126932278275.\n",
      "Iteration: 6057/8000, Loss: 0.126932278275.\n",
      "Iteration: 6058/8000, Loss: 0.126932278275.\n",
      "Iteration: 6059/8000, Loss: 0.126932278275.\n",
      "Iteration: 6060/8000, Loss: 0.126932278275.\n",
      "Iteration: 6061/8000, Loss: 0.126932263374.\n",
      "Iteration: 6062/8000, Loss: 0.126932278275.\n",
      "Iteration: 6063/8000, Loss: 0.126932263374.\n",
      "Iteration: 6064/8000, Loss: 0.126932263374.\n",
      "Iteration: 6065/8000, Loss: 0.126932263374.\n",
      "Iteration: 6066/8000, Loss: 0.126932263374.\n",
      "Iteration: 6067/8000, Loss: 0.126932263374.\n",
      "Iteration: 6068/8000, Loss: 0.126932263374.\n",
      "Iteration: 6069/8000, Loss: 0.126932263374.\n",
      "Iteration: 6070/8000, Loss: 0.126932248473.\n",
      "Iteration: 6071/8000, Loss: 0.126932263374.\n",
      "Iteration: 6072/8000, Loss: 0.126932248473.\n",
      "Iteration: 6073/8000, Loss: 0.126932248473.\n",
      "Iteration: 6074/8000, Loss: 0.126932248473.\n",
      "Iteration: 6075/8000, Loss: 0.126932233572.\n",
      "Iteration: 6076/8000, Loss: 0.126932233572.\n",
      "Iteration: 6077/8000, Loss: 0.126932233572.\n",
      "Iteration: 6078/8000, Loss: 0.126932233572.\n",
      "Iteration: 6079/8000, Loss: 0.126932233572.\n",
      "Iteration: 6080/8000, Loss: 0.126932233572.\n",
      "Iteration: 6081/8000, Loss: 0.126932233572.\n",
      "Iteration: 6082/8000, Loss: 0.126932233572.\n",
      "Iteration: 6083/8000, Loss: 0.126932218671.\n",
      "Iteration: 6084/8000, Loss: 0.126932218671.\n",
      "Iteration: 6085/8000, Loss: 0.126932218671.\n",
      "Iteration: 6086/8000, Loss: 0.126932218671.\n",
      "Iteration: 6087/8000, Loss: 0.126932218671.\n",
      "Iteration: 6088/8000, Loss: 0.126932218671.\n",
      "Iteration: 6089/8000, Loss: 0.12693220377.\n",
      "Iteration: 6090/8000, Loss: 0.12693220377.\n",
      "Iteration: 6091/8000, Loss: 0.12693220377.\n",
      "Iteration: 6092/8000, Loss: 0.12693220377.\n",
      "Iteration: 6093/8000, Loss: 0.12693220377.\n",
      "Iteration: 6094/8000, Loss: 0.126932188869.\n",
      "Iteration: 6095/8000, Loss: 0.126932188869.\n",
      "Iteration: 6096/8000, Loss: 0.126932188869.\n",
      "Iteration: 6097/8000, Loss: 0.126932188869.\n",
      "Iteration: 6098/8000, Loss: 0.126932188869.\n",
      "Iteration: 6099/8000, Loss: 0.126932173967.\n",
      "Iteration: 6100/8000, Loss: 0.126932173967.\n",
      "Iteration: 6101/8000, Loss: 0.126932173967.\n",
      "Iteration: 6102/8000, Loss: 0.126932173967.\n",
      "Iteration: 6103/8000, Loss: 0.126932173967.\n",
      "Iteration: 6104/8000, Loss: 0.126932159066.\n",
      "Iteration: 6105/8000, Loss: 0.126932173967.\n",
      "Iteration: 6106/8000, Loss: 0.126932159066.\n",
      "Iteration: 6107/8000, Loss: 0.126932159066.\n",
      "Iteration: 6108/8000, Loss: 0.126932159066.\n",
      "Iteration: 6109/8000, Loss: 0.126932159066.\n",
      "Iteration: 6110/8000, Loss: 0.126932144165.\n",
      "Iteration: 6111/8000, Loss: 0.126932144165.\n",
      "Iteration: 6112/8000, Loss: 0.126932144165.\n",
      "Iteration: 6113/8000, Loss: 0.126932144165.\n",
      "Iteration: 6114/8000, Loss: 0.126932144165.\n",
      "Iteration: 6115/8000, Loss: 0.126932144165.\n",
      "Iteration: 6116/8000, Loss: 0.126932129264.\n",
      "Iteration: 6117/8000, Loss: 0.126932144165.\n",
      "Iteration: 6118/8000, Loss: 0.126932129264.\n",
      "Iteration: 6119/8000, Loss: 0.126932129264.\n",
      "Iteration: 6120/8000, Loss: 0.126932129264.\n",
      "Iteration: 6121/8000, Loss: 0.126932114363.\n",
      "Iteration: 6122/8000, Loss: 0.126932129264.\n",
      "Iteration: 6123/8000, Loss: 0.126932114363.\n",
      "Iteration: 6124/8000, Loss: 0.126932114363.\n",
      "Iteration: 6125/8000, Loss: 0.126932114363.\n",
      "Iteration: 6126/8000, Loss: 0.126932114363.\n",
      "Iteration: 6127/8000, Loss: 0.126932114363.\n",
      "Iteration: 6128/8000, Loss: 0.126932114363.\n",
      "Iteration: 6129/8000, Loss: 0.126932099462.\n",
      "Iteration: 6130/8000, Loss: 0.126932099462.\n",
      "Iteration: 6131/8000, Loss: 0.12693208456.\n",
      "Iteration: 6132/8000, Loss: 0.126932099462.\n",
      "Iteration: 6133/8000, Loss: 0.126932099462.\n",
      "Iteration: 6134/8000, Loss: 0.12693208456.\n",
      "Iteration: 6135/8000, Loss: 0.12693208456.\n",
      "Iteration: 6136/8000, Loss: 0.12693208456.\n",
      "Iteration: 6137/8000, Loss: 0.12693208456.\n",
      "Iteration: 6138/8000, Loss: 0.12693208456.\n",
      "Iteration: 6139/8000, Loss: 0.12693208456.\n",
      "Iteration: 6140/8000, Loss: 0.12693208456.\n",
      "Iteration: 6141/8000, Loss: 0.12693208456.\n",
      "Iteration: 6142/8000, Loss: 0.12693208456.\n",
      "Iteration: 6143/8000, Loss: 0.12693208456.\n",
      "Iteration: 6144/8000, Loss: 0.12693208456.\n",
      "Iteration: 6145/8000, Loss: 0.126932069659.\n",
      "Iteration: 6146/8000, Loss: 0.126932069659.\n",
      "Iteration: 6147/8000, Loss: 0.126932069659.\n",
      "Iteration: 6148/8000, Loss: 0.126932054758.\n",
      "Iteration: 6149/8000, Loss: 0.126932054758.\n",
      "Iteration: 6150/8000, Loss: 0.126932054758.\n",
      "Iteration: 6151/8000, Loss: 0.126932054758.\n",
      "Iteration: 6152/8000, Loss: 0.126932054758.\n",
      "Iteration: 6153/8000, Loss: 0.126932054758.\n",
      "Iteration: 6154/8000, Loss: 0.126932039857.\n",
      "Iteration: 6155/8000, Loss: 0.126932039857.\n",
      "Iteration: 6156/8000, Loss: 0.126932024956.\n",
      "Iteration: 6157/8000, Loss: 0.126932024956.\n",
      "Iteration: 6158/8000, Loss: 0.126932024956.\n",
      "Iteration: 6159/8000, Loss: 0.126932024956.\n",
      "Iteration: 6160/8000, Loss: 0.126932024956.\n",
      "Iteration: 6161/8000, Loss: 0.126932024956.\n",
      "Iteration: 6162/8000, Loss: 0.126932024956.\n",
      "Iteration: 6163/8000, Loss: 0.126932024956.\n",
      "Iteration: 6164/8000, Loss: 0.126932024956.\n",
      "Iteration: 6165/8000, Loss: 0.126932024956.\n",
      "Iteration: 6166/8000, Loss: 0.126932010055.\n",
      "Iteration: 6167/8000, Loss: 0.126932010055.\n",
      "Iteration: 6168/8000, Loss: 0.126932010055.\n",
      "Iteration: 6169/8000, Loss: 0.126932010055.\n",
      "Iteration: 6170/8000, Loss: 0.126931995153.\n",
      "Iteration: 6171/8000, Loss: 0.126932010055.\n",
      "Iteration: 6172/8000, Loss: 0.126931995153.\n",
      "Iteration: 6173/8000, Loss: 0.126931995153.\n",
      "Iteration: 6174/8000, Loss: 0.126931995153.\n",
      "Iteration: 6175/8000, Loss: 0.126931980252.\n",
      "Iteration: 6176/8000, Loss: 0.126931980252.\n",
      "Iteration: 6177/8000, Loss: 0.126931980252.\n",
      "Iteration: 6178/8000, Loss: 0.126931980252.\n",
      "Iteration: 6179/8000, Loss: 0.126931980252.\n",
      "Iteration: 6180/8000, Loss: 0.126931980252.\n",
      "Iteration: 6181/8000, Loss: 0.126931980252.\n",
      "Iteration: 6182/8000, Loss: 0.126931980252.\n",
      "Iteration: 6183/8000, Loss: 0.126931980252.\n",
      "Iteration: 6184/8000, Loss: 0.126931965351.\n",
      "Iteration: 6185/8000, Loss: 0.126931965351.\n",
      "Iteration: 6186/8000, Loss: 0.126931965351.\n",
      "Iteration: 6187/8000, Loss: 0.126931965351.\n",
      "Iteration: 6188/8000, Loss: 0.126931965351.\n",
      "Iteration: 6189/8000, Loss: 0.126931965351.\n",
      "Iteration: 6190/8000, Loss: 0.126931965351.\n",
      "Iteration: 6191/8000, Loss: 0.12693195045.\n",
      "Iteration: 6192/8000, Loss: 0.126931965351.\n",
      "Iteration: 6193/8000, Loss: 0.12693195045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6194/8000, Loss: 0.12693195045.\n",
      "Iteration: 6195/8000, Loss: 0.126931935549.\n",
      "Iteration: 6196/8000, Loss: 0.12693195045.\n",
      "Iteration: 6197/8000, Loss: 0.126931935549.\n",
      "Iteration: 6198/8000, Loss: 0.126931935549.\n",
      "Iteration: 6199/8000, Loss: 0.126931935549.\n",
      "Iteration: 6200/8000, Loss: 0.126931935549.\n",
      "Iteration: 6201/8000, Loss: 0.126931935549.\n",
      "Iteration: 6202/8000, Loss: 0.126931920648.\n",
      "Iteration: 6203/8000, Loss: 0.126931920648.\n",
      "Iteration: 6204/8000, Loss: 0.126931920648.\n",
      "Iteration: 6205/8000, Loss: 0.126931920648.\n",
      "Iteration: 6206/8000, Loss: 0.126931920648.\n",
      "Iteration: 6207/8000, Loss: 0.126931920648.\n",
      "Iteration: 6208/8000, Loss: 0.126931905746.\n",
      "Iteration: 6209/8000, Loss: 0.126931920648.\n",
      "Iteration: 6210/8000, Loss: 0.126931905746.\n",
      "Iteration: 6211/8000, Loss: 0.126931905746.\n",
      "Iteration: 6212/8000, Loss: 0.126931905746.\n",
      "Iteration: 6213/8000, Loss: 0.126931905746.\n",
      "Iteration: 6214/8000, Loss: 0.126931905746.\n",
      "Iteration: 6215/8000, Loss: 0.126931890845.\n",
      "Iteration: 6216/8000, Loss: 0.126931890845.\n",
      "Iteration: 6217/8000, Loss: 0.126931890845.\n",
      "Iteration: 6218/8000, Loss: 0.126931890845.\n",
      "Iteration: 6219/8000, Loss: 0.126931890845.\n",
      "Iteration: 6220/8000, Loss: 0.126931890845.\n",
      "Iteration: 6221/8000, Loss: 0.126931875944.\n",
      "Iteration: 6222/8000, Loss: 0.126931875944.\n",
      "Iteration: 6223/8000, Loss: 0.126931875944.\n",
      "Iteration: 6224/8000, Loss: 0.126931875944.\n",
      "Iteration: 6225/8000, Loss: 0.126931875944.\n",
      "Iteration: 6226/8000, Loss: 0.126931875944.\n",
      "Iteration: 6227/8000, Loss: 0.126931875944.\n",
      "Iteration: 6228/8000, Loss: 0.126931875944.\n",
      "Iteration: 6229/8000, Loss: 0.126931875944.\n",
      "Iteration: 6230/8000, Loss: 0.126931875944.\n",
      "Iteration: 6231/8000, Loss: 0.126931861043.\n",
      "Iteration: 6232/8000, Loss: 0.126931861043.\n",
      "Iteration: 6233/8000, Loss: 0.126931861043.\n",
      "Iteration: 6234/8000, Loss: 0.126931846142.\n",
      "Iteration: 6235/8000, Loss: 0.126931846142.\n",
      "Iteration: 6236/8000, Loss: 0.126931846142.\n",
      "Iteration: 6237/8000, Loss: 0.126931861043.\n",
      "Iteration: 6238/8000, Loss: 0.126931846142.\n",
      "Iteration: 6239/8000, Loss: 0.126931846142.\n",
      "Iteration: 6240/8000, Loss: 0.126931846142.\n",
      "Iteration: 6241/8000, Loss: 0.126931846142.\n",
      "Iteration: 6242/8000, Loss: 0.126931846142.\n",
      "Iteration: 6243/8000, Loss: 0.126931831241.\n",
      "Iteration: 6244/8000, Loss: 0.126931831241.\n",
      "Iteration: 6245/8000, Loss: 0.126931816339.\n",
      "Iteration: 6246/8000, Loss: 0.126931816339.\n",
      "Iteration: 6247/8000, Loss: 0.126931816339.\n",
      "Iteration: 6248/8000, Loss: 0.126931816339.\n",
      "Iteration: 6249/8000, Loss: 0.126931816339.\n",
      "Iteration: 6250/8000, Loss: 0.126931816339.\n",
      "Iteration: 6251/8000, Loss: 0.126931816339.\n",
      "Iteration: 6252/8000, Loss: 0.126931816339.\n",
      "Iteration: 6253/8000, Loss: 0.126931816339.\n",
      "Iteration: 6254/8000, Loss: 0.126931816339.\n",
      "Iteration: 6255/8000, Loss: 0.126931801438.\n",
      "Iteration: 6256/8000, Loss: 0.126931801438.\n",
      "Iteration: 6257/8000, Loss: 0.126931801438.\n",
      "Iteration: 6258/8000, Loss: 0.126931801438.\n",
      "Iteration: 6259/8000, Loss: 0.126931786537.\n",
      "Iteration: 6260/8000, Loss: 0.126931786537.\n",
      "Iteration: 6261/8000, Loss: 0.126931786537.\n",
      "Iteration: 6262/8000, Loss: 0.126931786537.\n",
      "Iteration: 6263/8000, Loss: 0.126931786537.\n",
      "Iteration: 6264/8000, Loss: 0.126931786537.\n",
      "Iteration: 6265/8000, Loss: 0.126931786537.\n",
      "Iteration: 6266/8000, Loss: 0.126931771636.\n",
      "Iteration: 6267/8000, Loss: 0.126931786537.\n",
      "Iteration: 6268/8000, Loss: 0.126931771636.\n",
      "Iteration: 6269/8000, Loss: 0.126931786537.\n",
      "Iteration: 6270/8000, Loss: 0.126931771636.\n",
      "Iteration: 6271/8000, Loss: 0.126931771636.\n",
      "Iteration: 6272/8000, Loss: 0.126931771636.\n",
      "Iteration: 6273/8000, Loss: 0.126931756735.\n",
      "Iteration: 6274/8000, Loss: 0.126931771636.\n",
      "Iteration: 6275/8000, Loss: 0.126931756735.\n",
      "Iteration: 6276/8000, Loss: 0.126931756735.\n",
      "Iteration: 6277/8000, Loss: 0.126931756735.\n",
      "Iteration: 6278/8000, Loss: 0.126931756735.\n",
      "Iteration: 6279/8000, Loss: 0.126931756735.\n",
      "Iteration: 6280/8000, Loss: 0.126931741834.\n",
      "Iteration: 6281/8000, Loss: 0.126931756735.\n",
      "Iteration: 6282/8000, Loss: 0.126931741834.\n",
      "Iteration: 6283/8000, Loss: 0.126931741834.\n",
      "Iteration: 6284/8000, Loss: 0.126931741834.\n",
      "Iteration: 6285/8000, Loss: 0.126931741834.\n",
      "Iteration: 6286/8000, Loss: 0.126931741834.\n",
      "Iteration: 6287/8000, Loss: 0.126931741834.\n",
      "Iteration: 6288/8000, Loss: 0.126931726933.\n",
      "Iteration: 6289/8000, Loss: 0.126931741834.\n",
      "Iteration: 6290/8000, Loss: 0.126931741834.\n",
      "Iteration: 6291/8000, Loss: 0.126931726933.\n",
      "Iteration: 6292/8000, Loss: 0.126931712031.\n",
      "Iteration: 6293/8000, Loss: 0.126931712031.\n",
      "Iteration: 6294/8000, Loss: 0.126931712031.\n",
      "Iteration: 6295/8000, Loss: 0.126931712031.\n",
      "Iteration: 6296/8000, Loss: 0.126931712031.\n",
      "Iteration: 6297/8000, Loss: 0.126931712031.\n",
      "Iteration: 6298/8000, Loss: 0.126931712031.\n",
      "Iteration: 6299/8000, Loss: 0.126931712031.\n",
      "Iteration: 6300/8000, Loss: 0.12693169713.\n",
      "Iteration: 6301/8000, Loss: 0.12693169713.\n",
      "Iteration: 6302/8000, Loss: 0.12693169713.\n",
      "Iteration: 6303/8000, Loss: 0.12693169713.\n",
      "Iteration: 6304/8000, Loss: 0.12693169713.\n",
      "Iteration: 6305/8000, Loss: 0.126931682229.\n",
      "Iteration: 6306/8000, Loss: 0.12693169713.\n",
      "Iteration: 6307/8000, Loss: 0.12693169713.\n",
      "Iteration: 6308/8000, Loss: 0.126931682229.\n",
      "Iteration: 6309/8000, Loss: 0.126931682229.\n",
      "Iteration: 6310/8000, Loss: 0.126931682229.\n",
      "Iteration: 6311/8000, Loss: 0.126931682229.\n",
      "Iteration: 6312/8000, Loss: 0.126931682229.\n",
      "Iteration: 6313/8000, Loss: 0.126931682229.\n",
      "Iteration: 6314/8000, Loss: 0.126931667328.\n",
      "Iteration: 6315/8000, Loss: 0.126931667328.\n",
      "Iteration: 6316/8000, Loss: 0.126931667328.\n",
      "Iteration: 6317/8000, Loss: 0.126931667328.\n",
      "Iteration: 6318/8000, Loss: 0.126931667328.\n",
      "Iteration: 6319/8000, Loss: 0.126931667328.\n",
      "Iteration: 6320/8000, Loss: 0.126931667328.\n",
      "Iteration: 6321/8000, Loss: 0.126931652427.\n",
      "Iteration: 6322/8000, Loss: 0.126931667328.\n",
      "Iteration: 6323/8000, Loss: 0.126931652427.\n",
      "Iteration: 6324/8000, Loss: 0.126931637526.\n",
      "Iteration: 6325/8000, Loss: 0.126931637526.\n",
      "Iteration: 6326/8000, Loss: 0.126931637526.\n",
      "Iteration: 6327/8000, Loss: 0.126931637526.\n",
      "Iteration: 6328/8000, Loss: 0.126931637526.\n",
      "Iteration: 6329/8000, Loss: 0.126931637526.\n",
      "Iteration: 6330/8000, Loss: 0.126931637526.\n",
      "Iteration: 6331/8000, Loss: 0.126931637526.\n",
      "Iteration: 6332/8000, Loss: 0.126931637526.\n",
      "Iteration: 6333/8000, Loss: 0.126931637526.\n",
      "Iteration: 6334/8000, Loss: 0.126931637526.\n",
      "Iteration: 6335/8000, Loss: 0.126931637526.\n",
      "Iteration: 6336/8000, Loss: 0.126931622624.\n",
      "Iteration: 6337/8000, Loss: 0.126931637526.\n",
      "Iteration: 6338/8000, Loss: 0.126931622624.\n",
      "Iteration: 6339/8000, Loss: 0.126931607723.\n",
      "Iteration: 6340/8000, Loss: 0.126931607723.\n",
      "Iteration: 6341/8000, Loss: 0.126931607723.\n",
      "Iteration: 6342/8000, Loss: 0.126931607723.\n",
      "Iteration: 6343/8000, Loss: 0.126931607723.\n",
      "Iteration: 6344/8000, Loss: 0.126931607723.\n",
      "Iteration: 6345/8000, Loss: 0.126931607723.\n",
      "Iteration: 6346/8000, Loss: 0.126931607723.\n",
      "Iteration: 6347/8000, Loss: 0.126931607723.\n",
      "Iteration: 6348/8000, Loss: 0.126931592822.\n",
      "Iteration: 6349/8000, Loss: 0.126931592822.\n",
      "Iteration: 6350/8000, Loss: 0.126931592822.\n",
      "Iteration: 6351/8000, Loss: 0.126931592822.\n",
      "Iteration: 6352/8000, Loss: 0.126931592822.\n",
      "Iteration: 6353/8000, Loss: 0.126931592822.\n",
      "Iteration: 6354/8000, Loss: 0.126931592822.\n",
      "Iteration: 6355/8000, Loss: 0.126931592822.\n",
      "Iteration: 6356/8000, Loss: 0.126931577921.\n",
      "Iteration: 6357/8000, Loss: 0.126931577921.\n",
      "Iteration: 6358/8000, Loss: 0.126931577921.\n",
      "Iteration: 6359/8000, Loss: 0.126931577921.\n",
      "Iteration: 6360/8000, Loss: 0.126931577921.\n",
      "Iteration: 6361/8000, Loss: 0.126931577921.\n",
      "Iteration: 6362/8000, Loss: 0.126931577921.\n",
      "Iteration: 6363/8000, Loss: 0.126931577921.\n",
      "Iteration: 6364/8000, Loss: 0.126931577921.\n",
      "Iteration: 6365/8000, Loss: 0.126931577921.\n",
      "Iteration: 6366/8000, Loss: 0.126931577921.\n",
      "Iteration: 6367/8000, Loss: 0.126931577921.\n",
      "Iteration: 6368/8000, Loss: 0.12693156302.\n",
      "Iteration: 6369/8000, Loss: 0.126931577921.\n",
      "Iteration: 6370/8000, Loss: 0.126931548119.\n",
      "Iteration: 6371/8000, Loss: 0.126931548119.\n",
      "Iteration: 6372/8000, Loss: 0.126931548119.\n",
      "Iteration: 6373/8000, Loss: 0.126931548119.\n",
      "Iteration: 6374/8000, Loss: 0.126931533217.\n",
      "Iteration: 6375/8000, Loss: 0.126931533217.\n",
      "Iteration: 6376/8000, Loss: 0.126931533217.\n",
      "Iteration: 6377/8000, Loss: 0.126931533217.\n",
      "Iteration: 6378/8000, Loss: 0.126931533217.\n",
      "Iteration: 6379/8000, Loss: 0.126931533217.\n",
      "Iteration: 6380/8000, Loss: 0.126931533217.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6381/8000, Loss: 0.126931533217.\n",
      "Iteration: 6382/8000, Loss: 0.126931533217.\n",
      "Iteration: 6383/8000, Loss: 0.126931533217.\n",
      "Iteration: 6384/8000, Loss: 0.126931533217.\n",
      "Iteration: 6385/8000, Loss: 0.126931533217.\n",
      "Iteration: 6386/8000, Loss: 0.126931518316.\n",
      "Iteration: 6387/8000, Loss: 0.126931518316.\n",
      "Iteration: 6388/8000, Loss: 0.126931518316.\n",
      "Iteration: 6389/8000, Loss: 0.126931518316.\n",
      "Iteration: 6390/8000, Loss: 0.126931518316.\n",
      "Iteration: 6391/8000, Loss: 0.126931518316.\n",
      "Iteration: 6392/8000, Loss: 0.126931518316.\n",
      "Iteration: 6393/8000, Loss: 0.126931503415.\n",
      "Iteration: 6394/8000, Loss: 0.126931503415.\n",
      "Iteration: 6395/8000, Loss: 0.126931503415.\n",
      "Iteration: 6396/8000, Loss: 0.126931503415.\n",
      "Iteration: 6397/8000, Loss: 0.126931503415.\n",
      "Iteration: 6398/8000, Loss: 0.126931488514.\n",
      "Iteration: 6399/8000, Loss: 0.126931488514.\n",
      "Iteration: 6400/8000, Loss: 0.126931488514.\n",
      "Iteration: 6401/8000, Loss: 0.126931488514.\n",
      "Iteration: 6402/8000, Loss: 0.126931488514.\n",
      "Iteration: 6403/8000, Loss: 0.126931488514.\n",
      "Iteration: 6404/8000, Loss: 0.126931488514.\n",
      "Iteration: 6405/8000, Loss: 0.126931488514.\n",
      "Iteration: 6406/8000, Loss: 0.126931473613.\n",
      "Iteration: 6407/8000, Loss: 0.126931473613.\n",
      "Iteration: 6408/8000, Loss: 0.126931473613.\n",
      "Iteration: 6409/8000, Loss: 0.126931473613.\n",
      "Iteration: 6410/8000, Loss: 0.126931473613.\n",
      "Iteration: 6411/8000, Loss: 0.126931473613.\n",
      "Iteration: 6412/8000, Loss: 0.126931458712.\n",
      "Iteration: 6413/8000, Loss: 0.126931458712.\n",
      "Iteration: 6414/8000, Loss: 0.126931458712.\n",
      "Iteration: 6415/8000, Loss: 0.126931458712.\n",
      "Iteration: 6416/8000, Loss: 0.126931458712.\n",
      "Iteration: 6417/8000, Loss: 0.126931458712.\n",
      "Iteration: 6418/8000, Loss: 0.126931458712.\n",
      "Iteration: 6419/8000, Loss: 0.126931458712.\n",
      "Iteration: 6420/8000, Loss: 0.126931458712.\n",
      "Iteration: 6421/8000, Loss: 0.12693144381.\n",
      "Iteration: 6422/8000, Loss: 0.126931458712.\n",
      "Iteration: 6423/8000, Loss: 0.12693144381.\n",
      "Iteration: 6424/8000, Loss: 0.12693144381.\n",
      "Iteration: 6425/8000, Loss: 0.12693144381.\n",
      "Iteration: 6426/8000, Loss: 0.12693144381.\n",
      "Iteration: 6427/8000, Loss: 0.126931428909.\n",
      "Iteration: 6428/8000, Loss: 0.126931428909.\n",
      "Iteration: 6429/8000, Loss: 0.126931428909.\n",
      "Iteration: 6430/8000, Loss: 0.126931428909.\n",
      "Iteration: 6431/8000, Loss: 0.126931428909.\n",
      "Iteration: 6432/8000, Loss: 0.126931428909.\n",
      "Iteration: 6433/8000, Loss: 0.126931428909.\n",
      "Iteration: 6434/8000, Loss: 0.126931428909.\n",
      "Iteration: 6435/8000, Loss: 0.126931428909.\n",
      "Iteration: 6436/8000, Loss: 0.126931428909.\n",
      "Iteration: 6437/8000, Loss: 0.126931428909.\n",
      "Iteration: 6438/8000, Loss: 0.126931428909.\n",
      "Iteration: 6439/8000, Loss: 0.126931414008.\n",
      "Iteration: 6440/8000, Loss: 0.126931414008.\n",
      "Iteration: 6441/8000, Loss: 0.126931399107.\n",
      "Iteration: 6442/8000, Loss: 0.126931399107.\n",
      "Iteration: 6443/8000, Loss: 0.126931399107.\n",
      "Iteration: 6444/8000, Loss: 0.126931399107.\n",
      "Iteration: 6445/8000, Loss: 0.126931399107.\n",
      "Iteration: 6446/8000, Loss: 0.126931399107.\n",
      "Iteration: 6447/8000, Loss: 0.126931384206.\n",
      "Iteration: 6448/8000, Loss: 0.126931399107.\n",
      "Iteration: 6449/8000, Loss: 0.126931384206.\n",
      "Iteration: 6450/8000, Loss: 0.126931384206.\n",
      "Iteration: 6451/8000, Loss: 0.126931384206.\n",
      "Iteration: 6452/8000, Loss: 0.126931384206.\n",
      "Iteration: 6453/8000, Loss: 0.126931399107.\n",
      "Iteration: 6454/8000, Loss: 0.126931384206.\n",
      "Iteration: 6455/8000, Loss: 0.126931384206.\n",
      "Iteration: 6456/8000, Loss: 0.126931369305.\n",
      "Iteration: 6457/8000, Loss: 0.126931369305.\n",
      "Iteration: 6458/8000, Loss: 0.126931384206.\n",
      "Iteration: 6459/8000, Loss: 0.126931369305.\n",
      "Iteration: 6460/8000, Loss: 0.126931369305.\n",
      "Iteration: 6461/8000, Loss: 0.126931369305.\n",
      "Iteration: 6462/8000, Loss: 0.126931369305.\n",
      "Iteration: 6463/8000, Loss: 0.126931369305.\n",
      "Iteration: 6464/8000, Loss: 0.126931369305.\n",
      "Iteration: 6465/8000, Loss: 0.126931369305.\n",
      "Iteration: 6466/8000, Loss: 0.126931369305.\n",
      "Iteration: 6467/8000, Loss: 0.126931354403.\n",
      "Iteration: 6468/8000, Loss: 0.126931354403.\n",
      "Iteration: 6469/8000, Loss: 0.126931354403.\n",
      "Iteration: 6470/8000, Loss: 0.126931354403.\n",
      "Iteration: 6471/8000, Loss: 0.126931339502.\n",
      "Iteration: 6472/8000, Loss: 0.126931354403.\n",
      "Iteration: 6473/8000, Loss: 0.126931354403.\n",
      "Iteration: 6474/8000, Loss: 0.126931339502.\n",
      "Iteration: 6475/8000, Loss: 0.126931339502.\n",
      "Iteration: 6476/8000, Loss: 0.126931339502.\n",
      "Iteration: 6477/8000, Loss: 0.126931339502.\n",
      "Iteration: 6478/8000, Loss: 0.126931339502.\n",
      "Iteration: 6479/8000, Loss: 0.126931339502.\n",
      "Iteration: 6480/8000, Loss: 0.126931339502.\n",
      "Iteration: 6481/8000, Loss: 0.126931339502.\n",
      "Iteration: 6482/8000, Loss: 0.126931339502.\n",
      "Iteration: 6483/8000, Loss: 0.126931339502.\n",
      "Iteration: 6484/8000, Loss: 0.126931339502.\n",
      "Iteration: 6485/8000, Loss: 0.126931324601.\n",
      "Iteration: 6486/8000, Loss: 0.126931324601.\n",
      "Iteration: 6487/8000, Loss: 0.126931324601.\n",
      "Iteration: 6488/8000, Loss: 0.126931324601.\n",
      "Iteration: 6489/8000, Loss: 0.1269313097.\n",
      "Iteration: 6490/8000, Loss: 0.126931324601.\n",
      "Iteration: 6491/8000, Loss: 0.126931324601.\n",
      "Iteration: 6492/8000, Loss: 0.126931324601.\n",
      "Iteration: 6493/8000, Loss: 0.126931324601.\n",
      "Iteration: 6494/8000, Loss: 0.1269313097.\n",
      "Iteration: 6495/8000, Loss: 0.126931294799.\n",
      "Iteration: 6496/8000, Loss: 0.1269313097.\n",
      "Iteration: 6497/8000, Loss: 0.126931294799.\n",
      "Iteration: 6498/8000, Loss: 0.126931294799.\n",
      "Iteration: 6499/8000, Loss: 0.126931294799.\n",
      "Iteration: 6500/8000, Loss: 0.126931294799.\n",
      "Iteration: 6501/8000, Loss: 0.126931294799.\n",
      "Iteration: 6502/8000, Loss: 0.126931294799.\n",
      "Iteration: 6503/8000, Loss: 0.126931294799.\n",
      "Iteration: 6504/8000, Loss: 0.126931294799.\n",
      "Iteration: 6505/8000, Loss: 0.126931294799.\n",
      "Iteration: 6506/8000, Loss: 0.126931294799.\n",
      "Iteration: 6507/8000, Loss: 0.126931294799.\n",
      "Iteration: 6508/8000, Loss: 0.126931279898.\n",
      "Iteration: 6509/8000, Loss: 0.126931279898.\n",
      "Iteration: 6510/8000, Loss: 0.126931279898.\n",
      "Iteration: 6511/8000, Loss: 0.126931279898.\n",
      "Iteration: 6512/8000, Loss: 0.126931279898.\n",
      "Iteration: 6513/8000, Loss: 0.126931279898.\n",
      "Iteration: 6514/8000, Loss: 0.126931279898.\n",
      "Iteration: 6515/8000, Loss: 0.126931264997.\n",
      "Iteration: 6516/8000, Loss: 0.126931264997.\n",
      "Iteration: 6517/8000, Loss: 0.126931264997.\n",
      "Iteration: 6518/8000, Loss: 0.126931264997.\n",
      "Iteration: 6519/8000, Loss: 0.126931264997.\n",
      "Iteration: 6520/8000, Loss: 0.126931250095.\n",
      "Iteration: 6521/8000, Loss: 0.126931250095.\n",
      "Iteration: 6522/8000, Loss: 0.126931250095.\n",
      "Iteration: 6523/8000, Loss: 0.126931250095.\n",
      "Iteration: 6524/8000, Loss: 0.126931250095.\n",
      "Iteration: 6525/8000, Loss: 0.126931250095.\n",
      "Iteration: 6526/8000, Loss: 0.126931250095.\n",
      "Iteration: 6527/8000, Loss: 0.126931250095.\n",
      "Iteration: 6528/8000, Loss: 0.126931235194.\n",
      "Iteration: 6529/8000, Loss: 0.126931250095.\n",
      "Iteration: 6530/8000, Loss: 0.126931250095.\n",
      "Iteration: 6531/8000, Loss: 0.126931235194.\n",
      "Iteration: 6532/8000, Loss: 0.126931235194.\n",
      "Iteration: 6533/8000, Loss: 0.126931235194.\n",
      "Iteration: 6534/8000, Loss: 0.126931235194.\n",
      "Iteration: 6535/8000, Loss: 0.126931235194.\n",
      "Iteration: 6536/8000, Loss: 0.126931235194.\n",
      "Iteration: 6537/8000, Loss: 0.126931235194.\n",
      "Iteration: 6538/8000, Loss: 0.126931235194.\n",
      "Iteration: 6539/8000, Loss: 0.126931220293.\n",
      "Iteration: 6540/8000, Loss: 0.126931220293.\n",
      "Iteration: 6541/8000, Loss: 0.126931235194.\n",
      "Iteration: 6542/8000, Loss: 0.126931220293.\n",
      "Iteration: 6543/8000, Loss: 0.126931220293.\n",
      "Iteration: 6544/8000, Loss: 0.126931220293.\n",
      "Iteration: 6545/8000, Loss: 0.126931220293.\n",
      "Iteration: 6546/8000, Loss: 0.126931220293.\n",
      "Iteration: 6547/8000, Loss: 0.126931220293.\n",
      "Iteration: 6548/8000, Loss: 0.126931220293.\n",
      "Iteration: 6549/8000, Loss: 0.126931205392.\n",
      "Iteration: 6550/8000, Loss: 0.126931205392.\n",
      "Iteration: 6551/8000, Loss: 0.126931220293.\n",
      "Iteration: 6552/8000, Loss: 0.126931205392.\n",
      "Iteration: 6553/8000, Loss: 0.126931190491.\n",
      "Iteration: 6554/8000, Loss: 0.126931205392.\n",
      "Iteration: 6555/8000, Loss: 0.126931190491.\n",
      "Iteration: 6556/8000, Loss: 0.126931190491.\n",
      "Iteration: 6557/8000, Loss: 0.126931190491.\n",
      "Iteration: 6558/8000, Loss: 0.126931190491.\n",
      "Iteration: 6559/8000, Loss: 0.126931190491.\n",
      "Iteration: 6560/8000, Loss: 0.12693117559.\n",
      "Iteration: 6561/8000, Loss: 0.126931190491.\n",
      "Iteration: 6562/8000, Loss: 0.12693117559.\n",
      "Iteration: 6563/8000, Loss: 0.126931190491.\n",
      "Iteration: 6564/8000, Loss: 0.12693117559.\n",
      "Iteration: 6565/8000, Loss: 0.126931190491.\n",
      "Iteration: 6566/8000, Loss: 0.12693117559.\n",
      "Iteration: 6567/8000, Loss: 0.12693117559.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6568/8000, Loss: 0.12693117559.\n",
      "Iteration: 6569/8000, Loss: 0.126931160688.\n",
      "Iteration: 6570/8000, Loss: 0.126931160688.\n",
      "Iteration: 6571/8000, Loss: 0.126931160688.\n",
      "Iteration: 6572/8000, Loss: 0.126931160688.\n",
      "Iteration: 6573/8000, Loss: 0.126931160688.\n",
      "Iteration: 6574/8000, Loss: 0.126931160688.\n",
      "Iteration: 6575/8000, Loss: 0.126931160688.\n",
      "Iteration: 6576/8000, Loss: 0.126931160688.\n",
      "Iteration: 6577/8000, Loss: 0.126931160688.\n",
      "Iteration: 6578/8000, Loss: 0.126931160688.\n",
      "Iteration: 6579/8000, Loss: 0.126931160688.\n",
      "Iteration: 6580/8000, Loss: 0.126931145787.\n",
      "Iteration: 6581/8000, Loss: 0.126931160688.\n",
      "Iteration: 6582/8000, Loss: 0.126931160688.\n",
      "Iteration: 6583/8000, Loss: 0.126931160688.\n",
      "Iteration: 6584/8000, Loss: 0.126931160688.\n",
      "Iteration: 6585/8000, Loss: 0.126931145787.\n",
      "Iteration: 6586/8000, Loss: 0.126931145787.\n",
      "Iteration: 6587/8000, Loss: 0.126931145787.\n",
      "Iteration: 6588/8000, Loss: 0.126931145787.\n",
      "Iteration: 6589/8000, Loss: 0.126931145787.\n",
      "Iteration: 6590/8000, Loss: 0.126931130886.\n",
      "Iteration: 6591/8000, Loss: 0.126931130886.\n",
      "Iteration: 6592/8000, Loss: 0.126931130886.\n",
      "Iteration: 6593/8000, Loss: 0.126931130886.\n",
      "Iteration: 6594/8000, Loss: 0.126931130886.\n",
      "Iteration: 6595/8000, Loss: 0.126931130886.\n",
      "Iteration: 6596/8000, Loss: 0.126931130886.\n",
      "Iteration: 6597/8000, Loss: 0.126931115985.\n",
      "Iteration: 6598/8000, Loss: 0.126931115985.\n",
      "Iteration: 6599/8000, Loss: 0.126931115985.\n",
      "Iteration: 6600/8000, Loss: 0.126931115985.\n",
      "Iteration: 6601/8000, Loss: 0.126931115985.\n",
      "Iteration: 6602/8000, Loss: 0.126931115985.\n",
      "Iteration: 6603/8000, Loss: 0.126931115985.\n",
      "Iteration: 6604/8000, Loss: 0.126931115985.\n",
      "Iteration: 6605/8000, Loss: 0.126931115985.\n",
      "Iteration: 6606/8000, Loss: 0.126931101084.\n",
      "Iteration: 6607/8000, Loss: 0.126931101084.\n",
      "Iteration: 6608/8000, Loss: 0.126931101084.\n",
      "Iteration: 6609/8000, Loss: 0.126931101084.\n",
      "Iteration: 6610/8000, Loss: 0.126931101084.\n",
      "Iteration: 6611/8000, Loss: 0.126931101084.\n",
      "Iteration: 6612/8000, Loss: 0.126931101084.\n",
      "Iteration: 6613/8000, Loss: 0.126931086183.\n",
      "Iteration: 6614/8000, Loss: 0.126931101084.\n",
      "Iteration: 6615/8000, Loss: 0.126931086183.\n",
      "Iteration: 6616/8000, Loss: 0.126931086183.\n",
      "Iteration: 6617/8000, Loss: 0.126931086183.\n",
      "Iteration: 6618/8000, Loss: 0.126931101084.\n",
      "Iteration: 6619/8000, Loss: 0.126931071281.\n",
      "Iteration: 6620/8000, Loss: 0.126931071281.\n",
      "Iteration: 6621/8000, Loss: 0.126931071281.\n",
      "Iteration: 6622/8000, Loss: 0.126931071281.\n",
      "Iteration: 6623/8000, Loss: 0.126931071281.\n",
      "Iteration: 6624/8000, Loss: 0.126931071281.\n",
      "Iteration: 6625/8000, Loss: 0.126931071281.\n",
      "Iteration: 6626/8000, Loss: 0.126931071281.\n",
      "Iteration: 6627/8000, Loss: 0.12693105638.\n",
      "Iteration: 6628/8000, Loss: 0.126931071281.\n",
      "Iteration: 6629/8000, Loss: 0.126931071281.\n",
      "Iteration: 6630/8000, Loss: 0.12693105638.\n",
      "Iteration: 6631/8000, Loss: 0.126931071281.\n",
      "Iteration: 6632/8000, Loss: 0.12693105638.\n",
      "Iteration: 6633/8000, Loss: 0.12693105638.\n",
      "Iteration: 6634/8000, Loss: 0.12693105638.\n",
      "Iteration: 6635/8000, Loss: 0.12693105638.\n",
      "Iteration: 6636/8000, Loss: 0.12693105638.\n",
      "Iteration: 6637/8000, Loss: 0.12693105638.\n",
      "Iteration: 6638/8000, Loss: 0.12693105638.\n",
      "Iteration: 6639/8000, Loss: 0.126931041479.\n",
      "Iteration: 6640/8000, Loss: 0.126931041479.\n",
      "Iteration: 6641/8000, Loss: 0.126931041479.\n",
      "Iteration: 6642/8000, Loss: 0.126931041479.\n",
      "Iteration: 6643/8000, Loss: 0.126931041479.\n",
      "Iteration: 6644/8000, Loss: 0.126931041479.\n",
      "Iteration: 6645/8000, Loss: 0.126931041479.\n",
      "Iteration: 6646/8000, Loss: 0.126931041479.\n",
      "Iteration: 6647/8000, Loss: 0.126931041479.\n",
      "Iteration: 6648/8000, Loss: 0.126931041479.\n",
      "Iteration: 6649/8000, Loss: 0.126931026578.\n",
      "Iteration: 6650/8000, Loss: 0.126931026578.\n",
      "Iteration: 6651/8000, Loss: 0.126931026578.\n",
      "Iteration: 6652/8000, Loss: 0.126931026578.\n",
      "Iteration: 6653/8000, Loss: 0.126931026578.\n",
      "Iteration: 6654/8000, Loss: 0.126931026578.\n",
      "Iteration: 6655/8000, Loss: 0.126931011677.\n",
      "Iteration: 6656/8000, Loss: 0.126931011677.\n",
      "Iteration: 6657/8000, Loss: 0.126931011677.\n",
      "Iteration: 6658/8000, Loss: 0.126931011677.\n",
      "Iteration: 6659/8000, Loss: 0.126931011677.\n",
      "Iteration: 6660/8000, Loss: 0.126931011677.\n",
      "Iteration: 6661/8000, Loss: 0.126931011677.\n",
      "Iteration: 6662/8000, Loss: 0.126931011677.\n",
      "Iteration: 6663/8000, Loss: 0.126931011677.\n",
      "Iteration: 6664/8000, Loss: 0.126931011677.\n",
      "Iteration: 6665/8000, Loss: 0.126931011677.\n",
      "Iteration: 6666/8000, Loss: 0.126930996776.\n",
      "Iteration: 6667/8000, Loss: 0.126930996776.\n",
      "Iteration: 6668/8000, Loss: 0.126930996776.\n",
      "Iteration: 6669/8000, Loss: 0.126930981874.\n",
      "Iteration: 6670/8000, Loss: 0.126930981874.\n",
      "Iteration: 6671/8000, Loss: 0.126930981874.\n",
      "Iteration: 6672/8000, Loss: 0.126930981874.\n",
      "Iteration: 6673/8000, Loss: 0.126930981874.\n",
      "Iteration: 6674/8000, Loss: 0.126930981874.\n",
      "Iteration: 6675/8000, Loss: 0.126930981874.\n",
      "Iteration: 6676/8000, Loss: 0.126930981874.\n",
      "Iteration: 6677/8000, Loss: 0.126930981874.\n",
      "Iteration: 6678/8000, Loss: 0.126930981874.\n",
      "Iteration: 6679/8000, Loss: 0.126930981874.\n",
      "Iteration: 6680/8000, Loss: 0.126930981874.\n",
      "Iteration: 6681/8000, Loss: 0.126930981874.\n",
      "Iteration: 6682/8000, Loss: 0.126930981874.\n",
      "Iteration: 6683/8000, Loss: 0.126930981874.\n",
      "Iteration: 6684/8000, Loss: 0.126930966973.\n",
      "Iteration: 6685/8000, Loss: 0.126930952072.\n",
      "Iteration: 6686/8000, Loss: 0.126930952072.\n",
      "Iteration: 6687/8000, Loss: 0.126930952072.\n",
      "Iteration: 6688/8000, Loss: 0.126930952072.\n",
      "Iteration: 6689/8000, Loss: 0.126930952072.\n",
      "Iteration: 6690/8000, Loss: 0.126930952072.\n",
      "Iteration: 6691/8000, Loss: 0.126930952072.\n",
      "Iteration: 6692/8000, Loss: 0.126930952072.\n",
      "Iteration: 6693/8000, Loss: 0.126930952072.\n",
      "Iteration: 6694/8000, Loss: 0.126930952072.\n",
      "Iteration: 6695/8000, Loss: 0.126930952072.\n",
      "Iteration: 6696/8000, Loss: 0.126930952072.\n",
      "Iteration: 6697/8000, Loss: 0.126930952072.\n",
      "Iteration: 6698/8000, Loss: 0.126930952072.\n",
      "Iteration: 6699/8000, Loss: 0.126930952072.\n",
      "Iteration: 6700/8000, Loss: 0.126930952072.\n",
      "Iteration: 6701/8000, Loss: 0.126930952072.\n",
      "Iteration: 6702/8000, Loss: 0.126930937171.\n",
      "Iteration: 6703/8000, Loss: 0.126930937171.\n",
      "Iteration: 6704/8000, Loss: 0.126930937171.\n",
      "Iteration: 6705/8000, Loss: 0.126930937171.\n",
      "Iteration: 6706/8000, Loss: 0.126930937171.\n",
      "Iteration: 6707/8000, Loss: 0.126930937171.\n",
      "Iteration: 6708/8000, Loss: 0.126930937171.\n",
      "Iteration: 6709/8000, Loss: 0.126930937171.\n",
      "Iteration: 6710/8000, Loss: 0.12693092227.\n",
      "Iteration: 6711/8000, Loss: 0.12693092227.\n",
      "Iteration: 6712/8000, Loss: 0.12693092227.\n",
      "Iteration: 6713/8000, Loss: 0.12693092227.\n",
      "Iteration: 6714/8000, Loss: 0.12693092227.\n",
      "Iteration: 6715/8000, Loss: 0.12693092227.\n",
      "Iteration: 6716/8000, Loss: 0.12693092227.\n",
      "Iteration: 6717/8000, Loss: 0.12693092227.\n",
      "Iteration: 6718/8000, Loss: 0.12693092227.\n",
      "Iteration: 6719/8000, Loss: 0.12693092227.\n",
      "Iteration: 6720/8000, Loss: 0.12693092227.\n",
      "Iteration: 6721/8000, Loss: 0.12693092227.\n",
      "Iteration: 6722/8000, Loss: 0.12693092227.\n",
      "Iteration: 6723/8000, Loss: 0.12693092227.\n",
      "Iteration: 6724/8000, Loss: 0.12693092227.\n",
      "Iteration: 6725/8000, Loss: 0.12693092227.\n",
      "Iteration: 6726/8000, Loss: 0.126930907369.\n",
      "Iteration: 6727/8000, Loss: 0.126930892467.\n",
      "Iteration: 6728/8000, Loss: 0.126930907369.\n",
      "Iteration: 6729/8000, Loss: 0.126930892467.\n",
      "Iteration: 6730/8000, Loss: 0.126930892467.\n",
      "Iteration: 6731/8000, Loss: 0.126930892467.\n",
      "Iteration: 6732/8000, Loss: 0.126930892467.\n",
      "Iteration: 6733/8000, Loss: 0.126930892467.\n",
      "Iteration: 6734/8000, Loss: 0.126930892467.\n",
      "Iteration: 6735/8000, Loss: 0.126930892467.\n",
      "Iteration: 6736/8000, Loss: 0.126930892467.\n",
      "Iteration: 6737/8000, Loss: 0.126930892467.\n",
      "Iteration: 6738/8000, Loss: 0.126930877566.\n",
      "Iteration: 6739/8000, Loss: 0.126930877566.\n",
      "Iteration: 6740/8000, Loss: 0.126930877566.\n",
      "Iteration: 6741/8000, Loss: 0.126930877566.\n",
      "Iteration: 6742/8000, Loss: 0.126930877566.\n",
      "Iteration: 6743/8000, Loss: 0.126930877566.\n",
      "Iteration: 6744/8000, Loss: 0.126930877566.\n",
      "Iteration: 6745/8000, Loss: 0.126930877566.\n",
      "Iteration: 6746/8000, Loss: 0.126930877566.\n",
      "Iteration: 6747/8000, Loss: 0.126930862665.\n",
      "Iteration: 6748/8000, Loss: 0.126930862665.\n",
      "Iteration: 6749/8000, Loss: 0.126930862665.\n",
      "Iteration: 6750/8000, Loss: 0.126930862665.\n",
      "Iteration: 6751/8000, Loss: 0.126930862665.\n",
      "Iteration: 6752/8000, Loss: 0.126930847764.\n",
      "Iteration: 6753/8000, Loss: 0.126930847764.\n",
      "Iteration: 6754/8000, Loss: 0.126930847764.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6755/8000, Loss: 0.126930847764.\n",
      "Iteration: 6756/8000, Loss: 0.126930847764.\n",
      "Iteration: 6757/8000, Loss: 0.126930847764.\n",
      "Iteration: 6758/8000, Loss: 0.126930847764.\n",
      "Iteration: 6759/8000, Loss: 0.126930832863.\n",
      "Iteration: 6760/8000, Loss: 0.126930832863.\n",
      "Iteration: 6761/8000, Loss: 0.126930832863.\n",
      "Iteration: 6762/8000, Loss: 0.126930832863.\n",
      "Iteration: 6763/8000, Loss: 0.126930832863.\n",
      "Iteration: 6764/8000, Loss: 0.126930832863.\n",
      "Iteration: 6765/8000, Loss: 0.126930832863.\n",
      "Iteration: 6766/8000, Loss: 0.126930832863.\n",
      "Iteration: 6767/8000, Loss: 0.126930832863.\n",
      "Iteration: 6768/8000, Loss: 0.126930832863.\n",
      "Iteration: 6769/8000, Loss: 0.126930832863.\n",
      "Iteration: 6770/8000, Loss: 0.126930832863.\n",
      "Iteration: 6771/8000, Loss: 0.126930832863.\n",
      "Iteration: 6772/8000, Loss: 0.126930832863.\n",
      "Iteration: 6773/8000, Loss: 0.126930832863.\n",
      "Iteration: 6774/8000, Loss: 0.126930832863.\n",
      "Iteration: 6775/8000, Loss: 0.126930832863.\n",
      "Iteration: 6776/8000, Loss: 0.126930817962.\n",
      "Iteration: 6777/8000, Loss: 0.126930817962.\n",
      "Iteration: 6778/8000, Loss: 0.126930817962.\n",
      "Iteration: 6779/8000, Loss: 0.126930817962.\n",
      "Iteration: 6780/8000, Loss: 0.126930817962.\n",
      "Iteration: 6781/8000, Loss: 0.126930817962.\n",
      "Iteration: 6782/8000, Loss: 0.126930817962.\n",
      "Iteration: 6783/8000, Loss: 0.126930803061.\n",
      "Iteration: 6784/8000, Loss: 0.126930817962.\n",
      "Iteration: 6785/8000, Loss: 0.126930803061.\n",
      "Iteration: 6786/8000, Loss: 0.126930817962.\n",
      "Iteration: 6787/8000, Loss: 0.126930803061.\n",
      "Iteration: 6788/8000, Loss: 0.126930803061.\n",
      "Iteration: 6789/8000, Loss: 0.126930803061.\n",
      "Iteration: 6790/8000, Loss: 0.126930803061.\n",
      "Iteration: 6791/8000, Loss: 0.126930803061.\n",
      "Iteration: 6792/8000, Loss: 0.126930788159.\n",
      "Iteration: 6793/8000, Loss: 0.126930788159.\n",
      "Iteration: 6794/8000, Loss: 0.126930788159.\n",
      "Iteration: 6795/8000, Loss: 0.126930788159.\n",
      "Iteration: 6796/8000, Loss: 0.126930788159.\n",
      "Iteration: 6797/8000, Loss: 0.126930788159.\n",
      "Iteration: 6798/8000, Loss: 0.126930788159.\n",
      "Iteration: 6799/8000, Loss: 0.126930788159.\n",
      "Iteration: 6800/8000, Loss: 0.126930773258.\n",
      "Iteration: 6801/8000, Loss: 0.126930788159.\n",
      "Iteration: 6802/8000, Loss: 0.126930773258.\n",
      "Iteration: 6803/8000, Loss: 0.126930773258.\n",
      "Iteration: 6804/8000, Loss: 0.126930773258.\n",
      "Iteration: 6805/8000, Loss: 0.126930773258.\n",
      "Iteration: 6806/8000, Loss: 0.126930773258.\n",
      "Iteration: 6807/8000, Loss: 0.126930773258.\n",
      "Iteration: 6808/8000, Loss: 0.126930773258.\n",
      "Iteration: 6809/8000, Loss: 0.126930773258.\n",
      "Iteration: 6810/8000, Loss: 0.126930773258.\n",
      "Iteration: 6811/8000, Loss: 0.126930773258.\n",
      "Iteration: 6812/8000, Loss: 0.126930773258.\n",
      "Iteration: 6813/8000, Loss: 0.126930773258.\n",
      "Iteration: 6814/8000, Loss: 0.126930773258.\n",
      "Iteration: 6815/8000, Loss: 0.126930743456.\n",
      "Iteration: 6816/8000, Loss: 0.126930758357.\n",
      "Iteration: 6817/8000, Loss: 0.126930758357.\n",
      "Iteration: 6818/8000, Loss: 0.126930758357.\n",
      "Iteration: 6819/8000, Loss: 0.126930743456.\n",
      "Iteration: 6820/8000, Loss: 0.126930743456.\n",
      "Iteration: 6821/8000, Loss: 0.126930758357.\n",
      "Iteration: 6822/8000, Loss: 0.126930758357.\n",
      "Iteration: 6823/8000, Loss: 0.126930743456.\n",
      "Iteration: 6824/8000, Loss: 0.126930743456.\n",
      "Iteration: 6825/8000, Loss: 0.126930743456.\n",
      "Iteration: 6826/8000, Loss: 0.126930743456.\n",
      "Iteration: 6827/8000, Loss: 0.126930743456.\n",
      "Iteration: 6828/8000, Loss: 0.126930743456.\n",
      "Iteration: 6829/8000, Loss: 0.126930743456.\n",
      "Iteration: 6830/8000, Loss: 0.126930743456.\n",
      "Iteration: 6831/8000, Loss: 0.126930743456.\n",
      "Iteration: 6832/8000, Loss: 0.126930743456.\n",
      "Iteration: 6833/8000, Loss: 0.126930728555.\n",
      "Iteration: 6834/8000, Loss: 0.126930728555.\n",
      "Iteration: 6835/8000, Loss: 0.126930728555.\n",
      "Iteration: 6836/8000, Loss: 0.126930728555.\n",
      "Iteration: 6837/8000, Loss: 0.126930728555.\n",
      "Iteration: 6838/8000, Loss: 0.126930728555.\n",
      "Iteration: 6839/8000, Loss: 0.126930728555.\n",
      "Iteration: 6840/8000, Loss: 0.126930728555.\n",
      "Iteration: 6841/8000, Loss: 0.126930728555.\n",
      "Iteration: 6842/8000, Loss: 0.126930728555.\n",
      "Iteration: 6843/8000, Loss: 0.126930713654.\n",
      "Iteration: 6844/8000, Loss: 0.126930713654.\n",
      "Iteration: 6845/8000, Loss: 0.126930728555.\n",
      "Iteration: 6846/8000, Loss: 0.126930713654.\n",
      "Iteration: 6847/8000, Loss: 0.126930713654.\n",
      "Iteration: 6848/8000, Loss: 0.126930713654.\n",
      "Iteration: 6849/8000, Loss: 0.126930713654.\n",
      "Iteration: 6850/8000, Loss: 0.126930698752.\n",
      "Iteration: 6851/8000, Loss: 0.126930683851.\n",
      "Iteration: 6852/8000, Loss: 0.126930713654.\n",
      "Iteration: 6853/8000, Loss: 0.126930683851.\n",
      "Iteration: 6854/8000, Loss: 0.126930683851.\n",
      "Iteration: 6855/8000, Loss: 0.126930683851.\n",
      "Iteration: 6856/8000, Loss: 0.126930683851.\n",
      "Iteration: 6857/8000, Loss: 0.126930683851.\n",
      "Iteration: 6858/8000, Loss: 0.126930683851.\n",
      "Iteration: 6859/8000, Loss: 0.126930683851.\n",
      "Iteration: 6860/8000, Loss: 0.126930683851.\n",
      "Iteration: 6861/8000, Loss: 0.126930683851.\n",
      "Iteration: 6862/8000, Loss: 0.12693066895.\n",
      "Iteration: 6863/8000, Loss: 0.126930683851.\n",
      "Iteration: 6864/8000, Loss: 0.12693066895.\n",
      "Iteration: 6865/8000, Loss: 0.126930683851.\n",
      "Iteration: 6866/8000, Loss: 0.126930683851.\n",
      "Iteration: 6867/8000, Loss: 0.12693066895.\n",
      "Iteration: 6868/8000, Loss: 0.12693066895.\n",
      "Iteration: 6869/8000, Loss: 0.126930683851.\n",
      "Iteration: 6870/8000, Loss: 0.12693066895.\n",
      "Iteration: 6871/8000, Loss: 0.12693066895.\n",
      "Iteration: 6872/8000, Loss: 0.12693066895.\n",
      "Iteration: 6873/8000, Loss: 0.12693066895.\n",
      "Iteration: 6874/8000, Loss: 0.12693066895.\n",
      "Iteration: 6875/8000, Loss: 0.12693066895.\n",
      "Iteration: 6876/8000, Loss: 0.12693066895.\n",
      "Iteration: 6877/8000, Loss: 0.126930654049.\n",
      "Iteration: 6878/8000, Loss: 0.12693066895.\n",
      "Iteration: 6879/8000, Loss: 0.12693066895.\n",
      "Iteration: 6880/8000, Loss: 0.12693066895.\n",
      "Iteration: 6881/8000, Loss: 0.12693066895.\n",
      "Iteration: 6882/8000, Loss: 0.126930654049.\n",
      "Iteration: 6883/8000, Loss: 0.12693066895.\n",
      "Iteration: 6884/8000, Loss: 0.126930654049.\n",
      "Iteration: 6885/8000, Loss: 0.12693066895.\n",
      "Iteration: 6886/8000, Loss: 0.126930654049.\n",
      "Iteration: 6887/8000, Loss: 0.126930654049.\n",
      "Iteration: 6888/8000, Loss: 0.126930654049.\n",
      "Iteration: 6889/8000, Loss: 0.126930654049.\n",
      "Iteration: 6890/8000, Loss: 0.126930654049.\n",
      "Iteration: 6891/8000, Loss: 0.126930654049.\n",
      "Iteration: 6892/8000, Loss: 0.126930654049.\n",
      "Iteration: 6893/8000, Loss: 0.126930654049.\n",
      "Iteration: 6894/8000, Loss: 0.126930654049.\n",
      "Iteration: 6895/8000, Loss: 0.126930624247.\n",
      "Iteration: 6896/8000, Loss: 0.126930639148.\n",
      "Iteration: 6897/8000, Loss: 0.126930639148.\n",
      "Iteration: 6898/8000, Loss: 0.126930624247.\n",
      "Iteration: 6899/8000, Loss: 0.126930624247.\n",
      "Iteration: 6900/8000, Loss: 0.126930624247.\n",
      "Iteration: 6901/8000, Loss: 0.126930624247.\n",
      "Iteration: 6902/8000, Loss: 0.126930624247.\n",
      "Iteration: 6903/8000, Loss: 0.126930624247.\n",
      "Iteration: 6904/8000, Loss: 0.126930624247.\n",
      "Iteration: 6905/8000, Loss: 0.126930624247.\n",
      "Iteration: 6906/8000, Loss: 0.126930624247.\n",
      "Iteration: 6907/8000, Loss: 0.126930624247.\n",
      "Iteration: 6908/8000, Loss: 0.126930624247.\n",
      "Iteration: 6909/8000, Loss: 0.126930624247.\n",
      "Iteration: 6910/8000, Loss: 0.126930624247.\n",
      "Iteration: 6911/8000, Loss: 0.126930609345.\n",
      "Iteration: 6912/8000, Loss: 0.126930624247.\n",
      "Iteration: 6913/8000, Loss: 0.126930609345.\n",
      "Iteration: 6914/8000, Loss: 0.126930624247.\n",
      "Iteration: 6915/8000, Loss: 0.126930609345.\n",
      "Iteration: 6916/8000, Loss: 0.126930609345.\n",
      "Iteration: 6917/8000, Loss: 0.126930609345.\n",
      "Iteration: 6918/8000, Loss: 0.126930609345.\n",
      "Iteration: 6919/8000, Loss: 0.126930609345.\n",
      "Iteration: 6920/8000, Loss: 0.126930594444.\n",
      "Iteration: 6921/8000, Loss: 0.126930609345.\n",
      "Iteration: 6922/8000, Loss: 0.126930594444.\n",
      "Iteration: 6923/8000, Loss: 0.126930594444.\n",
      "Iteration: 6924/8000, Loss: 0.126930594444.\n",
      "Iteration: 6925/8000, Loss: 0.126930594444.\n",
      "Iteration: 6926/8000, Loss: 0.126930594444.\n",
      "Iteration: 6927/8000, Loss: 0.126930594444.\n",
      "Iteration: 6928/8000, Loss: 0.126930594444.\n",
      "Iteration: 6929/8000, Loss: 0.126930594444.\n",
      "Iteration: 6930/8000, Loss: 0.126930594444.\n",
      "Iteration: 6931/8000, Loss: 0.126930594444.\n",
      "Iteration: 6932/8000, Loss: 0.126930594444.\n",
      "Iteration: 6933/8000, Loss: 0.126930579543.\n",
      "Iteration: 6934/8000, Loss: 0.126930579543.\n",
      "Iteration: 6935/8000, Loss: 0.126930579543.\n",
      "Iteration: 6936/8000, Loss: 0.126930579543.\n",
      "Iteration: 6937/8000, Loss: 0.126930594444.\n",
      "Iteration: 6938/8000, Loss: 0.126930579543.\n",
      "Iteration: 6939/8000, Loss: 0.126930579543.\n",
      "Iteration: 6940/8000, Loss: 0.126930579543.\n",
      "Iteration: 6941/8000, Loss: 0.126930564642.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6942/8000, Loss: 0.126930564642.\n",
      "Iteration: 6943/8000, Loss: 0.126930564642.\n",
      "Iteration: 6944/8000, Loss: 0.126930564642.\n",
      "Iteration: 6945/8000, Loss: 0.126930564642.\n",
      "Iteration: 6946/8000, Loss: 0.126930564642.\n",
      "Iteration: 6947/8000, Loss: 0.126930564642.\n",
      "Iteration: 6948/8000, Loss: 0.126930564642.\n",
      "Iteration: 6949/8000, Loss: 0.126930564642.\n",
      "Iteration: 6950/8000, Loss: 0.126930564642.\n",
      "Iteration: 6951/8000, Loss: 0.126930564642.\n",
      "Iteration: 6952/8000, Loss: 0.126930564642.\n",
      "Iteration: 6953/8000, Loss: 0.126930564642.\n",
      "Iteration: 6954/8000, Loss: 0.126930549741.\n",
      "Iteration: 6955/8000, Loss: 0.126930549741.\n",
      "Iteration: 6956/8000, Loss: 0.126930549741.\n",
      "Iteration: 6957/8000, Loss: 0.126930549741.\n",
      "Iteration: 6958/8000, Loss: 0.126930549741.\n",
      "Iteration: 6959/8000, Loss: 0.126930549741.\n",
      "Iteration: 6960/8000, Loss: 0.12693053484.\n",
      "Iteration: 6961/8000, Loss: 0.126930549741.\n",
      "Iteration: 6962/8000, Loss: 0.12693053484.\n",
      "Iteration: 6963/8000, Loss: 0.12693053484.\n",
      "Iteration: 6964/8000, Loss: 0.12693053484.\n",
      "Iteration: 6965/8000, Loss: 0.126930549741.\n",
      "Iteration: 6966/8000, Loss: 0.12693053484.\n",
      "Iteration: 6967/8000, Loss: 0.12693053484.\n",
      "Iteration: 6968/8000, Loss: 0.12693053484.\n",
      "Iteration: 6969/8000, Loss: 0.12693053484.\n",
      "Iteration: 6970/8000, Loss: 0.12693053484.\n",
      "Iteration: 6971/8000, Loss: 0.12693053484.\n",
      "Iteration: 6972/8000, Loss: 0.12693053484.\n",
      "Iteration: 6973/8000, Loss: 0.126930519938.\n",
      "Iteration: 6974/8000, Loss: 0.12693053484.\n",
      "Iteration: 6975/8000, Loss: 0.12693053484.\n",
      "Iteration: 6976/8000, Loss: 0.12693053484.\n",
      "Iteration: 6977/8000, Loss: 0.12693053484.\n",
      "Iteration: 6978/8000, Loss: 0.12693053484.\n",
      "Iteration: 6979/8000, Loss: 0.12693053484.\n",
      "Iteration: 6980/8000, Loss: 0.126930519938.\n",
      "Iteration: 6981/8000, Loss: 0.126930519938.\n",
      "Iteration: 6982/8000, Loss: 0.126930519938.\n",
      "Iteration: 6983/8000, Loss: 0.126930519938.\n",
      "Iteration: 6984/8000, Loss: 0.126930519938.\n",
      "Iteration: 6985/8000, Loss: 0.126930519938.\n",
      "Iteration: 6986/8000, Loss: 0.126930519938.\n",
      "Iteration: 6987/8000, Loss: 0.126930505037.\n",
      "Iteration: 6988/8000, Loss: 0.126930505037.\n",
      "Iteration: 6989/8000, Loss: 0.126930505037.\n",
      "Iteration: 6990/8000, Loss: 0.126930505037.\n",
      "Iteration: 6991/8000, Loss: 0.126930505037.\n",
      "Iteration: 6992/8000, Loss: 0.126930505037.\n",
      "Iteration: 6993/8000, Loss: 0.126930505037.\n",
      "Iteration: 6994/8000, Loss: 0.126930505037.\n",
      "Iteration: 6995/8000, Loss: 0.126930505037.\n",
      "Iteration: 6996/8000, Loss: 0.126930490136.\n",
      "Iteration: 6997/8000, Loss: 0.126930490136.\n",
      "Iteration: 6998/8000, Loss: 0.126930505037.\n",
      "Iteration: 6999/8000, Loss: 0.126930490136.\n",
      "Iteration: 7000/8000, Loss: 0.126930490136.\n",
      "Iteration: 7001/8000, Loss: 0.126930490136.\n",
      "Iteration: 7002/8000, Loss: 0.126930475235.\n",
      "Iteration: 7003/8000, Loss: 0.126930475235.\n",
      "Iteration: 7004/8000, Loss: 0.126930475235.\n",
      "Iteration: 7005/8000, Loss: 0.126930490136.\n",
      "Iteration: 7006/8000, Loss: 0.126930475235.\n",
      "Iteration: 7007/8000, Loss: 0.126930475235.\n",
      "Iteration: 7008/8000, Loss: 0.126930490136.\n",
      "Iteration: 7009/8000, Loss: 0.126930475235.\n",
      "Iteration: 7010/8000, Loss: 0.126930475235.\n",
      "Iteration: 7011/8000, Loss: 0.126930475235.\n",
      "Iteration: 7012/8000, Loss: 0.126930475235.\n",
      "Iteration: 7013/8000, Loss: 0.126930475235.\n",
      "Iteration: 7014/8000, Loss: 0.126930475235.\n",
      "Iteration: 7015/8000, Loss: 0.126930475235.\n",
      "Iteration: 7016/8000, Loss: 0.126930460334.\n",
      "Iteration: 7017/8000, Loss: 0.126930475235.\n",
      "Iteration: 7018/8000, Loss: 0.126930460334.\n",
      "Iteration: 7019/8000, Loss: 0.126930460334.\n",
      "Iteration: 7020/8000, Loss: 0.126930460334.\n",
      "Iteration: 7021/8000, Loss: 0.126930460334.\n",
      "Iteration: 7022/8000, Loss: 0.126930460334.\n",
      "Iteration: 7023/8000, Loss: 0.126930460334.\n",
      "Iteration: 7024/8000, Loss: 0.126930460334.\n",
      "Iteration: 7025/8000, Loss: 0.126930460334.\n",
      "Iteration: 7026/8000, Loss: 0.126930445433.\n",
      "Iteration: 7027/8000, Loss: 0.126930445433.\n",
      "Iteration: 7028/8000, Loss: 0.126930460334.\n",
      "Iteration: 7029/8000, Loss: 0.126930445433.\n",
      "Iteration: 7030/8000, Loss: 0.126930445433.\n",
      "Iteration: 7031/8000, Loss: 0.126930445433.\n",
      "Iteration: 7032/8000, Loss: 0.126930460334.\n",
      "Iteration: 7033/8000, Loss: 0.126930445433.\n",
      "Iteration: 7034/8000, Loss: 0.126930445433.\n",
      "Iteration: 7035/8000, Loss: 0.126930445433.\n",
      "Iteration: 7036/8000, Loss: 0.126930445433.\n",
      "Iteration: 7037/8000, Loss: 0.126930445433.\n",
      "Iteration: 7038/8000, Loss: 0.126930445433.\n",
      "Iteration: 7039/8000, Loss: 0.126930430532.\n",
      "Iteration: 7040/8000, Loss: 0.126930430532.\n",
      "Iteration: 7041/8000, Loss: 0.126930430532.\n",
      "Iteration: 7042/8000, Loss: 0.126930430532.\n",
      "Iteration: 7043/8000, Loss: 0.126930430532.\n",
      "Iteration: 7044/8000, Loss: 0.126930430532.\n",
      "Iteration: 7045/8000, Loss: 0.126930430532.\n",
      "Iteration: 7046/8000, Loss: 0.126930430532.\n",
      "Iteration: 7047/8000, Loss: 0.126930430532.\n",
      "Iteration: 7048/8000, Loss: 0.126930430532.\n",
      "Iteration: 7049/8000, Loss: 0.126930430532.\n",
      "Iteration: 7050/8000, Loss: 0.126930430532.\n",
      "Iteration: 7051/8000, Loss: 0.126930430532.\n",
      "Iteration: 7052/8000, Loss: 0.126930430532.\n",
      "Iteration: 7053/8000, Loss: 0.126930430532.\n",
      "Iteration: 7054/8000, Loss: 0.126930430532.\n",
      "Iteration: 7055/8000, Loss: 0.126930430532.\n",
      "Iteration: 7056/8000, Loss: 0.12693041563.\n",
      "Iteration: 7057/8000, Loss: 0.12693041563.\n",
      "Iteration: 7058/8000, Loss: 0.12693041563.\n",
      "Iteration: 7059/8000, Loss: 0.12693041563.\n",
      "Iteration: 7060/8000, Loss: 0.12693041563.\n",
      "Iteration: 7061/8000, Loss: 0.12693041563.\n",
      "Iteration: 7062/8000, Loss: 0.12693041563.\n",
      "Iteration: 7063/8000, Loss: 0.12693041563.\n",
      "Iteration: 7064/8000, Loss: 0.12693041563.\n",
      "Iteration: 7065/8000, Loss: 0.12693041563.\n",
      "Iteration: 7066/8000, Loss: 0.126930400729.\n",
      "Iteration: 7067/8000, Loss: 0.126930400729.\n",
      "Iteration: 7068/8000, Loss: 0.126930400729.\n",
      "Iteration: 7069/8000, Loss: 0.126930400729.\n",
      "Iteration: 7070/8000, Loss: 0.126930400729.\n",
      "Iteration: 7071/8000, Loss: 0.126930385828.\n",
      "Iteration: 7072/8000, Loss: 0.126930400729.\n",
      "Iteration: 7073/8000, Loss: 0.126930385828.\n",
      "Iteration: 7074/8000, Loss: 0.126930400729.\n",
      "Iteration: 7075/8000, Loss: 0.126930385828.\n",
      "Iteration: 7076/8000, Loss: 0.126930385828.\n",
      "Iteration: 7077/8000, Loss: 0.126930385828.\n",
      "Iteration: 7078/8000, Loss: 0.126930385828.\n",
      "Iteration: 7079/8000, Loss: 0.126930385828.\n",
      "Iteration: 7080/8000, Loss: 0.126930385828.\n",
      "Iteration: 7081/8000, Loss: 0.126930385828.\n",
      "Iteration: 7082/8000, Loss: 0.126930385828.\n",
      "Iteration: 7083/8000, Loss: 0.126930385828.\n",
      "Iteration: 7084/8000, Loss: 0.126930385828.\n",
      "Iteration: 7085/8000, Loss: 0.126930385828.\n",
      "Iteration: 7086/8000, Loss: 0.126930385828.\n",
      "Iteration: 7087/8000, Loss: 0.126930370927.\n",
      "Iteration: 7088/8000, Loss: 0.126930370927.\n",
      "Iteration: 7089/8000, Loss: 0.126930370927.\n",
      "Iteration: 7090/8000, Loss: 0.126930370927.\n",
      "Iteration: 7091/8000, Loss: 0.126930370927.\n",
      "Iteration: 7092/8000, Loss: 0.126930370927.\n",
      "Iteration: 7093/8000, Loss: 0.126930370927.\n",
      "Iteration: 7094/8000, Loss: 0.126930356026.\n",
      "Iteration: 7095/8000, Loss: 0.126930356026.\n",
      "Iteration: 7096/8000, Loss: 0.126930356026.\n",
      "Iteration: 7097/8000, Loss: 0.126930356026.\n",
      "Iteration: 7098/8000, Loss: 0.126930356026.\n",
      "Iteration: 7099/8000, Loss: 0.126930356026.\n",
      "Iteration: 7100/8000, Loss: 0.126930356026.\n",
      "Iteration: 7101/8000, Loss: 0.126930356026.\n",
      "Iteration: 7102/8000, Loss: 0.126930356026.\n",
      "Iteration: 7103/8000, Loss: 0.126930356026.\n",
      "Iteration: 7104/8000, Loss: 0.126930356026.\n",
      "Iteration: 7105/8000, Loss: 0.126930356026.\n",
      "Iteration: 7106/8000, Loss: 0.126930356026.\n",
      "Iteration: 7107/8000, Loss: 0.126930356026.\n",
      "Iteration: 7108/8000, Loss: 0.126930356026.\n",
      "Iteration: 7109/8000, Loss: 0.126930356026.\n",
      "Iteration: 7110/8000, Loss: 0.126930341125.\n",
      "Iteration: 7111/8000, Loss: 0.126930341125.\n",
      "Iteration: 7112/8000, Loss: 0.126930341125.\n",
      "Iteration: 7113/8000, Loss: 0.126930356026.\n",
      "Iteration: 7114/8000, Loss: 0.126930341125.\n",
      "Iteration: 7115/8000, Loss: 0.126930341125.\n",
      "Iteration: 7116/8000, Loss: 0.126930341125.\n",
      "Iteration: 7117/8000, Loss: 0.126930341125.\n",
      "Iteration: 7118/8000, Loss: 0.126930341125.\n",
      "Iteration: 7119/8000, Loss: 0.126930341125.\n",
      "Iteration: 7120/8000, Loss: 0.126930341125.\n",
      "Iteration: 7121/8000, Loss: 0.126930341125.\n",
      "Iteration: 7122/8000, Loss: 0.126930341125.\n",
      "Iteration: 7123/8000, Loss: 0.126930326223.\n",
      "Iteration: 7124/8000, Loss: 0.126930326223.\n",
      "Iteration: 7125/8000, Loss: 0.126930326223.\n",
      "Iteration: 7126/8000, Loss: 0.126930326223.\n",
      "Iteration: 7127/8000, Loss: 0.126930326223.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 7128/8000, Loss: 0.126930326223.\n",
      "Iteration: 7129/8000, Loss: 0.126930326223.\n",
      "Iteration: 7130/8000, Loss: 0.126930326223.\n",
      "Iteration: 7131/8000, Loss: 0.126930326223.\n",
      "Iteration: 7132/8000, Loss: 0.126930326223.\n",
      "Iteration: 7133/8000, Loss: 0.126930326223.\n",
      "Iteration: 7134/8000, Loss: 0.126930326223.\n",
      "Iteration: 7135/8000, Loss: 0.126930326223.\n",
      "Iteration: 7136/8000, Loss: 0.126930326223.\n",
      "Iteration: 7137/8000, Loss: 0.126930326223.\n",
      "Iteration: 7138/8000, Loss: 0.126930326223.\n",
      "Iteration: 7139/8000, Loss: 0.126930311322.\n",
      "Iteration: 7140/8000, Loss: 0.126930326223.\n",
      "Iteration: 7141/8000, Loss: 0.126930326223.\n",
      "Iteration: 7142/8000, Loss: 0.126930311322.\n",
      "Iteration: 7143/8000, Loss: 0.126930326223.\n",
      "Iteration: 7144/8000, Loss: 0.126930296421.\n",
      "Iteration: 7145/8000, Loss: 0.126930296421.\n",
      "Iteration: 7146/8000, Loss: 0.126930296421.\n",
      "Iteration: 7147/8000, Loss: 0.126930296421.\n",
      "Iteration: 7148/8000, Loss: 0.126930296421.\n",
      "Iteration: 7149/8000, Loss: 0.126930296421.\n",
      "Iteration: 7150/8000, Loss: 0.126930296421.\n",
      "Iteration: 7151/8000, Loss: 0.126930296421.\n",
      "Iteration: 7152/8000, Loss: 0.126930296421.\n",
      "Iteration: 7153/8000, Loss: 0.126930296421.\n",
      "Iteration: 7154/8000, Loss: 0.126930296421.\n",
      "Iteration: 7155/8000, Loss: 0.126930296421.\n",
      "Iteration: 7156/8000, Loss: 0.126930296421.\n",
      "Iteration: 7157/8000, Loss: 0.126930296421.\n",
      "Iteration: 7158/8000, Loss: 0.126930296421.\n",
      "Iteration: 7159/8000, Loss: 0.126930296421.\n",
      "Iteration: 7160/8000, Loss: 0.12693028152.\n",
      "Iteration: 7161/8000, Loss: 0.126930266619.\n",
      "Iteration: 7162/8000, Loss: 0.12693028152.\n",
      "Iteration: 7163/8000, Loss: 0.12693028152.\n",
      "Iteration: 7164/8000, Loss: 0.12693028152.\n",
      "Iteration: 7165/8000, Loss: 0.126930266619.\n",
      "Iteration: 7166/8000, Loss: 0.126930266619.\n",
      "Iteration: 7167/8000, Loss: 0.126930266619.\n",
      "Iteration: 7168/8000, Loss: 0.12693028152.\n",
      "Iteration: 7169/8000, Loss: 0.12693028152.\n",
      "Iteration: 7170/8000, Loss: 0.126930266619.\n",
      "Iteration: 7171/8000, Loss: 0.12693028152.\n",
      "Iteration: 7172/8000, Loss: 0.12693028152.\n",
      "Iteration: 7173/8000, Loss: 0.126930266619.\n",
      "Iteration: 7174/8000, Loss: 0.126930266619.\n",
      "Iteration: 7175/8000, Loss: 0.126930266619.\n",
      "Iteration: 7176/8000, Loss: 0.126930266619.\n",
      "Iteration: 7177/8000, Loss: 0.126930251718.\n",
      "Iteration: 7178/8000, Loss: 0.126930266619.\n",
      "Iteration: 7179/8000, Loss: 0.126930251718.\n",
      "Iteration: 7180/8000, Loss: 0.126930251718.\n",
      "Iteration: 7181/8000, Loss: 0.126930266619.\n",
      "Iteration: 7182/8000, Loss: 0.126930251718.\n",
      "Iteration: 7183/8000, Loss: 0.126930251718.\n",
      "Iteration: 7184/8000, Loss: 0.126930251718.\n",
      "Iteration: 7185/8000, Loss: 0.126930251718.\n",
      "Iteration: 7186/8000, Loss: 0.126930251718.\n",
      "Iteration: 7187/8000, Loss: 0.126930251718.\n",
      "Iteration: 7188/8000, Loss: 0.126930251718.\n",
      "Iteration: 7189/8000, Loss: 0.126930251718.\n",
      "Iteration: 7190/8000, Loss: 0.126930251718.\n",
      "Iteration: 7191/8000, Loss: 0.126930251718.\n",
      "Iteration: 7192/8000, Loss: 0.126930251718.\n",
      "Iteration: 7193/8000, Loss: 0.126930251718.\n",
      "Iteration: 7194/8000, Loss: 0.126930251718.\n",
      "Iteration: 7195/8000, Loss: 0.126930251718.\n",
      "Iteration: 7196/8000, Loss: 0.126930251718.\n",
      "Iteration: 7197/8000, Loss: 0.126930251718.\n",
      "Iteration: 7198/8000, Loss: 0.126930251718.\n",
      "Iteration: 7199/8000, Loss: 0.126930236816.\n",
      "Iteration: 7200/8000, Loss: 0.126930236816.\n",
      "Iteration: 7201/8000, Loss: 0.126930236816.\n",
      "Iteration: 7202/8000, Loss: 0.126930236816.\n",
      "Iteration: 7203/8000, Loss: 0.126930236816.\n",
      "Iteration: 7204/8000, Loss: 0.126930236816.\n",
      "Iteration: 7205/8000, Loss: 0.126930236816.\n",
      "Iteration: 7206/8000, Loss: 0.126930236816.\n",
      "Iteration: 7207/8000, Loss: 0.126930221915.\n",
      "Iteration: 7208/8000, Loss: 0.126930236816.\n",
      "Iteration: 7209/8000, Loss: 0.126930221915.\n",
      "Iteration: 7210/8000, Loss: 0.126930221915.\n",
      "Iteration: 7211/8000, Loss: 0.126930221915.\n",
      "Iteration: 7212/8000, Loss: 0.126930221915.\n",
      "Iteration: 7213/8000, Loss: 0.126930221915.\n",
      "Iteration: 7214/8000, Loss: 0.126930221915.\n",
      "Iteration: 7215/8000, Loss: 0.126930221915.\n",
      "Iteration: 7216/8000, Loss: 0.126930221915.\n",
      "Iteration: 7217/8000, Loss: 0.126930221915.\n",
      "Iteration: 7218/8000, Loss: 0.126930221915.\n",
      "Iteration: 7219/8000, Loss: 0.126930221915.\n",
      "Iteration: 7220/8000, Loss: 0.126930221915.\n",
      "Iteration: 7221/8000, Loss: 0.126930221915.\n",
      "Iteration: 7222/8000, Loss: 0.126930207014.\n",
      "Iteration: 7223/8000, Loss: 0.126930207014.\n",
      "Iteration: 7224/8000, Loss: 0.126930207014.\n",
      "Iteration: 7225/8000, Loss: 0.126930207014.\n",
      "Iteration: 7226/8000, Loss: 0.126930207014.\n",
      "Iteration: 7227/8000, Loss: 0.126930207014.\n",
      "Iteration: 7228/8000, Loss: 0.126930207014.\n",
      "Iteration: 7229/8000, Loss: 0.126930207014.\n",
      "Iteration: 7230/8000, Loss: 0.126930207014.\n",
      "Iteration: 7231/8000, Loss: 0.126930207014.\n",
      "Iteration: 7232/8000, Loss: 0.126930207014.\n",
      "Iteration: 7233/8000, Loss: 0.126930192113.\n",
      "Iteration: 7234/8000, Loss: 0.126930207014.\n",
      "Iteration: 7235/8000, Loss: 0.126930207014.\n",
      "Iteration: 7236/8000, Loss: 0.126930192113.\n",
      "Iteration: 7237/8000, Loss: 0.126930192113.\n",
      "Iteration: 7238/8000, Loss: 0.126930192113.\n",
      "Iteration: 7239/8000, Loss: 0.126930177212.\n",
      "Iteration: 7240/8000, Loss: 0.126930177212.\n",
      "Iteration: 7241/8000, Loss: 0.126930192113.\n",
      "Iteration: 7242/8000, Loss: 0.126930177212.\n",
      "Iteration: 7243/8000, Loss: 0.126930192113.\n",
      "Iteration: 7244/8000, Loss: 0.126930177212.\n",
      "Iteration: 7245/8000, Loss: 0.126930177212.\n",
      "Iteration: 7246/8000, Loss: 0.126930177212.\n",
      "Iteration: 7247/8000, Loss: 0.126930177212.\n",
      "Iteration: 7248/8000, Loss: 0.126930177212.\n",
      "Iteration: 7249/8000, Loss: 0.126930162311.\n",
      "Iteration: 7250/8000, Loss: 0.126930162311.\n",
      "Iteration: 7251/8000, Loss: 0.126930162311.\n",
      "Iteration: 7252/8000, Loss: 0.126930177212.\n",
      "Iteration: 7253/8000, Loss: 0.126930162311.\n",
      "Iteration: 7254/8000, Loss: 0.126930177212.\n",
      "Iteration: 7255/8000, Loss: 0.126930162311.\n",
      "Iteration: 7256/8000, Loss: 0.126930162311.\n",
      "Iteration: 7257/8000, Loss: 0.126930162311.\n",
      "Iteration: 7258/8000, Loss: 0.126930162311.\n",
      "Iteration: 7259/8000, Loss: 0.126930162311.\n",
      "Iteration: 7260/8000, Loss: 0.126930162311.\n",
      "Iteration: 7261/8000, Loss: 0.126930162311.\n",
      "Iteration: 7262/8000, Loss: 0.126930162311.\n",
      "Iteration: 7263/8000, Loss: 0.126930162311.\n",
      "Iteration: 7264/8000, Loss: 0.126930162311.\n",
      "Iteration: 7265/8000, Loss: 0.126930162311.\n",
      "Iteration: 7266/8000, Loss: 0.126930162311.\n",
      "Iteration: 7267/8000, Loss: 0.126930147409.\n",
      "Iteration: 7268/8000, Loss: 0.126930162311.\n",
      "Iteration: 7269/8000, Loss: 0.126930147409.\n",
      "Iteration: 7270/8000, Loss: 0.126930147409.\n",
      "Iteration: 7271/8000, Loss: 0.126930162311.\n",
      "Iteration: 7272/8000, Loss: 0.126930147409.\n",
      "Iteration: 7273/8000, Loss: 0.126930147409.\n",
      "Iteration: 7274/8000, Loss: 0.126930147409.\n",
      "Iteration: 7275/8000, Loss: 0.126930147409.\n",
      "Iteration: 7276/8000, Loss: 0.126930147409.\n",
      "Iteration: 7277/8000, Loss: 0.126930147409.\n",
      "Iteration: 7278/8000, Loss: 0.126930147409.\n",
      "Iteration: 7279/8000, Loss: 0.126930147409.\n",
      "Iteration: 7280/8000, Loss: 0.126930147409.\n",
      "Iteration: 7281/8000, Loss: 0.126930147409.\n",
      "Iteration: 7282/8000, Loss: 0.126930147409.\n",
      "Iteration: 7283/8000, Loss: 0.126930147409.\n",
      "Iteration: 7284/8000, Loss: 0.126930132508.\n",
      "Iteration: 7285/8000, Loss: 0.126930132508.\n",
      "Iteration: 7286/8000, Loss: 0.126930132508.\n",
      "Iteration: 7287/8000, Loss: 0.126930132508.\n",
      "Iteration: 7288/8000, Loss: 0.126930132508.\n",
      "Iteration: 7289/8000, Loss: 0.126930117607.\n",
      "Iteration: 7290/8000, Loss: 0.126930132508.\n",
      "Iteration: 7291/8000, Loss: 0.126930117607.\n",
      "Iteration: 7292/8000, Loss: 0.126930117607.\n",
      "Iteration: 7293/8000, Loss: 0.126930117607.\n",
      "Iteration: 7294/8000, Loss: 0.126930132508.\n",
      "Iteration: 7295/8000, Loss: 0.126930117607.\n",
      "Iteration: 7296/8000, Loss: 0.126930117607.\n",
      "Iteration: 7297/8000, Loss: 0.126930117607.\n",
      "Iteration: 7298/8000, Loss: 0.126930117607.\n",
      "Iteration: 7299/8000, Loss: 0.126930117607.\n",
      "Iteration: 7300/8000, Loss: 0.126930117607.\n",
      "Iteration: 7301/8000, Loss: 0.126930102706.\n",
      "Iteration: 7302/8000, Loss: 0.126930117607.\n",
      "Iteration: 7303/8000, Loss: 0.126930117607.\n",
      "Iteration: 7304/8000, Loss: 0.126930117607.\n",
      "Iteration: 7305/8000, Loss: 0.126930102706.\n",
      "Iteration: 7306/8000, Loss: 0.126930102706.\n",
      "Iteration: 7307/8000, Loss: 0.126930102706.\n",
      "Iteration: 7308/8000, Loss: 0.126930102706.\n",
      "Iteration: 7309/8000, Loss: 0.126930102706.\n",
      "Iteration: 7310/8000, Loss: 0.126930117607.\n",
      "Iteration: 7311/8000, Loss: 0.126930102706.\n",
      "Iteration: 7312/8000, Loss: 0.126930102706.\n",
      "Iteration: 7313/8000, Loss: 0.126930102706.\n",
      "Iteration: 7314/8000, Loss: 0.126930102706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 7315/8000, Loss: 0.126930087805.\n",
      "Iteration: 7316/8000, Loss: 0.126930087805.\n",
      "Iteration: 7317/8000, Loss: 0.126930087805.\n",
      "Iteration: 7318/8000, Loss: 0.126930087805.\n",
      "Iteration: 7319/8000, Loss: 0.126930087805.\n",
      "Iteration: 7320/8000, Loss: 0.126930087805.\n",
      "Iteration: 7321/8000, Loss: 0.126930087805.\n",
      "Iteration: 7322/8000, Loss: 0.126930087805.\n",
      "Iteration: 7323/8000, Loss: 0.126930087805.\n",
      "Iteration: 7324/8000, Loss: 0.126930087805.\n",
      "Iteration: 7325/8000, Loss: 0.126930087805.\n",
      "Iteration: 7326/8000, Loss: 0.126930087805.\n",
      "Iteration: 7327/8000, Loss: 0.126930087805.\n",
      "Iteration: 7328/8000, Loss: 0.126930087805.\n",
      "Iteration: 7329/8000, Loss: 0.126930087805.\n",
      "Iteration: 7330/8000, Loss: 0.126930087805.\n",
      "Iteration: 7331/8000, Loss: 0.126930087805.\n",
      "Iteration: 7332/8000, Loss: 0.126930087805.\n",
      "Iteration: 7333/8000, Loss: 0.126930087805.\n",
      "Iteration: 7334/8000, Loss: 0.126930087805.\n",
      "Iteration: 7335/8000, Loss: 0.126930087805.\n",
      "Iteration: 7336/8000, Loss: 0.126930072904.\n",
      "Iteration: 7337/8000, Loss: 0.126930072904.\n",
      "Iteration: 7338/8000, Loss: 0.126930072904.\n",
      "Iteration: 7339/8000, Loss: 0.126930058002.\n",
      "Iteration: 7340/8000, Loss: 0.126930058002.\n",
      "Iteration: 7341/8000, Loss: 0.126930058002.\n",
      "Iteration: 7342/8000, Loss: 0.126930058002.\n",
      "Iteration: 7343/8000, Loss: 0.126930072904.\n",
      "Iteration: 7344/8000, Loss: 0.126930058002.\n",
      "Iteration: 7345/8000, Loss: 0.126930058002.\n",
      "Iteration: 7346/8000, Loss: 0.126930058002.\n",
      "Iteration: 7347/8000, Loss: 0.126930058002.\n",
      "Iteration: 7348/8000, Loss: 0.126930058002.\n",
      "Iteration: 7349/8000, Loss: 0.126930058002.\n",
      "Iteration: 7350/8000, Loss: 0.126930058002.\n",
      "Iteration: 7351/8000, Loss: 0.126930058002.\n",
      "Iteration: 7352/8000, Loss: 0.126930058002.\n",
      "Iteration: 7353/8000, Loss: 0.126930058002.\n",
      "Iteration: 7354/8000, Loss: 0.126930058002.\n",
      "Iteration: 7355/8000, Loss: 0.126930043101.\n",
      "Iteration: 7356/8000, Loss: 0.126930058002.\n",
      "Iteration: 7357/8000, Loss: 0.126930058002.\n",
      "Iteration: 7358/8000, Loss: 0.126930058002.\n",
      "Iteration: 7359/8000, Loss: 0.126930058002.\n",
      "Iteration: 7360/8000, Loss: 0.126930058002.\n",
      "Iteration: 7361/8000, Loss: 0.126930043101.\n",
      "Iteration: 7362/8000, Loss: 0.126930058002.\n",
      "Iteration: 7363/8000, Loss: 0.126930043101.\n",
      "Iteration: 7364/8000, Loss: 0.126930043101.\n",
      "Iteration: 7365/8000, Loss: 0.126930043101.\n",
      "Iteration: 7366/8000, Loss: 0.126930043101.\n",
      "Iteration: 7367/8000, Loss: 0.126930043101.\n",
      "Iteration: 7368/8000, Loss: 0.126930043101.\n",
      "Iteration: 7369/8000, Loss: 0.126930043101.\n",
      "Iteration: 7370/8000, Loss: 0.126930043101.\n",
      "Iteration: 7371/8000, Loss: 0.126930043101.\n",
      "Iteration: 7372/8000, Loss: 0.126930043101.\n",
      "Iteration: 7373/8000, Loss: 0.126930043101.\n",
      "Iteration: 7374/8000, Loss: 0.126930043101.\n",
      "Iteration: 7375/8000, Loss: 0.126930043101.\n",
      "Iteration: 7376/8000, Loss: 0.126930043101.\n",
      "Iteration: 7377/8000, Loss: 0.126930043101.\n",
      "Iteration: 7378/8000, Loss: 0.126930043101.\n",
      "Iteration: 7379/8000, Loss: 0.126930043101.\n",
      "Iteration: 7380/8000, Loss: 0.126930043101.\n",
      "Iteration: 7381/8000, Loss: 0.126930043101.\n",
      "Iteration: 7382/8000, Loss: 0.126930043101.\n",
      "Iteration: 7383/8000, Loss: 0.126930043101.\n",
      "Iteration: 7384/8000, Loss: 0.126930043101.\n",
      "Iteration: 7385/8000, Loss: 0.126930043101.\n",
      "Iteration: 7386/8000, Loss: 0.1269300282.\n",
      "Iteration: 7387/8000, Loss: 0.126930043101.\n",
      "Iteration: 7388/8000, Loss: 0.1269300282.\n",
      "Iteration: 7389/8000, Loss: 0.1269300282.\n",
      "Iteration: 7390/8000, Loss: 0.1269300282.\n",
      "Iteration: 7391/8000, Loss: 0.1269300282.\n",
      "Iteration: 7392/8000, Loss: 0.126930013299.\n",
      "Iteration: 7393/8000, Loss: 0.126930013299.\n",
      "Iteration: 7394/8000, Loss: 0.1269300282.\n",
      "Iteration: 7395/8000, Loss: 0.126930013299.\n",
      "Iteration: 7396/8000, Loss: 0.126930013299.\n",
      "Iteration: 7397/8000, Loss: 0.126930013299.\n",
      "Iteration: 7398/8000, Loss: 0.126929998398.\n",
      "Iteration: 7399/8000, Loss: 0.126930013299.\n",
      "Iteration: 7400/8000, Loss: 0.126930013299.\n",
      "Iteration: 7401/8000, Loss: 0.126930013299.\n",
      "Iteration: 7402/8000, Loss: 0.126930013299.\n",
      "Iteration: 7403/8000, Loss: 0.126930013299.\n",
      "Iteration: 7404/8000, Loss: 0.126930013299.\n",
      "Iteration: 7405/8000, Loss: 0.126930013299.\n",
      "Iteration: 7406/8000, Loss: 0.126930013299.\n",
      "Iteration: 7407/8000, Loss: 0.126930013299.\n",
      "Iteration: 7408/8000, Loss: 0.126929998398.\n",
      "Iteration: 7409/8000, Loss: 0.126929983497.\n",
      "Iteration: 7410/8000, Loss: 0.126929998398.\n",
      "Iteration: 7411/8000, Loss: 0.126929998398.\n",
      "Iteration: 7412/8000, Loss: 0.126930013299.\n",
      "Iteration: 7413/8000, Loss: 0.126930013299.\n",
      "Iteration: 7414/8000, Loss: 0.126929998398.\n",
      "Iteration: 7415/8000, Loss: 0.126929998398.\n",
      "Iteration: 7416/8000, Loss: 0.126929998398.\n",
      "Iteration: 7417/8000, Loss: 0.126929998398.\n",
      "Iteration: 7418/8000, Loss: 0.126929998398.\n",
      "Iteration: 7419/8000, Loss: 0.126929998398.\n",
      "Iteration: 7420/8000, Loss: 0.126929983497.\n",
      "Iteration: 7421/8000, Loss: 0.126929998398.\n",
      "Iteration: 7422/8000, Loss: 0.126929983497.\n",
      "Iteration: 7423/8000, Loss: 0.126929983497.\n",
      "Iteration: 7424/8000, Loss: 0.126929968596.\n",
      "Iteration: 7425/8000, Loss: 0.126929968596.\n",
      "Iteration: 7426/8000, Loss: 0.126929968596.\n",
      "Iteration: 7427/8000, Loss: 0.126929968596.\n",
      "Iteration: 7428/8000, Loss: 0.126929968596.\n",
      "Iteration: 7429/8000, Loss: 0.126929983497.\n",
      "Iteration: 7430/8000, Loss: 0.126929968596.\n",
      "Iteration: 7431/8000, Loss: 0.126929968596.\n",
      "Iteration: 7432/8000, Loss: 0.126929983497.\n",
      "Iteration: 7433/8000, Loss: 0.126929968596.\n",
      "Iteration: 7434/8000, Loss: 0.126929968596.\n",
      "Iteration: 7435/8000, Loss: 0.126929968596.\n",
      "Iteration: 7436/8000, Loss: 0.126929968596.\n",
      "Iteration: 7437/8000, Loss: 0.126929968596.\n",
      "Iteration: 7438/8000, Loss: 0.126929968596.\n",
      "Iteration: 7439/8000, Loss: 0.126929968596.\n",
      "Iteration: 7440/8000, Loss: 0.126929968596.\n",
      "Iteration: 7441/8000, Loss: 0.126929968596.\n",
      "Iteration: 7442/8000, Loss: 0.126929968596.\n",
      "Iteration: 7443/8000, Loss: 0.126929968596.\n",
      "Iteration: 7444/8000, Loss: 0.126929953694.\n",
      "Iteration: 7445/8000, Loss: 0.126929968596.\n",
      "Iteration: 7446/8000, Loss: 0.126929953694.\n",
      "Iteration: 7447/8000, Loss: 0.126929968596.\n",
      "Iteration: 7448/8000, Loss: 0.126929953694.\n",
      "Iteration: 7449/8000, Loss: 0.126929953694.\n",
      "Iteration: 7450/8000, Loss: 0.126929953694.\n",
      "Iteration: 7451/8000, Loss: 0.126929953694.\n",
      "Iteration: 7452/8000, Loss: 0.126929953694.\n",
      "Iteration: 7453/8000, Loss: 0.126929953694.\n",
      "Iteration: 7454/8000, Loss: 0.126929953694.\n",
      "Iteration: 7455/8000, Loss: 0.126929953694.\n",
      "Iteration: 7456/8000, Loss: 0.126929938793.\n",
      "Iteration: 7457/8000, Loss: 0.126929938793.\n",
      "Iteration: 7458/8000, Loss: 0.126929938793.\n",
      "Iteration: 7459/8000, Loss: 0.126929938793.\n",
      "Iteration: 7460/8000, Loss: 0.126929938793.\n",
      "Iteration: 7461/8000, Loss: 0.126929938793.\n",
      "Iteration: 7462/8000, Loss: 0.126929938793.\n",
      "Iteration: 7463/8000, Loss: 0.126929938793.\n",
      "Iteration: 7464/8000, Loss: 0.126929938793.\n",
      "Iteration: 7465/8000, Loss: 0.126929938793.\n",
      "Iteration: 7466/8000, Loss: 0.126929938793.\n",
      "Iteration: 7467/8000, Loss: 0.126929938793.\n",
      "Iteration: 7468/8000, Loss: 0.126929938793.\n",
      "Iteration: 7469/8000, Loss: 0.126929938793.\n",
      "Iteration: 7470/8000, Loss: 0.126929938793.\n",
      "Iteration: 7471/8000, Loss: 0.126929938793.\n",
      "Iteration: 7472/8000, Loss: 0.126929938793.\n",
      "Iteration: 7473/8000, Loss: 0.126929938793.\n",
      "Iteration: 7474/8000, Loss: 0.126929938793.\n",
      "Iteration: 7475/8000, Loss: 0.126929938793.\n",
      "Iteration: 7476/8000, Loss: 0.126929938793.\n",
      "Iteration: 7477/8000, Loss: 0.126929938793.\n",
      "Iteration: 7478/8000, Loss: 0.126929938793.\n",
      "Iteration: 7479/8000, Loss: 0.126929923892.\n",
      "Iteration: 7480/8000, Loss: 0.126929923892.\n",
      "Iteration: 7481/8000, Loss: 0.126929923892.\n",
      "Iteration: 7482/8000, Loss: 0.126929923892.\n",
      "Iteration: 7483/8000, Loss: 0.126929923892.\n",
      "Iteration: 7484/8000, Loss: 0.126929923892.\n",
      "Iteration: 7485/8000, Loss: 0.126929923892.\n",
      "Iteration: 7486/8000, Loss: 0.126929923892.\n",
      "Iteration: 7487/8000, Loss: 0.126929923892.\n",
      "Iteration: 7488/8000, Loss: 0.126929923892.\n",
      "Iteration: 7489/8000, Loss: 0.126929923892.\n",
      "Iteration: 7490/8000, Loss: 0.126929923892.\n",
      "Iteration: 7491/8000, Loss: 0.126929923892.\n",
      "Iteration: 7492/8000, Loss: 0.126929923892.\n",
      "Iteration: 7493/8000, Loss: 0.126929923892.\n",
      "Iteration: 7494/8000, Loss: 0.126929908991.\n",
      "Iteration: 7495/8000, Loss: 0.126929923892.\n",
      "Iteration: 7496/8000, Loss: 0.126929908991.\n",
      "Iteration: 7497/8000, Loss: 0.126929923892.\n",
      "Iteration: 7498/8000, Loss: 0.126929908991.\n",
      "Iteration: 7499/8000, Loss: 0.126929908991.\n",
      "Iteration: 7500/8000, Loss: 0.126929908991.\n",
      "Iteration: 7501/8000, Loss: 0.126929908991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 7502/8000, Loss: 0.126929908991.\n",
      "Iteration: 7503/8000, Loss: 0.126929908991.\n",
      "Iteration: 7504/8000, Loss: 0.12692989409.\n",
      "Iteration: 7505/8000, Loss: 0.12692989409.\n",
      "Iteration: 7506/8000, Loss: 0.126929908991.\n",
      "Iteration: 7507/8000, Loss: 0.126929908991.\n",
      "Iteration: 7508/8000, Loss: 0.126929908991.\n",
      "Iteration: 7509/8000, Loss: 0.126929908991.\n",
      "Iteration: 7510/8000, Loss: 0.12692989409.\n",
      "Iteration: 7511/8000, Loss: 0.12692989409.\n",
      "Iteration: 7512/8000, Loss: 0.12692989409.\n",
      "Iteration: 7513/8000, Loss: 0.12692989409.\n",
      "Iteration: 7514/8000, Loss: 0.12692989409.\n",
      "Iteration: 7515/8000, Loss: 0.12692989409.\n",
      "Iteration: 7516/8000, Loss: 0.12692989409.\n",
      "Iteration: 7517/8000, Loss: 0.12692989409.\n",
      "Iteration: 7518/8000, Loss: 0.126929879189.\n",
      "Iteration: 7519/8000, Loss: 0.126929879189.\n",
      "Iteration: 7520/8000, Loss: 0.126929879189.\n",
      "Iteration: 7521/8000, Loss: 0.126929879189.\n",
      "Iteration: 7522/8000, Loss: 0.126929879189.\n",
      "Iteration: 7523/8000, Loss: 0.126929879189.\n",
      "Iteration: 7524/8000, Loss: 0.126929879189.\n",
      "Iteration: 7525/8000, Loss: 0.126929879189.\n",
      "Iteration: 7526/8000, Loss: 0.126929879189.\n",
      "Iteration: 7527/8000, Loss: 0.126929879189.\n",
      "Iteration: 7528/8000, Loss: 0.126929879189.\n",
      "Iteration: 7529/8000, Loss: 0.126929879189.\n",
      "Iteration: 7530/8000, Loss: 0.126929879189.\n",
      "Iteration: 7531/8000, Loss: 0.126929879189.\n",
      "Iteration: 7532/8000, Loss: 0.126929864287.\n",
      "Iteration: 7533/8000, Loss: 0.126929879189.\n",
      "Iteration: 7534/8000, Loss: 0.126929864287.\n",
      "Iteration: 7535/8000, Loss: 0.126929864287.\n",
      "Iteration: 7536/8000, Loss: 0.126929864287.\n",
      "Iteration: 7537/8000, Loss: 0.126929864287.\n",
      "Iteration: 7538/8000, Loss: 0.126929864287.\n",
      "Iteration: 7539/8000, Loss: 0.126929864287.\n",
      "Iteration: 7540/8000, Loss: 0.126929864287.\n",
      "Iteration: 7541/8000, Loss: 0.126929864287.\n",
      "Iteration: 7542/8000, Loss: 0.126929864287.\n",
      "Iteration: 7543/8000, Loss: 0.126929864287.\n",
      "Iteration: 7544/8000, Loss: 0.126929864287.\n",
      "Iteration: 7545/8000, Loss: 0.126929864287.\n",
      "Iteration: 7546/8000, Loss: 0.126929864287.\n",
      "Iteration: 7547/8000, Loss: 0.126929864287.\n",
      "Iteration: 7548/8000, Loss: 0.126929864287.\n",
      "Iteration: 7549/8000, Loss: 0.126929864287.\n",
      "Iteration: 7550/8000, Loss: 0.126929864287.\n",
      "Iteration: 7551/8000, Loss: 0.126929864287.\n",
      "Iteration: 7552/8000, Loss: 0.126929864287.\n",
      "Iteration: 7553/8000, Loss: 0.126929864287.\n",
      "Iteration: 7554/8000, Loss: 0.126929864287.\n",
      "Iteration: 7555/8000, Loss: 0.126929864287.\n",
      "Iteration: 7556/8000, Loss: 0.126929849386.\n",
      "Iteration: 7557/8000, Loss: 0.126929849386.\n",
      "Iteration: 7558/8000, Loss: 0.126929849386.\n",
      "Iteration: 7559/8000, Loss: 0.126929849386.\n",
      "Iteration: 7560/8000, Loss: 0.126929849386.\n",
      "Iteration: 7561/8000, Loss: 0.126929849386.\n",
      "Iteration: 7562/8000, Loss: 0.126929849386.\n",
      "Iteration: 7563/8000, Loss: 0.126929849386.\n",
      "Iteration: 7564/8000, Loss: 0.126929834485.\n",
      "Iteration: 7565/8000, Loss: 0.126929834485.\n",
      "Iteration: 7566/8000, Loss: 0.126929834485.\n",
      "Iteration: 7567/8000, Loss: 0.126929834485.\n",
      "Iteration: 7568/8000, Loss: 0.126929834485.\n",
      "Iteration: 7569/8000, Loss: 0.126929834485.\n",
      "Iteration: 7570/8000, Loss: 0.126929834485.\n",
      "Iteration: 7571/8000, Loss: 0.126929834485.\n",
      "Iteration: 7572/8000, Loss: 0.126929834485.\n",
      "Iteration: 7573/8000, Loss: 0.126929834485.\n",
      "Iteration: 7574/8000, Loss: 0.126929834485.\n",
      "Iteration: 7575/8000, Loss: 0.126929819584.\n",
      "Iteration: 7576/8000, Loss: 0.126929819584.\n",
      "Iteration: 7577/8000, Loss: 0.126929819584.\n",
      "Iteration: 7578/8000, Loss: 0.126929834485.\n",
      "Iteration: 7579/8000, Loss: 0.126929834485.\n",
      "Iteration: 7580/8000, Loss: 0.126929819584.\n",
      "Iteration: 7581/8000, Loss: 0.126929819584.\n",
      "Iteration: 7582/8000, Loss: 0.126929819584.\n",
      "Iteration: 7583/8000, Loss: 0.126929819584.\n",
      "Iteration: 7584/8000, Loss: 0.126929819584.\n",
      "Iteration: 7585/8000, Loss: 0.126929819584.\n",
      "Iteration: 7586/8000, Loss: 0.126929819584.\n",
      "Iteration: 7587/8000, Loss: 0.126929819584.\n",
      "Iteration: 7588/8000, Loss: 0.126929819584.\n",
      "Iteration: 7589/8000, Loss: 0.126929819584.\n",
      "Iteration: 7590/8000, Loss: 0.126929819584.\n",
      "Iteration: 7591/8000, Loss: 0.126929819584.\n",
      "Iteration: 7592/8000, Loss: 0.126929819584.\n",
      "Iteration: 7593/8000, Loss: 0.126929819584.\n",
      "Iteration: 7594/8000, Loss: 0.126929819584.\n",
      "Iteration: 7595/8000, Loss: 0.126929819584.\n",
      "Iteration: 7596/8000, Loss: 0.126929819584.\n",
      "Iteration: 7597/8000, Loss: 0.126929819584.\n",
      "Iteration: 7598/8000, Loss: 0.126929804683.\n",
      "Iteration: 7599/8000, Loss: 0.126929804683.\n",
      "Iteration: 7600/8000, Loss: 0.126929804683.\n",
      "Iteration: 7601/8000, Loss: 0.126929804683.\n",
      "Iteration: 7602/8000, Loss: 0.126929804683.\n",
      "Iteration: 7603/8000, Loss: 0.126929804683.\n",
      "Iteration: 7604/8000, Loss: 0.126929804683.\n",
      "Iteration: 7605/8000, Loss: 0.126929804683.\n",
      "Iteration: 7606/8000, Loss: 0.126929789782.\n",
      "Iteration: 7607/8000, Loss: 0.126929804683.\n",
      "Iteration: 7608/8000, Loss: 0.126929804683.\n",
      "Iteration: 7609/8000, Loss: 0.126929789782.\n",
      "Iteration: 7610/8000, Loss: 0.126929789782.\n",
      "Iteration: 7611/8000, Loss: 0.126929789782.\n",
      "Iteration: 7612/8000, Loss: 0.126929789782.\n",
      "Iteration: 7613/8000, Loss: 0.126929789782.\n",
      "Iteration: 7614/8000, Loss: 0.126929789782.\n",
      "Iteration: 7615/8000, Loss: 0.126929789782.\n",
      "Iteration: 7616/8000, Loss: 0.126929789782.\n",
      "Iteration: 7617/8000, Loss: 0.126929789782.\n",
      "Iteration: 7618/8000, Loss: 0.126929789782.\n",
      "Iteration: 7619/8000, Loss: 0.126929789782.\n",
      "Iteration: 7620/8000, Loss: 0.126929789782.\n",
      "Iteration: 7621/8000, Loss: 0.126929789782.\n",
      "Iteration: 7622/8000, Loss: 0.126929789782.\n",
      "Iteration: 7623/8000, Loss: 0.126929789782.\n",
      "Iteration: 7624/8000, Loss: 0.126929789782.\n",
      "Iteration: 7625/8000, Loss: 0.12692977488.\n",
      "Iteration: 7626/8000, Loss: 0.126929789782.\n",
      "Iteration: 7627/8000, Loss: 0.126929789782.\n",
      "Iteration: 7628/8000, Loss: 0.126929789782.\n",
      "Iteration: 7629/8000, Loss: 0.12692977488.\n",
      "Iteration: 7630/8000, Loss: 0.126929789782.\n",
      "Iteration: 7631/8000, Loss: 0.12692977488.\n",
      "Iteration: 7632/8000, Loss: 0.12692977488.\n",
      "Iteration: 7633/8000, Loss: 0.12692977488.\n",
      "Iteration: 7634/8000, Loss: 0.12692977488.\n",
      "Iteration: 7635/8000, Loss: 0.126929759979.\n",
      "Iteration: 7636/8000, Loss: 0.12692977488.\n",
      "Iteration: 7637/8000, Loss: 0.12692977488.\n",
      "Iteration: 7638/8000, Loss: 0.12692977488.\n",
      "Iteration: 7639/8000, Loss: 0.12692977488.\n",
      "Iteration: 7640/8000, Loss: 0.12692977488.\n",
      "Iteration: 7641/8000, Loss: 0.126929759979.\n",
      "Iteration: 7642/8000, Loss: 0.126929759979.\n",
      "Iteration: 7643/8000, Loss: 0.126929759979.\n",
      "Iteration: 7644/8000, Loss: 0.126929759979.\n",
      "Iteration: 7645/8000, Loss: 0.126929759979.\n",
      "Iteration: 7646/8000, Loss: 0.126929759979.\n",
      "Iteration: 7647/8000, Loss: 0.126929759979.\n",
      "Iteration: 7648/8000, Loss: 0.126929759979.\n",
      "Iteration: 7649/8000, Loss: 0.126929759979.\n",
      "Iteration: 7650/8000, Loss: 0.126929759979.\n",
      "Iteration: 7651/8000, Loss: 0.126929759979.\n",
      "Iteration: 7652/8000, Loss: 0.126929759979.\n",
      "Iteration: 7653/8000, Loss: 0.126929759979.\n",
      "Iteration: 7654/8000, Loss: 0.126929759979.\n",
      "Iteration: 7655/8000, Loss: 0.126929759979.\n",
      "Iteration: 7656/8000, Loss: 0.126929745078.\n",
      "Iteration: 7657/8000, Loss: 0.126929759979.\n",
      "Iteration: 7658/8000, Loss: 0.126929759979.\n",
      "Iteration: 7659/8000, Loss: 0.126929759979.\n",
      "Iteration: 7660/8000, Loss: 0.126929745078.\n",
      "Iteration: 7661/8000, Loss: 0.126929759979.\n",
      "Iteration: 7662/8000, Loss: 0.126929759979.\n",
      "Iteration: 7663/8000, Loss: 0.126929759979.\n",
      "Iteration: 7664/8000, Loss: 0.126929759979.\n",
      "Iteration: 7665/8000, Loss: 0.126929759979.\n",
      "Iteration: 7666/8000, Loss: 0.126929745078.\n",
      "Iteration: 7667/8000, Loss: 0.126929759979.\n",
      "Iteration: 7668/8000, Loss: 0.126929745078.\n",
      "Iteration: 7669/8000, Loss: 0.126929759979.\n",
      "Iteration: 7670/8000, Loss: 0.126929745078.\n",
      "Iteration: 7671/8000, Loss: 0.126929745078.\n",
      "Iteration: 7672/8000, Loss: 0.126929745078.\n",
      "Iteration: 7673/8000, Loss: 0.126929730177.\n",
      "Iteration: 7674/8000, Loss: 0.126929730177.\n",
      "Iteration: 7675/8000, Loss: 0.126929730177.\n",
      "Iteration: 7676/8000, Loss: 0.126929730177.\n",
      "Iteration: 7677/8000, Loss: 0.126929730177.\n",
      "Iteration: 7678/8000, Loss: 0.126929730177.\n",
      "Iteration: 7679/8000, Loss: 0.126929730177.\n",
      "Iteration: 7680/8000, Loss: 0.126929730177.\n",
      "Iteration: 7681/8000, Loss: 0.126929745078.\n",
      "Iteration: 7682/8000, Loss: 0.126929730177.\n",
      "Iteration: 7683/8000, Loss: 0.126929730177.\n",
      "Iteration: 7684/8000, Loss: 0.126929730177.\n",
      "Iteration: 7685/8000, Loss: 0.126929730177.\n",
      "Iteration: 7686/8000, Loss: 0.126929730177.\n",
      "Iteration: 7687/8000, Loss: 0.126929715276.\n",
      "Iteration: 7688/8000, Loss: 0.126929730177.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 7689/8000, Loss: 0.126929715276.\n",
      "Iteration: 7690/8000, Loss: 0.126929715276.\n",
      "Iteration: 7691/8000, Loss: 0.126929730177.\n",
      "Iteration: 7692/8000, Loss: 0.126929715276.\n",
      "Iteration: 7693/8000, Loss: 0.126929715276.\n",
      "Iteration: 7694/8000, Loss: 0.126929715276.\n",
      "Iteration: 7695/8000, Loss: 0.126929715276.\n",
      "Iteration: 7696/8000, Loss: 0.126929715276.\n",
      "Iteration: 7697/8000, Loss: 0.126929715276.\n",
      "Iteration: 7698/8000, Loss: 0.126929715276.\n",
      "Iteration: 7699/8000, Loss: 0.126929715276.\n",
      "Iteration: 7700/8000, Loss: 0.126929715276.\n",
      "Iteration: 7701/8000, Loss: 0.126929715276.\n",
      "Iteration: 7702/8000, Loss: 0.126929715276.\n",
      "Iteration: 7703/8000, Loss: 0.126929715276.\n",
      "Iteration: 7704/8000, Loss: 0.126929715276.\n",
      "Iteration: 7705/8000, Loss: 0.126929700375.\n",
      "Iteration: 7706/8000, Loss: 0.126929700375.\n",
      "Iteration: 7707/8000, Loss: 0.126929715276.\n",
      "Iteration: 7708/8000, Loss: 0.126929700375.\n",
      "Iteration: 7709/8000, Loss: 0.126929700375.\n",
      "Iteration: 7710/8000, Loss: 0.126929700375.\n",
      "Iteration: 7711/8000, Loss: 0.126929700375.\n",
      "Iteration: 7712/8000, Loss: 0.126929700375.\n",
      "Iteration: 7713/8000, Loss: 0.126929700375.\n",
      "Iteration: 7714/8000, Loss: 0.126929700375.\n",
      "Iteration: 7715/8000, Loss: 0.126929700375.\n",
      "Iteration: 7716/8000, Loss: 0.126929700375.\n",
      "Iteration: 7717/8000, Loss: 0.126929700375.\n",
      "Iteration: 7718/8000, Loss: 0.126929700375.\n",
      "Iteration: 7719/8000, Loss: 0.126929700375.\n",
      "Iteration: 7720/8000, Loss: 0.126929700375.\n",
      "Iteration: 7721/8000, Loss: 0.126929700375.\n",
      "Iteration: 7722/8000, Loss: 0.126929685473.\n",
      "Iteration: 7723/8000, Loss: 0.126929685473.\n",
      "Iteration: 7724/8000, Loss: 0.126929700375.\n",
      "Iteration: 7725/8000, Loss: 0.126929700375.\n",
      "Iteration: 7726/8000, Loss: 0.126929700375.\n",
      "Iteration: 7727/8000, Loss: 0.126929700375.\n",
      "Iteration: 7728/8000, Loss: 0.126929670572.\n",
      "Iteration: 7729/8000, Loss: 0.126929685473.\n",
      "Iteration: 7730/8000, Loss: 0.126929685473.\n",
      "Iteration: 7731/8000, Loss: 0.126929670572.\n",
      "Iteration: 7732/8000, Loss: 0.126929685473.\n",
      "Iteration: 7733/8000, Loss: 0.126929685473.\n",
      "Iteration: 7734/8000, Loss: 0.126929685473.\n",
      "Iteration: 7735/8000, Loss: 0.126929670572.\n",
      "Iteration: 7736/8000, Loss: 0.126929670572.\n",
      "Iteration: 7737/8000, Loss: 0.126929670572.\n",
      "Iteration: 7738/8000, Loss: 0.126929685473.\n",
      "Iteration: 7739/8000, Loss: 0.126929685473.\n",
      "Iteration: 7740/8000, Loss: 0.126929685473.\n",
      "Iteration: 7741/8000, Loss: 0.126929670572.\n",
      "Iteration: 7742/8000, Loss: 0.126929685473.\n",
      "Iteration: 7743/8000, Loss: 0.126929670572.\n",
      "Iteration: 7744/8000, Loss: 0.126929670572.\n",
      "Iteration: 7745/8000, Loss: 0.126929670572.\n",
      "Iteration: 7746/8000, Loss: 0.126929685473.\n",
      "Iteration: 7747/8000, Loss: 0.126929670572.\n",
      "Iteration: 7748/8000, Loss: 0.126929670572.\n",
      "Iteration: 7749/8000, Loss: 0.126929670572.\n",
      "Iteration: 7750/8000, Loss: 0.126929670572.\n",
      "Iteration: 7751/8000, Loss: 0.126929670572.\n",
      "Iteration: 7752/8000, Loss: 0.126929670572.\n",
      "Iteration: 7753/8000, Loss: 0.126929670572.\n",
      "Iteration: 7754/8000, Loss: 0.126929670572.\n",
      "Iteration: 7755/8000, Loss: 0.126929670572.\n",
      "Iteration: 7756/8000, Loss: 0.126929670572.\n",
      "Iteration: 7757/8000, Loss: 0.126929670572.\n",
      "Iteration: 7758/8000, Loss: 0.126929655671.\n",
      "Iteration: 7759/8000, Loss: 0.126929655671.\n",
      "Iteration: 7760/8000, Loss: 0.126929655671.\n",
      "Iteration: 7761/8000, Loss: 0.126929655671.\n",
      "Iteration: 7762/8000, Loss: 0.126929655671.\n",
      "Iteration: 7763/8000, Loss: 0.126929655671.\n",
      "Iteration: 7764/8000, Loss: 0.126929655671.\n",
      "Iteration: 7765/8000, Loss: 0.126929655671.\n",
      "Iteration: 7766/8000, Loss: 0.126929655671.\n",
      "Iteration: 7767/8000, Loss: 0.126929655671.\n",
      "Iteration: 7768/8000, Loss: 0.126929655671.\n",
      "Iteration: 7769/8000, Loss: 0.126929655671.\n",
      "Iteration: 7770/8000, Loss: 0.126929655671.\n",
      "Iteration: 7771/8000, Loss: 0.126929655671.\n",
      "Iteration: 7772/8000, Loss: 0.126929655671.\n",
      "Iteration: 7773/8000, Loss: 0.126929655671.\n",
      "Iteration: 7774/8000, Loss: 0.126929655671.\n",
      "Iteration: 7775/8000, Loss: 0.126929655671.\n",
      "Iteration: 7776/8000, Loss: 0.126929655671.\n",
      "Iteration: 7777/8000, Loss: 0.126929655671.\n",
      "Iteration: 7778/8000, Loss: 0.12692964077.\n",
      "Iteration: 7779/8000, Loss: 0.126929655671.\n",
      "Iteration: 7780/8000, Loss: 0.126929655671.\n",
      "Iteration: 7781/8000, Loss: 0.126929655671.\n",
      "Iteration: 7782/8000, Loss: 0.12692964077.\n",
      "Iteration: 7783/8000, Loss: 0.12692964077.\n",
      "Iteration: 7784/8000, Loss: 0.12692964077.\n",
      "Iteration: 7785/8000, Loss: 0.126929655671.\n",
      "Iteration: 7786/8000, Loss: 0.12692964077.\n",
      "Iteration: 7787/8000, Loss: 0.12692964077.\n",
      "Iteration: 7788/8000, Loss: 0.12692964077.\n",
      "Iteration: 7789/8000, Loss: 0.12692964077.\n",
      "Iteration: 7790/8000, Loss: 0.12692964077.\n",
      "Iteration: 7791/8000, Loss: 0.12692964077.\n",
      "Iteration: 7792/8000, Loss: 0.12692964077.\n",
      "Iteration: 7793/8000, Loss: 0.12692964077.\n",
      "Iteration: 7794/8000, Loss: 0.12692964077.\n",
      "Iteration: 7795/8000, Loss: 0.12692964077.\n",
      "Iteration: 7796/8000, Loss: 0.12692964077.\n",
      "Iteration: 7797/8000, Loss: 0.126929625869.\n",
      "Iteration: 7798/8000, Loss: 0.12692964077.\n",
      "Iteration: 7799/8000, Loss: 0.126929625869.\n",
      "Iteration: 7800/8000, Loss: 0.126929625869.\n",
      "Iteration: 7801/8000, Loss: 0.126929625869.\n",
      "Iteration: 7802/8000, Loss: 0.126929625869.\n",
      "Iteration: 7803/8000, Loss: 0.126929625869.\n",
      "Iteration: 7804/8000, Loss: 0.126929610968.\n",
      "Iteration: 7805/8000, Loss: 0.126929610968.\n",
      "Iteration: 7806/8000, Loss: 0.126929610968.\n",
      "Iteration: 7807/8000, Loss: 0.126929610968.\n",
      "Iteration: 7808/8000, Loss: 0.126929610968.\n",
      "Iteration: 7809/8000, Loss: 0.126929610968.\n",
      "Iteration: 7810/8000, Loss: 0.126929610968.\n",
      "Iteration: 7811/8000, Loss: 0.126929610968.\n",
      "Iteration: 7812/8000, Loss: 0.126929610968.\n",
      "Iteration: 7813/8000, Loss: 0.126929610968.\n",
      "Iteration: 7814/8000, Loss: 0.126929610968.\n",
      "Iteration: 7815/8000, Loss: 0.126929610968.\n",
      "Iteration: 7816/8000, Loss: 0.126929610968.\n",
      "Iteration: 7817/8000, Loss: 0.126929610968.\n",
      "Iteration: 7818/8000, Loss: 0.126929610968.\n",
      "Iteration: 7819/8000, Loss: 0.126929610968.\n",
      "Iteration: 7820/8000, Loss: 0.126929610968.\n",
      "Iteration: 7821/8000, Loss: 0.126929610968.\n",
      "Iteration: 7822/8000, Loss: 0.126929610968.\n",
      "Iteration: 7823/8000, Loss: 0.126929610968.\n",
      "Iteration: 7824/8000, Loss: 0.126929610968.\n",
      "Iteration: 7825/8000, Loss: 0.126929610968.\n",
      "Iteration: 7826/8000, Loss: 0.126929610968.\n",
      "Iteration: 7827/8000, Loss: 0.126929610968.\n",
      "Iteration: 7828/8000, Loss: 0.126929610968.\n",
      "Iteration: 7829/8000, Loss: 0.126929610968.\n",
      "Iteration: 7830/8000, Loss: 0.126929610968.\n",
      "Iteration: 7831/8000, Loss: 0.126929610968.\n",
      "Iteration: 7832/8000, Loss: 0.126929596066.\n",
      "Iteration: 7833/8000, Loss: 0.126929610968.\n",
      "Iteration: 7834/8000, Loss: 0.126929610968.\n",
      "Iteration: 7835/8000, Loss: 0.126929610968.\n",
      "Iteration: 7836/8000, Loss: 0.126929610968.\n",
      "Iteration: 7837/8000, Loss: 0.126929596066.\n",
      "Iteration: 7838/8000, Loss: 0.126929610968.\n",
      "Iteration: 7839/8000, Loss: 0.126929610968.\n",
      "Iteration: 7840/8000, Loss: 0.126929596066.\n",
      "Iteration: 7841/8000, Loss: 0.126929596066.\n",
      "Iteration: 7842/8000, Loss: 0.126929596066.\n",
      "Iteration: 7843/8000, Loss: 0.126929596066.\n",
      "Iteration: 7844/8000, Loss: 0.126929581165.\n",
      "Iteration: 7845/8000, Loss: 0.126929610968.\n",
      "Iteration: 7846/8000, Loss: 0.126929581165.\n",
      "Iteration: 7847/8000, Loss: 0.126929581165.\n",
      "Iteration: 7848/8000, Loss: 0.126929581165.\n",
      "Iteration: 7849/8000, Loss: 0.126929581165.\n",
      "Iteration: 7850/8000, Loss: 0.126929581165.\n",
      "Iteration: 7851/8000, Loss: 0.126929581165.\n",
      "Iteration: 7852/8000, Loss: 0.126929581165.\n",
      "Iteration: 7853/8000, Loss: 0.126929581165.\n",
      "Iteration: 7854/8000, Loss: 0.126929581165.\n",
      "Iteration: 7855/8000, Loss: 0.126929581165.\n",
      "Iteration: 7856/8000, Loss: 0.126929581165.\n",
      "Iteration: 7857/8000, Loss: 0.126929581165.\n",
      "Iteration: 7858/8000, Loss: 0.126929581165.\n",
      "Iteration: 7859/8000, Loss: 0.126929581165.\n",
      "Iteration: 7860/8000, Loss: 0.126929581165.\n",
      "Iteration: 7861/8000, Loss: 0.126929581165.\n",
      "Iteration: 7862/8000, Loss: 0.126929581165.\n",
      "Iteration: 7863/8000, Loss: 0.126929581165.\n",
      "Iteration: 7864/8000, Loss: 0.126929581165.\n",
      "Iteration: 7865/8000, Loss: 0.126929581165.\n",
      "Iteration: 7866/8000, Loss: 0.126929581165.\n",
      "Iteration: 7867/8000, Loss: 0.126929581165.\n",
      "Iteration: 7868/8000, Loss: 0.126929581165.\n",
      "Iteration: 7869/8000, Loss: 0.126929581165.\n",
      "Iteration: 7870/8000, Loss: 0.126929566264.\n",
      "Iteration: 7871/8000, Loss: 0.126929566264.\n",
      "Iteration: 7872/8000, Loss: 0.126929566264.\n",
      "Iteration: 7873/8000, Loss: 0.126929566264.\n",
      "Iteration: 7874/8000, Loss: 0.126929566264.\n",
      "Iteration: 7875/8000, Loss: 0.126929566264.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 7876/8000, Loss: 0.126929566264.\n",
      "Iteration: 7877/8000, Loss: 0.126929566264.\n",
      "Iteration: 7878/8000, Loss: 0.126929566264.\n",
      "Iteration: 7879/8000, Loss: 0.126929566264.\n",
      "Iteration: 7880/8000, Loss: 0.126929566264.\n",
      "Iteration: 7881/8000, Loss: 0.126929566264.\n",
      "Iteration: 7882/8000, Loss: 0.126929551363.\n",
      "Iteration: 7883/8000, Loss: 0.126929551363.\n",
      "Iteration: 7884/8000, Loss: 0.126929551363.\n",
      "Iteration: 7885/8000, Loss: 0.126929551363.\n",
      "Iteration: 7886/8000, Loss: 0.126929551363.\n",
      "Iteration: 7887/8000, Loss: 0.126929551363.\n",
      "Iteration: 7888/8000, Loss: 0.126929551363.\n",
      "Iteration: 7889/8000, Loss: 0.126929551363.\n",
      "Iteration: 7890/8000, Loss: 0.126929551363.\n",
      "Iteration: 7891/8000, Loss: 0.126929551363.\n",
      "Iteration: 7892/8000, Loss: 0.126929551363.\n",
      "Iteration: 7893/8000, Loss: 0.126929551363.\n",
      "Iteration: 7894/8000, Loss: 0.126929551363.\n",
      "Iteration: 7895/8000, Loss: 0.126929551363.\n",
      "Iteration: 7896/8000, Loss: 0.126929551363.\n",
      "Iteration: 7897/8000, Loss: 0.126929551363.\n",
      "Iteration: 7898/8000, Loss: 0.126929551363.\n",
      "Iteration: 7899/8000, Loss: 0.126929551363.\n",
      "Iteration: 7900/8000, Loss: 0.126929551363.\n",
      "Iteration: 7901/8000, Loss: 0.126929551363.\n",
      "Iteration: 7902/8000, Loss: 0.126929551363.\n",
      "Iteration: 7903/8000, Loss: 0.126929551363.\n",
      "Iteration: 7904/8000, Loss: 0.126929551363.\n",
      "Iteration: 7905/8000, Loss: 0.126929551363.\n",
      "Iteration: 7906/8000, Loss: 0.126929551363.\n",
      "Iteration: 7907/8000, Loss: 0.126929551363.\n",
      "Iteration: 7908/8000, Loss: 0.126929551363.\n",
      "Iteration: 7909/8000, Loss: 0.126929536462.\n",
      "Iteration: 7910/8000, Loss: 0.126929551363.\n",
      "Iteration: 7911/8000, Loss: 0.126929536462.\n",
      "Iteration: 7912/8000, Loss: 0.126929551363.\n",
      "Iteration: 7913/8000, Loss: 0.126929551363.\n",
      "Iteration: 7914/8000, Loss: 0.126929551363.\n",
      "Iteration: 7915/8000, Loss: 0.126929551363.\n",
      "Iteration: 7916/8000, Loss: 0.126929551363.\n",
      "Iteration: 7917/8000, Loss: 0.126929551363.\n",
      "Iteration: 7918/8000, Loss: 0.126929551363.\n",
      "Iteration: 7919/8000, Loss: 0.126929536462.\n",
      "Iteration: 7920/8000, Loss: 0.126929551363.\n",
      "Iteration: 7921/8000, Loss: 0.126929551363.\n",
      "Iteration: 7922/8000, Loss: 0.126929536462.\n",
      "Iteration: 7923/8000, Loss: 0.126929536462.\n",
      "Iteration: 7924/8000, Loss: 0.126929536462.\n",
      "Iteration: 7925/8000, Loss: 0.126929536462.\n",
      "Iteration: 7926/8000, Loss: 0.126929536462.\n",
      "Iteration: 7927/8000, Loss: 0.126929536462.\n",
      "Iteration: 7928/8000, Loss: 0.126929536462.\n",
      "Iteration: 7929/8000, Loss: 0.126929536462.\n",
      "Iteration: 7930/8000, Loss: 0.126929521561.\n",
      "Iteration: 7931/8000, Loss: 0.126929536462.\n",
      "Iteration: 7932/8000, Loss: 0.126929521561.\n",
      "Iteration: 7933/8000, Loss: 0.126929521561.\n",
      "Iteration: 7934/8000, Loss: 0.126929521561.\n",
      "Iteration: 7935/8000, Loss: 0.126929536462.\n",
      "Iteration: 7936/8000, Loss: 0.126929521561.\n",
      "Iteration: 7937/8000, Loss: 0.126929521561.\n",
      "Iteration: 7938/8000, Loss: 0.126929521561.\n",
      "Iteration: 7939/8000, Loss: 0.126929521561.\n",
      "Iteration: 7940/8000, Loss: 0.126929521561.\n",
      "Iteration: 7941/8000, Loss: 0.12692950666.\n",
      "Iteration: 7942/8000, Loss: 0.12692950666.\n",
      "Iteration: 7943/8000, Loss: 0.12692950666.\n",
      "Iteration: 7944/8000, Loss: 0.12692950666.\n",
      "Iteration: 7945/8000, Loss: 0.12692950666.\n",
      "Iteration: 7946/8000, Loss: 0.12692950666.\n",
      "Iteration: 7947/8000, Loss: 0.12692950666.\n",
      "Iteration: 7948/8000, Loss: 0.12692950666.\n",
      "Iteration: 7949/8000, Loss: 0.12692950666.\n",
      "Iteration: 7950/8000, Loss: 0.12692950666.\n",
      "Iteration: 7951/8000, Loss: 0.12692950666.\n",
      "Iteration: 7952/8000, Loss: 0.12692950666.\n",
      "Iteration: 7953/8000, Loss: 0.12692950666.\n",
      "Iteration: 7954/8000, Loss: 0.12692950666.\n",
      "Iteration: 7955/8000, Loss: 0.12692950666.\n",
      "Iteration: 7956/8000, Loss: 0.12692950666.\n",
      "Iteration: 7957/8000, Loss: 0.12692950666.\n",
      "Iteration: 7958/8000, Loss: 0.12692950666.\n",
      "Iteration: 7959/8000, Loss: 0.12692950666.\n",
      "Iteration: 7960/8000, Loss: 0.12692950666.\n",
      "Iteration: 7961/8000, Loss: 0.12692950666.\n",
      "Iteration: 7962/8000, Loss: 0.12692950666.\n",
      "Iteration: 7963/8000, Loss: 0.12692950666.\n",
      "Iteration: 7964/8000, Loss: 0.126929491758.\n",
      "Iteration: 7965/8000, Loss: 0.126929491758.\n",
      "Iteration: 7966/8000, Loss: 0.126929491758.\n",
      "Iteration: 7967/8000, Loss: 0.126929491758.\n",
      "Iteration: 7968/8000, Loss: 0.126929491758.\n",
      "Iteration: 7969/8000, Loss: 0.126929491758.\n",
      "Iteration: 7970/8000, Loss: 0.126929491758.\n",
      "Iteration: 7971/8000, Loss: 0.126929491758.\n",
      "Iteration: 7972/8000, Loss: 0.126929491758.\n",
      "Iteration: 7973/8000, Loss: 0.126929491758.\n",
      "Iteration: 7974/8000, Loss: 0.126929491758.\n",
      "Iteration: 7975/8000, Loss: 0.126929491758.\n",
      "Iteration: 7976/8000, Loss: 0.126929491758.\n",
      "Iteration: 7977/8000, Loss: 0.126929491758.\n",
      "Iteration: 7978/8000, Loss: 0.126929491758.\n",
      "Iteration: 7979/8000, Loss: 0.126929491758.\n",
      "Iteration: 7980/8000, Loss: 0.126929491758.\n",
      "Iteration: 7981/8000, Loss: 0.126929461956.\n",
      "Iteration: 7982/8000, Loss: 0.126929491758.\n",
      "Iteration: 7983/8000, Loss: 0.126929461956.\n",
      "Iteration: 7984/8000, Loss: 0.126929461956.\n",
      "Iteration: 7985/8000, Loss: 0.126929461956.\n",
      "Iteration: 7986/8000, Loss: 0.126929461956.\n",
      "Iteration: 7987/8000, Loss: 0.126929461956.\n",
      "Iteration: 7988/8000, Loss: 0.126929461956.\n",
      "Iteration: 7989/8000, Loss: 0.126929476857.\n",
      "Iteration: 7990/8000, Loss: 0.126929461956.\n",
      "Iteration: 7991/8000, Loss: 0.126929461956.\n",
      "Iteration: 7992/8000, Loss: 0.126929461956.\n",
      "Iteration: 7993/8000, Loss: 0.126929461956.\n",
      "Iteration: 7994/8000, Loss: 0.126929461956.\n",
      "Iteration: 7995/8000, Loss: 0.126929461956.\n",
      "Iteration: 7996/8000, Loss: 0.126929461956.\n",
      "Iteration: 7997/8000, Loss: 0.126929461956.\n",
      "Iteration: 7998/8000, Loss: 0.126929461956.\n",
      "Iteration: 7999/8000, Loss: 0.126929461956.\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "for i in range(max_iter):\n",
    "    idx = np.random.choice(data_size, batch_size)\n",
    "    loss, _ = sess.run([train_loss, train_op], feed_dict={X: train_feature, y: train_label})\n",
    "    loss_list.append(loss)\n",
    "    print \"\\rIteration: {}/{}, Loss: {}.\".format(i, max_iter, loss)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efc24044bd0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXk8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efc26d506d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = make_meshgrid(x[:, 0], x[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for predict\n",
    "new_x = np.c_[xx.ravel(), yy.ravel()]\n",
    "new_feature = gen_feature(new_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sess.run(out, feed_dict={X: new_feature})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.4363541603088379, 5.4636458396909298)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEC6DhJ0gCMJl/P9ior3fjgH0pAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efc1c672390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_y = np.argmax(y_pred, axis=1)\n",
    "\n",
    "ax = plt.axes()\n",
    "\n",
    "plot_contours(ax, pred_y, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "ax.scatter(class_0[:, 0], class_0[:, 1], c='b', s=20, edgecolors='k')\n",
    "ax.scatter(class_1[:, 0], class_1[:, 1], c='g', s=20, edgecolors='k')\n",
    "ax.set_xlim(xx.min(), xx.max())\n",
    "ax.set_ylim(yy.min(), yy.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
